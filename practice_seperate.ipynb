{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "practice_seperate",
      "provenance": [],
      "collapsed_sections": [
        "OgGOQhWUPb8m"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sjx_1D2aO7v3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YerBmWU2r_Yk",
        "outputId": "10fcca49-938d-4028-fd07-ed970774368e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# google drive 연동\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pandas as pd\n",
        "os.chdir('/content/drive/MyDrive/jiwon')\n",
        "\n",
        "weather = pd.read_csv('해운대 날씨.csv')\n",
        "customer = pd.read_csv('해운대 입장객수2.csv')"
      ],
      "metadata": {
        "id": "1Z9yA_dMsmHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NpkRSB4EtqEd",
        "outputId": "5a84e987-c88a-4eae-e22b-4a407adbd59e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           날짜  강수_관측값    기온    습도  체감온도  평균풍속    평균기압  평균수온  평균최대파고  평균파주기\n",
              "0  2012-05-01    10.5  20.4  62.1  21.5   6.5  1009.0  15.2     1.2    4.8\n",
              "1  2012-05-02     1.0  19.6  70.5  21.4   7.8  1004.0  15.5     2.1    5.7\n",
              "2  2012-05-03     0.1  20.7  77.5  22.9   4.1  1004.0  16.4     1.9    6.6\n",
              "3  2012-05-04     0.0  19.9  70.7  21.7   4.1  1006.5  16.4     1.6    7.5\n",
              "4  2012-05-05     0.0  24.8  47.2  24.7   6.1  1004.9  15.8     1.9    7.8"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7bc36ff-6d60-4ef8-9380-1fcc5fc8628f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>날짜</th>\n",
              "      <th>강수_관측값</th>\n",
              "      <th>기온</th>\n",
              "      <th>습도</th>\n",
              "      <th>체감온도</th>\n",
              "      <th>평균풍속</th>\n",
              "      <th>평균기압</th>\n",
              "      <th>평균수온</th>\n",
              "      <th>평균최대파고</th>\n",
              "      <th>평균파주기</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-05-01</td>\n",
              "      <td>10.5</td>\n",
              "      <td>20.4</td>\n",
              "      <td>62.1</td>\n",
              "      <td>21.5</td>\n",
              "      <td>6.5</td>\n",
              "      <td>1009.0</td>\n",
              "      <td>15.2</td>\n",
              "      <td>1.2</td>\n",
              "      <td>4.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-05-02</td>\n",
              "      <td>1.0</td>\n",
              "      <td>19.6</td>\n",
              "      <td>70.5</td>\n",
              "      <td>21.4</td>\n",
              "      <td>7.8</td>\n",
              "      <td>1004.0</td>\n",
              "      <td>15.5</td>\n",
              "      <td>2.1</td>\n",
              "      <td>5.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-05-03</td>\n",
              "      <td>0.1</td>\n",
              "      <td>20.7</td>\n",
              "      <td>77.5</td>\n",
              "      <td>22.9</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1004.0</td>\n",
              "      <td>16.4</td>\n",
              "      <td>1.9</td>\n",
              "      <td>6.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-05-04</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.9</td>\n",
              "      <td>70.7</td>\n",
              "      <td>21.7</td>\n",
              "      <td>4.1</td>\n",
              "      <td>1006.5</td>\n",
              "      <td>16.4</td>\n",
              "      <td>1.6</td>\n",
              "      <td>7.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-05-05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.8</td>\n",
              "      <td>47.2</td>\n",
              "      <td>24.7</td>\n",
              "      <td>6.1</td>\n",
              "      <td>1004.9</td>\n",
              "      <td>15.8</td>\n",
              "      <td>1.9</td>\n",
              "      <td>7.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7bc36ff-6d60-4ef8-9380-1fcc5fc8628f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a7bc36ff-6d60-4ef8-9380-1fcc5fc8628f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a7bc36ff-6d60-4ef8-9380-1fcc5fc8628f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AW7MlvkutqCM",
        "outputId": "800d0f46-7017-4751-9207-88724e11fd0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          방문일 방문객수\n",
              "0  2012-05-01  NaN\n",
              "1  2012-05-02  NaN\n",
              "2  2012-05-03  NaN\n",
              "3  2012-05-04  NaN\n",
              "4  2012-05-05  NaN"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-438eafe9-20e5-4964-8f8b-f91243cad49e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>방문일</th>\n",
              "      <th>방문객수</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-05-01</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-05-02</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-05-03</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-05-04</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-05-05</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-438eafe9-20e5-4964-8f8b-f91243cad49e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-438eafe9-20e5-4964-8f8b-f91243cad49e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-438eafe9-20e5-4964-8f8b-f91243cad49e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Input\n",
        "from tensorflow.keras.layers import Bidirectional\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "from sklearn.preprocessing import MaxAbsScaler,RobustScaler\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import datetime\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "import inspect, os\n",
        "\n",
        "\n",
        "# 날짜를 date type으로 변경 후, 나머지는 numeric type으로 변경\n",
        "weather['날짜'] = pd.to_datetime(weather['날짜'], infer_datetime_format=True)\n",
        "weather.iloc[:,1:] = weather.iloc[:,1:].apply(pd.to_numeric)\n",
        "\n",
        "customer['방문일'] = pd.to_datetime(customer['방문일'], infer_datetime_format=True)\n",
        "customer['방문객수'] = customer['방문객수'].str.replace(\",\",\"\")\n",
        "customer.iloc[:,1:] = customer.iloc[:,1:].apply(pd.to_numeric)"
      ],
      "metadata": {
        "id": "Otkr69l0tg0t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "a06dd62d-4b9c-4afb-a09d-edd685264be2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-b352569968cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mcustomer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'방문일'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustomer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'방문일'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer_datetime_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mcustomer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'방문객수'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustomer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'방문객수'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\",\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0mcustomer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustomer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0maccessor_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0;31m# https://www.pydanny.com/cached-property.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/strings/accessor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringDtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_categorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_string\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStringDtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/strings/accessor.py\u001b[0m in \u001b[0;36m_validate\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minferred_dtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_types\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only use .str accessor with string values!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minferred_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Can only use .str accessor with string values!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weather.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p7jbT0T0elD",
        "outputId": "19026f16-5b2f-49c2-b183-235d76fb0591"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1618, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "customer.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTQP49F60ei-",
        "outputId": "0f9414e9-87ad-48f9-997a-da44acac2f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1465, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# merge data : 방문객수 예측을 위한 데이터\n",
        "total_data = pd.merge(weather, customer, left_on='날짜', right_on=\"방문일\", how='inner')\n",
        "total_data = total_data[['강수_관측값', \"기온\", \"습도\", \"체감온도\", \"평균수온\", \"평균풍속\", \"평균기압\", \"평균최대파고\", \"평균파주기\", \"방문객수\"]]\n",
        "\n",
        "# weather data : 날씨 예측을 위한 데이터(na는 제거하는 방향으로 일단 진행)\n",
        "total_data.loc[total_data['평균수온'] != total_data['평균수온'], '평균수온'] = total_data['평균수온'].mean()\n",
        "total_data.loc[total_data['평균풍속'] != total_data['평균풍속'], '평균풍속'] = total_data['평균풍속'].mean()\n",
        "total_data.loc[total_data['평균기압'] != total_data['평균기압'], '평균기압'] = total_data['평균기압'].mean()\n",
        "total_data.loc[total_data['평균최대파고'] != total_data['평균최대파고'], '평균최대파고'] = total_data['평균최대파고'].mean()\n",
        "total_data.loc[total_data['평균파주기'] != total_data['평균파주기'], '평균파주기'] = total_data['평균파주기'].mean()\n",
        "total_data = total_data.fillna(0)"
      ],
      "metadata": {
        "id": "MNrTID4vFigs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_data.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvIiX-Er15tq",
        "outputId": "8ba415db-4225-486f-838b-db05f8f50ea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "강수_관측값    0\n",
              "기온        0\n",
              "습도        0\n",
              "체감온도      0\n",
              "평균수온      0\n",
              "평균풍속      0\n",
              "평균기압      0\n",
              "평균최대파고    0\n",
              "평균파주기     0\n",
              "방문객수      0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 방문객 수 예측"
      ],
      "metadata": {
        "id": "BjYggYR-JBWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 방문객 수 예측을 위한 train/test split\n",
        "train_x, test_x, train_y, test_y = train_test_split(total_data.iloc[:, :-1], total_data['방문객수'], test_size=0.2)"
      ],
      "metadata": {
        "id": "f6h_mUXT0eeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 방문객 수 예측을 위한  minmax scaler\n",
        "x_mm_scaler = MinMaxScaler()\n",
        "train_x_scaled = x_mm_scaler.fit_transform(train_x)\n",
        "test_x_scaled = x_mm_scaler.transform(test_x)"
      ],
      "metadata": {
        "id": "VTm66mQo0ecJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_scaled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrFuZoBgtjfF",
        "outputId": "b13f459f-d24e-4ae7-d006-5d3a46397bbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1172, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x_scaled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sy2Iq29ntyS4",
        "outputId": "8fc3b7d1-0e71-4a6c-8781-df41f4db6702"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(293, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 방문객 수 예측을 위한  model training\n",
        "model=Sequential()\n",
        "model.add(Dense(128,input_dim=9, activation='relu'))\n",
        "model.add(Dense(256, activation='swish'))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(256, activation='swish'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='swish'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(16, activation='swish'))\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "t7LEHUe40eZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9b38f47-27dd-4fe4-af34-6c5bbbebe953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_19 (Dense)            (None, 128)               1280      \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 512)               131584    \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 340,993\n",
            "Trainable params: 340,993\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 진행\n",
        "earlyStopping=EarlyStopping(monitor='val_loss',patience=500,mode='min',verbose=1,restore_best_weights=True) \n",
        "model.compile(loss='mse',optimizer='adam')\n",
        "hist=model.fit(train_x_scaled,train_y,epochs=3000,batch_size=128,validation_split=0.2, callbacks=[earlyStopping])"
      ],
      "metadata": {
        "id": "z0dtixXcG403",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b57e6d91-68ad-4ee3-943c-42d02b016bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3000\n",
            "8/8 [==============================] - 1s 41ms/step - loss: 23353497600.0000 - val_loss: 19023800320.0000\n",
            "Epoch 2/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 23352766464.0000 - val_loss: 19021209600.0000\n",
            "Epoch 3/3000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 23344359424.0000 - val_loss: 18996983808.0000\n",
            "Epoch 4/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 23275829248.0000 - val_loss: 18832791552.0000\n",
            "Epoch 5/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 22876737536.0000 - val_loss: 17975658496.0000\n",
            "Epoch 6/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 21076637696.0000 - val_loss: 15109910528.0000\n",
            "Epoch 7/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 17695315968.0000 - val_loss: 15417337856.0000\n",
            "Epoch 8/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 17507532800.0000 - val_loss: 13884024832.0000\n",
            "Epoch 9/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 16970475520.0000 - val_loss: 13648437248.0000\n",
            "Epoch 10/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 16475969536.0000 - val_loss: 13570400256.0000\n",
            "Epoch 11/3000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 16075008000.0000 - val_loss: 12986676224.0000\n",
            "Epoch 12/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 15561124864.0000 - val_loss: 12688355328.0000\n",
            "Epoch 13/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 14861812736.0000 - val_loss: 12155604992.0000\n",
            "Epoch 14/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 14046832640.0000 - val_loss: 11705095168.0000\n",
            "Epoch 15/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 13096265728.0000 - val_loss: 10981369856.0000\n",
            "Epoch 16/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 12531664896.0000 - val_loss: 11314177024.0000\n",
            "Epoch 17/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 12407340032.0000 - val_loss: 11247418368.0000\n",
            "Epoch 18/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 12301599744.0000 - val_loss: 10914416640.0000\n",
            "Epoch 19/3000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 12278132736.0000 - val_loss: 11024745472.0000\n",
            "Epoch 20/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11671439360.0000 - val_loss: 10665962496.0000\n",
            "Epoch 21/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11618689024.0000 - val_loss: 10990879744.0000\n",
            "Epoch 22/3000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 11544706048.0000 - val_loss: 10618644480.0000\n",
            "Epoch 23/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11806051328.0000 - val_loss: 10761497600.0000\n",
            "Epoch 24/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11459529728.0000 - val_loss: 10566689792.0000\n",
            "Epoch 25/3000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 11408402432.0000 - val_loss: 10608834560.0000\n",
            "Epoch 26/3000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 11401708544.0000 - val_loss: 10574902272.0000\n",
            "Epoch 27/3000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 11462820864.0000 - val_loss: 10846313472.0000\n",
            "Epoch 28/3000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 11351270400.0000 - val_loss: 10574875648.0000\n",
            "Epoch 29/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11430893568.0000 - val_loss: 10855587840.0000\n",
            "Epoch 30/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11402849280.0000 - val_loss: 10558596096.0000\n",
            "Epoch 31/3000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 11321200640.0000 - val_loss: 10707086336.0000\n",
            "Epoch 32/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 11306902528.0000 - val_loss: 10606060544.0000\n",
            "Epoch 33/3000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 11248809984.0000 - val_loss: 10714394624.0000\n",
            "Epoch 34/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 11260264448.0000 - val_loss: 10551530496.0000\n",
            "Epoch 35/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11372047360.0000 - val_loss: 10832993280.0000\n",
            "Epoch 36/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11307930624.0000 - val_loss: 10544863232.0000\n",
            "Epoch 37/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11250132992.0000 - val_loss: 10689940480.0000\n",
            "Epoch 38/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11253109760.0000 - val_loss: 10651550720.0000\n",
            "Epoch 39/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 11218591744.0000 - val_loss: 10545278976.0000\n",
            "Epoch 40/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 11264190464.0000 - val_loss: 10822856704.0000\n",
            "Epoch 41/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11212363776.0000 - val_loss: 10581725184.0000\n",
            "Epoch 42/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 11163722752.0000 - val_loss: 10585392128.0000\n",
            "Epoch 43/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11171946496.0000 - val_loss: 10559588352.0000\n",
            "Epoch 44/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 11689874432.0000 - val_loss: 10534518784.0000\n",
            "Epoch 45/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11546166272.0000 - val_loss: 10559037440.0000\n",
            "Epoch 46/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 11425070080.0000 - val_loss: 10503719936.0000\n",
            "Epoch 47/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11162895360.0000 - val_loss: 10664264704.0000\n",
            "Epoch 48/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11155582976.0000 - val_loss: 10518025216.0000\n",
            "Epoch 49/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11291197440.0000 - val_loss: 10590203904.0000\n",
            "Epoch 50/3000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 11649937408.0000 - val_loss: 10523257856.0000\n",
            "Epoch 51/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11199939584.0000 - val_loss: 10941464576.0000\n",
            "Epoch 52/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11517448192.0000 - val_loss: 10522208256.0000\n",
            "Epoch 53/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11231470592.0000 - val_loss: 10858423296.0000\n",
            "Epoch 54/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11427411968.0000 - val_loss: 10502695936.0000\n",
            "Epoch 55/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11171793920.0000 - val_loss: 10773558272.0000\n",
            "Epoch 56/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11047048192.0000 - val_loss: 10531497984.0000\n",
            "Epoch 57/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11162373120.0000 - val_loss: 10518886400.0000\n",
            "Epoch 58/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11000909824.0000 - val_loss: 10642622464.0000\n",
            "Epoch 59/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11000426496.0000 - val_loss: 10529793024.0000\n",
            "Epoch 60/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10974209024.0000 - val_loss: 10569668608.0000\n",
            "Epoch 61/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 10957833216.0000 - val_loss: 10545488896.0000\n",
            "Epoch 62/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10993853440.0000 - val_loss: 10634506240.0000\n",
            "Epoch 63/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11139605504.0000 - val_loss: 10559898624.0000\n",
            "Epoch 64/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11003433984.0000 - val_loss: 10535946240.0000\n",
            "Epoch 65/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11062670336.0000 - val_loss: 10594251776.0000\n",
            "Epoch 66/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10929258496.0000 - val_loss: 10540071936.0000\n",
            "Epoch 67/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10971228160.0000 - val_loss: 10731573248.0000\n",
            "Epoch 68/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11003296768.0000 - val_loss: 10549682176.0000\n",
            "Epoch 69/3000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 11033915392.0000 - val_loss: 10681929728.0000\n",
            "Epoch 70/3000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 11087635456.0000 - val_loss: 10512273408.0000\n",
            "Epoch 71/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10983406592.0000 - val_loss: 10671034368.0000\n",
            "Epoch 72/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10860519424.0000 - val_loss: 10555317248.0000\n",
            "Epoch 73/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10971217920.0000 - val_loss: 10811940864.0000\n",
            "Epoch 74/3000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 10887090176.0000 - val_loss: 10574574592.0000\n",
            "Epoch 75/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 10945390592.0000 - val_loss: 10558039040.0000\n",
            "Epoch 76/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10913634304.0000 - val_loss: 10649424896.0000\n",
            "Epoch 77/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10933734400.0000 - val_loss: 10547313664.0000\n",
            "Epoch 78/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10848391168.0000 - val_loss: 10695582720.0000\n",
            "Epoch 79/3000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 10858262528.0000 - val_loss: 10564103168.0000\n",
            "Epoch 80/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11055632384.0000 - val_loss: 10679417856.0000\n",
            "Epoch 81/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10848611328.0000 - val_loss: 10588669952.0000\n",
            "Epoch 82/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10895199232.0000 - val_loss: 10656552960.0000\n",
            "Epoch 83/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10963093504.0000 - val_loss: 10560288768.0000\n",
            "Epoch 84/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11255104512.0000 - val_loss: 10569681920.0000\n",
            "Epoch 85/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11614703616.0000 - val_loss: 10505957376.0000\n",
            "Epoch 86/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 11416817664.0000 - val_loss: 10489626624.0000\n",
            "Epoch 87/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10901163008.0000 - val_loss: 10755052544.0000\n",
            "Epoch 88/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10892672000.0000 - val_loss: 10499117056.0000\n",
            "Epoch 89/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10764231680.0000 - val_loss: 10953348096.0000\n",
            "Epoch 90/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10838119424.0000 - val_loss: 10555442176.0000\n",
            "Epoch 91/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10832672768.0000 - val_loss: 10623249408.0000\n",
            "Epoch 92/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10790762496.0000 - val_loss: 10576241664.0000\n",
            "Epoch 93/3000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 10877998080.0000 - val_loss: 10650834944.0000\n",
            "Epoch 94/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10744931328.0000 - val_loss: 10571683840.0000\n",
            "Epoch 95/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10725627904.0000 - val_loss: 10871715840.0000\n",
            "Epoch 96/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10971761664.0000 - val_loss: 10602314752.0000\n",
            "Epoch 97/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10959087616.0000 - val_loss: 11005182976.0000\n",
            "Epoch 98/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10825391104.0000 - val_loss: 10561935360.0000\n",
            "Epoch 99/3000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 10782800896.0000 - val_loss: 10605877248.0000\n",
            "Epoch 100/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10724813824.0000 - val_loss: 10721542144.0000\n",
            "Epoch 101/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10722304000.0000 - val_loss: 10769882112.0000\n",
            "Epoch 102/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10853211136.0000 - val_loss: 10708106240.0000\n",
            "Epoch 103/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10706831360.0000 - val_loss: 10652983296.0000\n",
            "Epoch 104/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10775524352.0000 - val_loss: 10637749248.0000\n",
            "Epoch 105/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10738282496.0000 - val_loss: 10687396864.0000\n",
            "Epoch 106/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10715685888.0000 - val_loss: 10764404736.0000\n",
            "Epoch 107/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10715153408.0000 - val_loss: 10724943872.0000\n",
            "Epoch 108/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10671095808.0000 - val_loss: 10724523008.0000\n",
            "Epoch 109/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10679569408.0000 - val_loss: 10731429888.0000\n",
            "Epoch 110/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10852131840.0000 - val_loss: 10690308096.0000\n",
            "Epoch 111/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10736132096.0000 - val_loss: 10664493056.0000\n",
            "Epoch 112/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10660056064.0000 - val_loss: 10659688448.0000\n",
            "Epoch 113/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10740481024.0000 - val_loss: 10733831168.0000\n",
            "Epoch 114/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10792024064.0000 - val_loss: 10597534720.0000\n",
            "Epoch 115/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10905903104.0000 - val_loss: 10689995776.0000\n",
            "Epoch 116/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10692787200.0000 - val_loss: 10597488640.0000\n",
            "Epoch 117/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10768273408.0000 - val_loss: 10704065536.0000\n",
            "Epoch 118/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10599478272.0000 - val_loss: 10691260416.0000\n",
            "Epoch 119/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 10709711872.0000 - val_loss: 10650073088.0000\n",
            "Epoch 120/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10645299200.0000 - val_loss: 10769033216.0000\n",
            "Epoch 121/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10754666496.0000 - val_loss: 10823640064.0000\n",
            "Epoch 122/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10810138624.0000 - val_loss: 10701719552.0000\n",
            "Epoch 123/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10593466368.0000 - val_loss: 10735959040.0000\n",
            "Epoch 124/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10592656384.0000 - val_loss: 10708312064.0000\n",
            "Epoch 125/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10662363136.0000 - val_loss: 10789999616.0000\n",
            "Epoch 126/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10584427520.0000 - val_loss: 10831817728.0000\n",
            "Epoch 127/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10581496832.0000 - val_loss: 10727624704.0000\n",
            "Epoch 128/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10815521792.0000 - val_loss: 10943970304.0000\n",
            "Epoch 129/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11371082752.0000 - val_loss: 10749805568.0000\n",
            "Epoch 130/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 11110344704.0000 - val_loss: 10809344000.0000\n",
            "Epoch 131/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10920934400.0000 - val_loss: 10580140032.0000\n",
            "Epoch 132/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10937811968.0000 - val_loss: 10602615808.0000\n",
            "Epoch 133/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10595386368.0000 - val_loss: 10843236352.0000\n",
            "Epoch 134/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 10610660352.0000 - val_loss: 10689170432.0000\n",
            "Epoch 135/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10534556672.0000 - val_loss: 10970259456.0000\n",
            "Epoch 136/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10545402880.0000 - val_loss: 10730109952.0000\n",
            "Epoch 137/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10567536640.0000 - val_loss: 10751632384.0000\n",
            "Epoch 138/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10554178560.0000 - val_loss: 10707274752.0000\n",
            "Epoch 139/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10771430400.0000 - val_loss: 10847362048.0000\n",
            "Epoch 140/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10646414336.0000 - val_loss: 10663993344.0000\n",
            "Epoch 141/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10584413184.0000 - val_loss: 10796612608.0000\n",
            "Epoch 142/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10595439616.0000 - val_loss: 10698698752.0000\n",
            "Epoch 143/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 10674648064.0000 - val_loss: 10776236032.0000\n",
            "Epoch 144/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10496569344.0000 - val_loss: 10790418432.0000\n",
            "Epoch 145/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 10517908480.0000 - val_loss: 10744990720.0000\n",
            "Epoch 146/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10616156160.0000 - val_loss: 10780550144.0000\n",
            "Epoch 147/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10810516480.0000 - val_loss: 11069072384.0000\n",
            "Epoch 148/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10837531648.0000 - val_loss: 10795749376.0000\n",
            "Epoch 149/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10768596992.0000 - val_loss: 10940140544.0000\n",
            "Epoch 150/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10901958656.0000 - val_loss: 10745461760.0000\n",
            "Epoch 151/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10518364160.0000 - val_loss: 10785514496.0000\n",
            "Epoch 152/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10448690176.0000 - val_loss: 10860081152.0000\n",
            "Epoch 153/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10466881536.0000 - val_loss: 10751176704.0000\n",
            "Epoch 154/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10542502912.0000 - val_loss: 10749469696.0000\n",
            "Epoch 155/3000\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 10430656512.0000 - val_loss: 10756284416.0000\n",
            "Epoch 156/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10416058368.0000 - val_loss: 10912628736.0000\n",
            "Epoch 157/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10472092672.0000 - val_loss: 10774366208.0000\n",
            "Epoch 158/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10780050432.0000 - val_loss: 11178647552.0000\n",
            "Epoch 159/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10909216768.0000 - val_loss: 10743384064.0000\n",
            "Epoch 160/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 11096167424.0000 - val_loss: 10795527168.0000\n",
            "Epoch 161/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10857817088.0000 - val_loss: 10597081088.0000\n",
            "Epoch 162/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 10606694400.0000 - val_loss: 10701021184.0000\n",
            "Epoch 163/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 11085901824.0000 - val_loss: 10655239168.0000\n",
            "Epoch 164/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10881386496.0000 - val_loss: 10778264576.0000\n",
            "Epoch 165/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10559635456.0000 - val_loss: 10868864000.0000\n",
            "Epoch 166/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10442730496.0000 - val_loss: 10771867648.0000\n",
            "Epoch 167/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10406209536.0000 - val_loss: 10813848576.0000\n",
            "Epoch 168/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10431792128.0000 - val_loss: 10891554816.0000\n",
            "Epoch 169/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 10367043584.0000 - val_loss: 10817707008.0000\n",
            "Epoch 170/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10465522688.0000 - val_loss: 10824690688.0000\n",
            "Epoch 171/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10368461824.0000 - val_loss: 10858438656.0000\n",
            "Epoch 172/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10354341888.0000 - val_loss: 10822394880.0000\n",
            "Epoch 173/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10405504000.0000 - val_loss: 11033695232.0000\n",
            "Epoch 174/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10377631744.0000 - val_loss: 10838946816.0000\n",
            "Epoch 175/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 10379675648.0000 - val_loss: 11075042304.0000\n",
            "Epoch 176/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10364036096.0000 - val_loss: 10843250688.0000\n",
            "Epoch 177/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10556531712.0000 - val_loss: 11001998336.0000\n",
            "Epoch 178/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10446427136.0000 - val_loss: 10765853696.0000\n",
            "Epoch 179/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10308715520.0000 - val_loss: 10988097536.0000\n",
            "Epoch 180/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 10459303936.0000 - val_loss: 10714475520.0000\n",
            "Epoch 181/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10576660480.0000 - val_loss: 10842554368.0000\n",
            "Epoch 182/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 10683451392.0000 - val_loss: 10821243904.0000\n",
            "Epoch 183/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10592364544.0000 - val_loss: 10750086144.0000\n",
            "Epoch 184/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 10432623616.0000 - val_loss: 10752972800.0000\n",
            "Epoch 185/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10410303488.0000 - val_loss: 10794009600.0000\n",
            "Epoch 186/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10508325888.0000 - val_loss: 11067237376.0000\n",
            "Epoch 187/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10516336640.0000 - val_loss: 10698845184.0000\n",
            "Epoch 188/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10477487104.0000 - val_loss: 10943334400.0000\n",
            "Epoch 189/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10261413888.0000 - val_loss: 10808863744.0000\n",
            "Epoch 190/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10310416384.0000 - val_loss: 10908177408.0000\n",
            "Epoch 191/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10244961280.0000 - val_loss: 10835675136.0000\n",
            "Epoch 192/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10485471232.0000 - val_loss: 11065906176.0000\n",
            "Epoch 193/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10240643072.0000 - val_loss: 10806391808.0000\n",
            "Epoch 194/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10355253248.0000 - val_loss: 10783239168.0000\n",
            "Epoch 195/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10239256576.0000 - val_loss: 10759362560.0000\n",
            "Epoch 196/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10175424512.0000 - val_loss: 11193211904.0000\n",
            "Epoch 197/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10188364800.0000 - val_loss: 10802619392.0000\n",
            "Epoch 198/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10370906112.0000 - val_loss: 11139851264.0000\n",
            "Epoch 199/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10275722240.0000 - val_loss: 10746909696.0000\n",
            "Epoch 200/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10330120192.0000 - val_loss: 10975861760.0000\n",
            "Epoch 201/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10169018368.0000 - val_loss: 10840769536.0000\n",
            "Epoch 202/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10163644416.0000 - val_loss: 11037005824.0000\n",
            "Epoch 203/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10221449216.0000 - val_loss: 10724108288.0000\n",
            "Epoch 204/3000\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 10369406976.0000 - val_loss: 11648344064.0000\n",
            "Epoch 205/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10560655360.0000 - val_loss: 10857931776.0000\n",
            "Epoch 206/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10234644480.0000 - val_loss: 11000164352.0000\n",
            "Epoch 207/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10271333376.0000 - val_loss: 11057509376.0000\n",
            "Epoch 208/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10154687488.0000 - val_loss: 10741946368.0000\n",
            "Epoch 209/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10201404416.0000 - val_loss: 10959741952.0000\n",
            "Epoch 210/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10098009088.0000 - val_loss: 10951032832.0000\n",
            "Epoch 211/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 10159480832.0000 - val_loss: 11013979136.0000\n",
            "Epoch 212/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10180459520.0000 - val_loss: 10905938944.0000\n",
            "Epoch 213/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10167204864.0000 - val_loss: 11047953408.0000\n",
            "Epoch 214/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10239629312.0000 - val_loss: 10807006208.0000\n",
            "Epoch 215/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10119334912.0000 - val_loss: 11084227584.0000\n",
            "Epoch 216/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10492516352.0000 - val_loss: 10832934912.0000\n",
            "Epoch 217/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10243339264.0000 - val_loss: 11135550464.0000\n",
            "Epoch 218/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 10086311936.0000 - val_loss: 10802604032.0000\n",
            "Epoch 219/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10193156096.0000 - val_loss: 10793057280.0000\n",
            "Epoch 220/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10110142464.0000 - val_loss: 10788972544.0000\n",
            "Epoch 221/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10224999424.0000 - val_loss: 11101370368.0000\n",
            "Epoch 222/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10064188416.0000 - val_loss: 10753245184.0000\n",
            "Epoch 223/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10059967488.0000 - val_loss: 11183993856.0000\n",
            "Epoch 224/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10065432576.0000 - val_loss: 11156556800.0000\n",
            "Epoch 225/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 10431246336.0000 - val_loss: 10950913024.0000\n",
            "Epoch 226/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10535833600.0000 - val_loss: 11321577472.0000\n",
            "Epoch 227/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10214795264.0000 - val_loss: 10809912320.0000\n",
            "Epoch 228/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10041259008.0000 - val_loss: 11109925888.0000\n",
            "Epoch 229/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10059552768.0000 - val_loss: 11052602368.0000\n",
            "Epoch 230/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10027627520.0000 - val_loss: 11183409152.0000\n",
            "Epoch 231/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10169016320.0000 - val_loss: 10761361408.0000\n",
            "Epoch 232/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 9974451200.0000 - val_loss: 11233097728.0000\n",
            "Epoch 233/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10021018624.0000 - val_loss: 11044878336.0000\n",
            "Epoch 234/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9926723584.0000 - val_loss: 10974393344.0000\n",
            "Epoch 235/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9974895616.0000 - val_loss: 10976498688.0000\n",
            "Epoch 236/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10022882304.0000 - val_loss: 11256228864.0000\n",
            "Epoch 237/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10035525632.0000 - val_loss: 10812623872.0000\n",
            "Epoch 238/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10047788032.0000 - val_loss: 10975768576.0000\n",
            "Epoch 239/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10022303744.0000 - val_loss: 10814850048.0000\n",
            "Epoch 240/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10000327680.0000 - val_loss: 10846356480.0000\n",
            "Epoch 241/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10008396800.0000 - val_loss: 11044168704.0000\n",
            "Epoch 242/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9839579136.0000 - val_loss: 10909669376.0000\n",
            "Epoch 243/3000\n",
            "8/8 [==============================] - 0s 15ms/step - loss: 10100636672.0000 - val_loss: 11516240896.0000\n",
            "Epoch 244/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9911022592.0000 - val_loss: 10710982656.0000\n",
            "Epoch 245/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9926890496.0000 - val_loss: 11464906752.0000\n",
            "Epoch 246/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9929624576.0000 - val_loss: 10828151808.0000\n",
            "Epoch 247/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10123412480.0000 - val_loss: 11798539264.0000\n",
            "Epoch 248/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9983691776.0000 - val_loss: 10836216832.0000\n",
            "Epoch 249/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9962006528.0000 - val_loss: 11505045504.0000\n",
            "Epoch 250/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 10116356096.0000 - val_loss: 10855119872.0000\n",
            "Epoch 251/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9926499328.0000 - val_loss: 10995548160.0000\n",
            "Epoch 252/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10022337536.0000 - val_loss: 11344748544.0000\n",
            "Epoch 253/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9997890560.0000 - val_loss: 10771277824.0000\n",
            "Epoch 254/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 9886721024.0000 - val_loss: 12058790912.0000\n",
            "Epoch 255/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9981942784.0000 - val_loss: 10911434752.0000\n",
            "Epoch 256/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9976744960.0000 - val_loss: 11349433344.0000\n",
            "Epoch 257/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9973240832.0000 - val_loss: 10810492928.0000\n",
            "Epoch 258/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9934965760.0000 - val_loss: 11705902080.0000\n",
            "Epoch 259/3000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 9877265408.0000 - val_loss: 10876953600.0000\n",
            "Epoch 260/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 9746939904.0000 - val_loss: 11399863296.0000\n",
            "Epoch 261/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9827930112.0000 - val_loss: 10968195072.0000\n",
            "Epoch 262/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9762506752.0000 - val_loss: 11883889664.0000\n",
            "Epoch 263/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9794994176.0000 - val_loss: 10933821440.0000\n",
            "Epoch 264/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9767020544.0000 - val_loss: 11565949952.0000\n",
            "Epoch 265/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9865398272.0000 - val_loss: 11014456320.0000\n",
            "Epoch 266/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9721745408.0000 - val_loss: 11211465728.0000\n",
            "Epoch 267/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9851169792.0000 - val_loss: 11173941248.0000\n",
            "Epoch 268/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 9710945280.0000 - val_loss: 11256768512.0000\n",
            "Epoch 269/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9856651264.0000 - val_loss: 10895101952.0000\n",
            "Epoch 270/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 10109053952.0000 - val_loss: 11828071424.0000\n",
            "Epoch 271/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10019051520.0000 - val_loss: 11046423552.0000\n",
            "Epoch 272/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9833333760.0000 - val_loss: 10953740288.0000\n",
            "Epoch 273/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 9641944064.0000 - val_loss: 11388284928.0000\n",
            "Epoch 274/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9820660736.0000 - val_loss: 10982737920.0000\n",
            "Epoch 275/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9808079872.0000 - val_loss: 10875802624.0000\n",
            "Epoch 276/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 9779150848.0000 - val_loss: 11651078144.0000\n",
            "Epoch 277/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9940960256.0000 - val_loss: 10971683840.0000\n",
            "Epoch 278/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9684293632.0000 - val_loss: 10897897472.0000\n",
            "Epoch 279/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9661192192.0000 - val_loss: 11326339072.0000\n",
            "Epoch 280/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9606095872.0000 - val_loss: 10975259648.0000\n",
            "Epoch 281/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9752073216.0000 - val_loss: 10902385664.0000\n",
            "Epoch 282/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 9661520896.0000 - val_loss: 11784867840.0000\n",
            "Epoch 283/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9950431232.0000 - val_loss: 11010048000.0000\n",
            "Epoch 284/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9943369728.0000 - val_loss: 11194334208.0000\n",
            "Epoch 285/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9621448704.0000 - val_loss: 10957864960.0000\n",
            "Epoch 286/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9601686528.0000 - val_loss: 11043394560.0000\n",
            "Epoch 287/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9514141696.0000 - val_loss: 11024080896.0000\n",
            "Epoch 288/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9533688832.0000 - val_loss: 11287004160.0000\n",
            "Epoch 289/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 9572633600.0000 - val_loss: 11220972544.0000\n",
            "Epoch 290/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9722472448.0000 - val_loss: 10856994816.0000\n",
            "Epoch 291/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9635945472.0000 - val_loss: 11387272192.0000\n",
            "Epoch 292/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9517348864.0000 - val_loss: 10807710720.0000\n",
            "Epoch 293/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9744695296.0000 - val_loss: 12018824192.0000\n",
            "Epoch 294/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9845949440.0000 - val_loss: 11000718336.0000\n",
            "Epoch 295/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9442134016.0000 - val_loss: 11335979008.0000\n",
            "Epoch 296/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9602331648.0000 - val_loss: 11894557696.0000\n",
            "Epoch 297/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10174656512.0000 - val_loss: 11033755648.0000\n",
            "Epoch 298/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9769257984.0000 - val_loss: 11713368064.0000\n",
            "Epoch 299/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9512487936.0000 - val_loss: 10839567360.0000\n",
            "Epoch 300/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9668688896.0000 - val_loss: 11101838336.0000\n",
            "Epoch 301/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9530878976.0000 - val_loss: 11125625856.0000\n",
            "Epoch 302/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9541837824.0000 - val_loss: 10853066752.0000\n",
            "Epoch 303/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9624478720.0000 - val_loss: 12087997440.0000\n",
            "Epoch 304/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10460051456.0000 - val_loss: 10892684288.0000\n",
            "Epoch 305/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9473512448.0000 - val_loss: 12009823232.0000\n",
            "Epoch 306/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9421032448.0000 - val_loss: 11032765440.0000\n",
            "Epoch 307/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9518551040.0000 - val_loss: 12808116224.0000\n",
            "Epoch 308/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9495826432.0000 - val_loss: 10996626432.0000\n",
            "Epoch 309/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9784004608.0000 - val_loss: 12510636032.0000\n",
            "Epoch 310/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 9826542592.0000 - val_loss: 10848141312.0000\n",
            "Epoch 311/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9350366208.0000 - val_loss: 11859599360.0000\n",
            "Epoch 312/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9583087616.0000 - val_loss: 10842736640.0000\n",
            "Epoch 313/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9905088512.0000 - val_loss: 12317287424.0000\n",
            "Epoch 314/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9482935296.0000 - val_loss: 10789204992.0000\n",
            "Epoch 315/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9410465792.0000 - val_loss: 12037058560.0000\n",
            "Epoch 316/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9488912384.0000 - val_loss: 10947365888.0000\n",
            "Epoch 317/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 9428989952.0000 - val_loss: 11737024512.0000\n",
            "Epoch 318/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9407209472.0000 - val_loss: 11324738560.0000\n",
            "Epoch 319/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9344015360.0000 - val_loss: 11213570048.0000\n",
            "Epoch 320/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9429658624.0000 - val_loss: 11721264128.0000\n",
            "Epoch 321/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9361408000.0000 - val_loss: 11068685312.0000\n",
            "Epoch 322/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9307300864.0000 - val_loss: 11235302400.0000\n",
            "Epoch 323/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9598855168.0000 - val_loss: 11318702080.0000\n",
            "Epoch 324/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 9418632192.0000 - val_loss: 11568802816.0000\n",
            "Epoch 325/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9342882816.0000 - val_loss: 11352098816.0000\n",
            "Epoch 326/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9345421312.0000 - val_loss: 11252545536.0000\n",
            "Epoch 327/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9280327680.0000 - val_loss: 11507569664.0000\n",
            "Epoch 328/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 9240590336.0000 - val_loss: 11072361472.0000\n",
            "Epoch 329/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9310597120.0000 - val_loss: 11604648960.0000\n",
            "Epoch 330/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9345110016.0000 - val_loss: 11075663872.0000\n",
            "Epoch 331/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9346014208.0000 - val_loss: 11087382528.0000\n",
            "Epoch 332/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9256036352.0000 - val_loss: 11104722944.0000\n",
            "Epoch 333/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9311650816.0000 - val_loss: 11241597952.0000\n",
            "Epoch 334/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9276155904.0000 - val_loss: 10825358336.0000\n",
            "Epoch 335/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9344633856.0000 - val_loss: 12271668224.0000\n",
            "Epoch 336/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 9263618048.0000 - val_loss: 10998616064.0000\n",
            "Epoch 337/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9466434560.0000 - val_loss: 10774667264.0000\n",
            "Epoch 338/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9604206592.0000 - val_loss: 12304287744.0000\n",
            "Epoch 339/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9476446208.0000 - val_loss: 10782577664.0000\n",
            "Epoch 340/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9732593664.0000 - val_loss: 12108928000.0000\n",
            "Epoch 341/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9350113280.0000 - val_loss: 10898910208.0000\n",
            "Epoch 342/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9244224512.0000 - val_loss: 11889020928.0000\n",
            "Epoch 343/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9659482112.0000 - val_loss: 10949052416.0000\n",
            "Epoch 344/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9454827520.0000 - val_loss: 11689523200.0000\n",
            "Epoch 345/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9338780672.0000 - val_loss: 10856609792.0000\n",
            "Epoch 346/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9157839872.0000 - val_loss: 11437115392.0000\n",
            "Epoch 347/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9311525888.0000 - val_loss: 11126932480.0000\n",
            "Epoch 348/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9263343616.0000 - val_loss: 11144712192.0000\n",
            "Epoch 349/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9373809664.0000 - val_loss: 11992304640.0000\n",
            "Epoch 350/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9223498752.0000 - val_loss: 10921543680.0000\n",
            "Epoch 351/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9253088256.0000 - val_loss: 11577666560.0000\n",
            "Epoch 352/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9131124736.0000 - val_loss: 10902709248.0000\n",
            "Epoch 353/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9247699968.0000 - val_loss: 10901048320.0000\n",
            "Epoch 354/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9134332928.0000 - val_loss: 11771905024.0000\n",
            "Epoch 355/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9159641088.0000 - val_loss: 11001243648.0000\n",
            "Epoch 356/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9120358400.0000 - val_loss: 11738230784.0000\n",
            "Epoch 357/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9343168512.0000 - val_loss: 11191591936.0000\n",
            "Epoch 358/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9399954432.0000 - val_loss: 10943925248.0000\n",
            "Epoch 359/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9046219776.0000 - val_loss: 11367325696.0000\n",
            "Epoch 360/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 9003501568.0000 - val_loss: 11086365696.0000\n",
            "Epoch 361/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9102007296.0000 - val_loss: 10949013504.0000\n",
            "Epoch 362/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9072926720.0000 - val_loss: 11285295104.0000\n",
            "Epoch 363/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9058370560.0000 - val_loss: 11215890432.0000\n",
            "Epoch 364/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8948542464.0000 - val_loss: 10976872448.0000\n",
            "Epoch 365/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9142827008.0000 - val_loss: 11944742912.0000\n",
            "Epoch 366/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9131149312.0000 - val_loss: 10860553216.0000\n",
            "Epoch 367/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8985481216.0000 - val_loss: 11192824832.0000\n",
            "Epoch 368/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9189367808.0000 - val_loss: 11567693824.0000\n",
            "Epoch 369/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9001641984.0000 - val_loss: 10900743168.0000\n",
            "Epoch 370/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 9086517248.0000 - val_loss: 11233305600.0000\n",
            "Epoch 371/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9026120704.0000 - val_loss: 11451122688.0000\n",
            "Epoch 372/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8880385024.0000 - val_loss: 11196894208.0000\n",
            "Epoch 373/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8882190336.0000 - val_loss: 11397573632.0000\n",
            "Epoch 374/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9047065600.0000 - val_loss: 10951456768.0000\n",
            "Epoch 375/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9299915776.0000 - val_loss: 12026918912.0000\n",
            "Epoch 376/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9116423168.0000 - val_loss: 10912494592.0000\n",
            "Epoch 377/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9299267584.0000 - val_loss: 10970590208.0000\n",
            "Epoch 378/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9050157056.0000 - val_loss: 12208124928.0000\n",
            "Epoch 379/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9273178112.0000 - val_loss: 11094995968.0000\n",
            "Epoch 380/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9223298048.0000 - val_loss: 12725709824.0000\n",
            "Epoch 381/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9280563200.0000 - val_loss: 10942077952.0000\n",
            "Epoch 382/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8861134848.0000 - val_loss: 11238130688.0000\n",
            "Epoch 383/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9280965632.0000 - val_loss: 11443936256.0000\n",
            "Epoch 384/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8985093120.0000 - val_loss: 11817304064.0000\n",
            "Epoch 385/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8966697984.0000 - val_loss: 10924525568.0000\n",
            "Epoch 386/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8846192640.0000 - val_loss: 11356379136.0000\n",
            "Epoch 387/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8900808704.0000 - val_loss: 11992793088.0000\n",
            "Epoch 388/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9171778560.0000 - val_loss: 10973606912.0000\n",
            "Epoch 389/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9184943104.0000 - val_loss: 11826833408.0000\n",
            "Epoch 390/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9224858624.0000 - val_loss: 11157363712.0000\n",
            "Epoch 391/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9195268096.0000 - val_loss: 12250411008.0000\n",
            "Epoch 392/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8794872832.0000 - val_loss: 10975971328.0000\n",
            "Epoch 393/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8942526464.0000 - val_loss: 12555003904.0000\n",
            "Epoch 394/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 9080949760.0000 - val_loss: 10963688448.0000\n",
            "Epoch 395/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9176609792.0000 - val_loss: 10715930624.0000\n",
            "Epoch 396/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9018477568.0000 - val_loss: 12099573760.0000\n",
            "Epoch 397/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8843986944.0000 - val_loss: 11149830144.0000\n",
            "Epoch 398/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8912019456.0000 - val_loss: 12208014336.0000\n",
            "Epoch 399/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8840473600.0000 - val_loss: 11113984000.0000\n",
            "Epoch 400/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8940696576.0000 - val_loss: 11630927872.0000\n",
            "Epoch 401/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8747911168.0000 - val_loss: 11223575552.0000\n",
            "Epoch 402/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8693998592.0000 - val_loss: 11388938240.0000\n",
            "Epoch 403/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8680586240.0000 - val_loss: 11252176896.0000\n",
            "Epoch 404/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8703009792.0000 - val_loss: 11916350464.0000\n",
            "Epoch 405/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8688083968.0000 - val_loss: 10819619840.0000\n",
            "Epoch 406/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8763610112.0000 - val_loss: 12748589056.0000\n",
            "Epoch 407/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8901500928.0000 - val_loss: 11548039168.0000\n",
            "Epoch 408/3000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 9518004224.0000 - val_loss: 11746369536.0000\n",
            "Epoch 409/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8927498240.0000 - val_loss: 11230472192.0000\n",
            "Epoch 410/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8897925120.0000 - val_loss: 11766338560.0000\n",
            "Epoch 411/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8772360192.0000 - val_loss: 11026827264.0000\n",
            "Epoch 412/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8845423616.0000 - val_loss: 13273028608.0000\n",
            "Epoch 413/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8971806720.0000 - val_loss: 11042021376.0000\n",
            "Epoch 414/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8681692160.0000 - val_loss: 12468083712.0000\n",
            "Epoch 415/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8945051648.0000 - val_loss: 10912690176.0000\n",
            "Epoch 416/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8954334208.0000 - val_loss: 11652285440.0000\n",
            "Epoch 417/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8974901248.0000 - val_loss: 11020068864.0000\n",
            "Epoch 418/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8970885120.0000 - val_loss: 11645706240.0000\n",
            "Epoch 419/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8579150848.0000 - val_loss: 11247458304.0000\n",
            "Epoch 420/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8556731392.0000 - val_loss: 12975736832.0000\n",
            "Epoch 421/3000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 9315447808.0000 - val_loss: 11190195200.0000\n",
            "Epoch 422/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8983534592.0000 - val_loss: 11624246272.0000\n",
            "Epoch 423/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8619173888.0000 - val_loss: 11536312320.0000\n",
            "Epoch 424/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8717247488.0000 - val_loss: 11027036160.0000\n",
            "Epoch 425/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 8705463296.0000 - val_loss: 11661676544.0000\n",
            "Epoch 426/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8609396736.0000 - val_loss: 11369866240.0000\n",
            "Epoch 427/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8477772800.0000 - val_loss: 11680212992.0000\n",
            "Epoch 428/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8735163392.0000 - val_loss: 12030774272.0000\n",
            "Epoch 429/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8906535936.0000 - val_loss: 11676938240.0000\n",
            "Epoch 430/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8513691136.0000 - val_loss: 11748952064.0000\n",
            "Epoch 431/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8775681024.0000 - val_loss: 11322381312.0000\n",
            "Epoch 432/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8782900224.0000 - val_loss: 11476231168.0000\n",
            "Epoch 433/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 8835384320.0000 - val_loss: 12683452416.0000\n",
            "Epoch 434/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8912398336.0000 - val_loss: 11275870208.0000\n",
            "Epoch 435/3000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 9283661824.0000 - val_loss: 14515993600.0000\n",
            "Epoch 436/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9149795328.0000 - val_loss: 11078006784.0000\n",
            "Epoch 437/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 9241769984.0000 - val_loss: 12739141632.0000\n",
            "Epoch 438/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8773073920.0000 - val_loss: 10836235264.0000\n",
            "Epoch 439/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8667924480.0000 - val_loss: 11659357184.0000\n",
            "Epoch 440/3000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 8579661824.0000 - val_loss: 12500281344.0000\n",
            "Epoch 441/3000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 9589153792.0000 - val_loss: 11168454656.0000\n",
            "Epoch 442/3000\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 8577364480.0000 - val_loss: 12999203840.0000\n",
            "Epoch 443/3000\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 8683052032.0000 - val_loss: 11112081408.0000\n",
            "Epoch 444/3000\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 8910772224.0000 - val_loss: 12739633152.0000\n",
            "Epoch 445/3000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 8504477696.0000 - val_loss: 10672796672.0000\n",
            "Epoch 446/3000\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 9056651264.0000 - val_loss: 12193169408.0000\n",
            "Epoch 447/3000\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 9490628608.0000 - val_loss: 11068934144.0000\n",
            "Epoch 448/3000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 8684144640.0000 - val_loss: 12221900800.0000\n",
            "Epoch 449/3000\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 8890748928.0000 - val_loss: 11661316096.0000\n",
            "Epoch 450/3000\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 8624355328.0000 - val_loss: 11305879552.0000\n",
            "Epoch 451/3000\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 8502267392.0000 - val_loss: 11805300736.0000\n",
            "Epoch 452/3000\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 8380982272.0000 - val_loss: 11525403648.0000\n",
            "Epoch 453/3000\n",
            "8/8 [==============================] - 0s 48ms/step - loss: 8341323264.0000 - val_loss: 11711109120.0000\n",
            "Epoch 454/3000\n",
            "8/8 [==============================] - 1s 67ms/step - loss: 8224684032.0000 - val_loss: 11760323584.0000\n",
            "Epoch 455/3000\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 8327839744.0000 - val_loss: 11573058560.0000\n",
            "Epoch 456/3000\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 8235697664.0000 - val_loss: 11873837056.0000\n",
            "Epoch 457/3000\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 8726247424.0000 - val_loss: 15081494528.0000\n",
            "Epoch 458/3000\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 9574651904.0000 - val_loss: 11277472768.0000\n",
            "Epoch 459/3000\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 9235066880.0000 - val_loss: 12536794112.0000\n",
            "Epoch 460/3000\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 8614879232.0000 - val_loss: 10845382656.0000\n",
            "Epoch 461/3000\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 8962029568.0000 - val_loss: 13371623424.0000\n",
            "Epoch 462/3000\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 10066351104.0000 - val_loss: 10821407744.0000\n",
            "Epoch 463/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 10800089088.0000 - val_loss: 11615331328.0000\n",
            "Epoch 464/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9676449792.0000 - val_loss: 11931786240.0000\n",
            "Epoch 465/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9283591168.0000 - val_loss: 10975100928.0000\n",
            "Epoch 466/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8971958272.0000 - val_loss: 11606190080.0000\n",
            "Epoch 467/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8589488128.0000 - val_loss: 11182205952.0000\n",
            "Epoch 468/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8489520128.0000 - val_loss: 11503757312.0000\n",
            "Epoch 469/3000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 8287599616.0000 - val_loss: 11664305152.0000\n",
            "Epoch 470/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8390014464.0000 - val_loss: 11215667200.0000\n",
            "Epoch 471/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8519491072.0000 - val_loss: 11747161088.0000\n",
            "Epoch 472/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 8341845504.0000 - val_loss: 11867959296.0000\n",
            "Epoch 473/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9289248768.0000 - val_loss: 11162772480.0000\n",
            "Epoch 474/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9358163968.0000 - val_loss: 12119533568.0000\n",
            "Epoch 475/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 9020026880.0000 - val_loss: 10669109248.0000\n",
            "Epoch 476/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8514860032.0000 - val_loss: 12462462976.0000\n",
            "Epoch 477/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8995817472.0000 - val_loss: 10976147456.0000\n",
            "Epoch 478/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9129756672.0000 - val_loss: 12936924160.0000\n",
            "Epoch 479/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8611011584.0000 - val_loss: 10748200960.0000\n",
            "Epoch 480/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9009755136.0000 - val_loss: 11491240960.0000\n",
            "Epoch 481/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8503306240.0000 - val_loss: 11081752576.0000\n",
            "Epoch 482/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 8645628928.0000 - val_loss: 12307191808.0000\n",
            "Epoch 483/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8673865728.0000 - val_loss: 11450985472.0000\n",
            "Epoch 484/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8472359424.0000 - val_loss: 11690933248.0000\n",
            "Epoch 485/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8194977280.0000 - val_loss: 11151673344.0000\n",
            "Epoch 486/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8206358528.0000 - val_loss: 12020842496.0000\n",
            "Epoch 487/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8132897792.0000 - val_loss: 12145136640.0000\n",
            "Epoch 488/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8131892736.0000 - val_loss: 11402380288.0000\n",
            "Epoch 489/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7916291584.0000 - val_loss: 12434706432.0000\n",
            "Epoch 490/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8503901696.0000 - val_loss: 11265293312.0000\n",
            "Epoch 491/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8303074816.0000 - val_loss: 12236317696.0000\n",
            "Epoch 492/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8138008064.0000 - val_loss: 11127316480.0000\n",
            "Epoch 493/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8157626880.0000 - val_loss: 11305318400.0000\n",
            "Epoch 494/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8000411136.0000 - val_loss: 11430375424.0000\n",
            "Epoch 495/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7907728896.0000 - val_loss: 12136451072.0000\n",
            "Epoch 496/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 7976849920.0000 - val_loss: 11775173632.0000\n",
            "Epoch 497/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 9492793344.0000 - val_loss: 12997275648.0000\n",
            "Epoch 498/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8342279168.0000 - val_loss: 11363906560.0000\n",
            "Epoch 499/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8170853376.0000 - val_loss: 11275960320.0000\n",
            "Epoch 500/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8156864512.0000 - val_loss: 12883005440.0000\n",
            "Epoch 501/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8443915264.0000 - val_loss: 11026749440.0000\n",
            "Epoch 502/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8006402560.0000 - val_loss: 11836030976.0000\n",
            "Epoch 503/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7841141248.0000 - val_loss: 12479229952.0000\n",
            "Epoch 504/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8013432832.0000 - val_loss: 11346523136.0000\n",
            "Epoch 505/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8052423168.0000 - val_loss: 11731687424.0000\n",
            "Epoch 506/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 8527174144.0000 - val_loss: 12972518400.0000\n",
            "Epoch 507/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8124050944.0000 - val_loss: 10774133760.0000\n",
            "Epoch 508/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 8277259776.0000 - val_loss: 15538163712.0000\n",
            "Epoch 509/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8989754368.0000 - val_loss: 11405998080.0000\n",
            "Epoch 510/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 8359469568.0000 - val_loss: 13085084672.0000\n",
            "Epoch 511/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8704658432.0000 - val_loss: 11403823104.0000\n",
            "Epoch 512/3000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 8068643328.0000 - val_loss: 14071220224.0000\n",
            "Epoch 513/3000\n",
            "8/8 [==============================] - 0s 16ms/step - loss: 8313701376.0000 - val_loss: 11101440000.0000\n",
            "Epoch 514/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 8217146368.0000 - val_loss: 11870705664.0000\n",
            "Epoch 515/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7830130176.0000 - val_loss: 11823080448.0000\n",
            "Epoch 516/3000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 7664708608.0000 - val_loss: 11596521472.0000\n",
            "Epoch 517/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7709687808.0000 - val_loss: 12144646144.0000\n",
            "Epoch 518/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7739579392.0000 - val_loss: 11637073920.0000\n",
            "Epoch 519/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 8205276160.0000 - val_loss: 12029647872.0000\n",
            "Epoch 520/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8110237696.0000 - val_loss: 13722101760.0000\n",
            "Epoch 521/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8089449472.0000 - val_loss: 11328839680.0000\n",
            "Epoch 522/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 8091669504.0000 - val_loss: 11696849920.0000\n",
            "Epoch 523/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7897658368.0000 - val_loss: 12104499200.0000\n",
            "Epoch 524/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7672353280.0000 - val_loss: 11958763520.0000\n",
            "Epoch 525/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7806843392.0000 - val_loss: 12239665152.0000\n",
            "Epoch 526/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7980389888.0000 - val_loss: 12401584128.0000\n",
            "Epoch 527/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7545147392.0000 - val_loss: 12042424320.0000\n",
            "Epoch 528/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7524563456.0000 - val_loss: 12208634880.0000\n",
            "Epoch 529/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 7543268864.0000 - val_loss: 13228912640.0000\n",
            "Epoch 530/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7700557312.0000 - val_loss: 12234606592.0000\n",
            "Epoch 531/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7436105728.0000 - val_loss: 12037098496.0000\n",
            "Epoch 532/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 7525668352.0000 - val_loss: 12304568320.0000\n",
            "Epoch 533/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7718387200.0000 - val_loss: 11496937472.0000\n",
            "Epoch 534/3000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 7671259136.0000 - val_loss: 12612272128.0000\n",
            "Epoch 535/3000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 7629614080.0000 - val_loss: 11612670976.0000\n",
            "Epoch 536/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7974490112.0000 - val_loss: 11686769664.0000\n",
            "Epoch 537/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 7986371072.0000 - val_loss: 12919196672.0000\n",
            "Epoch 538/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8356753920.0000 - val_loss: 13445544960.0000\n",
            "Epoch 539/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8024784896.0000 - val_loss: 11397148672.0000\n",
            "Epoch 540/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7550998528.0000 - val_loss: 12454044672.0000\n",
            "Epoch 541/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7443515392.0000 - val_loss: 12502907904.0000\n",
            "Epoch 542/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 7615938560.0000 - val_loss: 11478397952.0000\n",
            "Epoch 543/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 8019384832.0000 - val_loss: 14349582336.0000\n",
            "Epoch 544/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8342109184.0000 - val_loss: 11569008640.0000\n",
            "Epoch 545/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7900488192.0000 - val_loss: 11622311936.0000\n",
            "Epoch 546/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 9073333248.0000 - val_loss: 13871371264.0000\n",
            "Epoch 547/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8803119104.0000 - val_loss: 10826866688.0000\n",
            "Epoch 548/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8050682368.0000 - val_loss: 11839323136.0000\n",
            "Epoch 549/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 7642993664.0000 - val_loss: 12498712576.0000\n",
            "Epoch 550/3000\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 9077444608.0000 - val_loss: 12009355264.0000\n",
            "Epoch 551/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 9248728064.0000 - val_loss: 13176370176.0000\n",
            "Epoch 552/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8483209728.0000 - val_loss: 11894733824.0000\n",
            "Epoch 553/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 7824080384.0000 - val_loss: 13428836352.0000\n",
            "Epoch 554/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8246898176.0000 - val_loss: 11743110144.0000\n",
            "Epoch 555/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 8879705088.0000 - val_loss: 14486935552.0000\n",
            "Epoch 556/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 8746546176.0000 - val_loss: 10956207104.0000\n",
            "Epoch 557/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7961691136.0000 - val_loss: 13122072576.0000\n",
            "Epoch 558/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7864264704.0000 - val_loss: 11770986496.0000\n",
            "Epoch 559/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7829040128.0000 - val_loss: 13498872832.0000\n",
            "Epoch 560/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7207772672.0000 - val_loss: 12027204608.0000\n",
            "Epoch 561/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7411583488.0000 - val_loss: 12107712512.0000\n",
            "Epoch 562/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7317838336.0000 - val_loss: 11421843456.0000\n",
            "Epoch 563/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7371343360.0000 - val_loss: 11475337216.0000\n",
            "Epoch 564/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7663045632.0000 - val_loss: 15262445568.0000\n",
            "Epoch 565/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 8032370176.0000 - val_loss: 11592435712.0000\n",
            "Epoch 566/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7351463424.0000 - val_loss: 12195008512.0000\n",
            "Epoch 567/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7142074880.0000 - val_loss: 13136959488.0000\n",
            "Epoch 568/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 7205129216.0000 - val_loss: 11966150656.0000\n",
            "Epoch 569/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 6984762880.0000 - val_loss: 12767346688.0000\n",
            "Epoch 570/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 6916125696.0000 - val_loss: 12825183232.0000\n",
            "Epoch 571/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 6881814528.0000 - val_loss: 13033523200.0000\n",
            "Epoch 572/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7083240960.0000 - val_loss: 13154196480.0000\n",
            "Epoch 573/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 6983541760.0000 - val_loss: 12244369408.0000\n",
            "Epoch 574/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7133114368.0000 - val_loss: 12641527808.0000\n",
            "Epoch 575/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 6933192192.0000 - val_loss: 13814551552.0000\n",
            "Epoch 576/3000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 6818876416.0000 - val_loss: 13483828224.0000\n",
            "Epoch 577/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 6763845632.0000 - val_loss: 12300532736.0000\n",
            "Epoch 578/3000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 6957788160.0000 - val_loss: 12530166784.0000\n",
            "Epoch 579/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 6809412608.0000 - val_loss: 14028428288.0000\n",
            "Epoch 580/3000\n",
            "8/8 [==============================] - 0s 19ms/step - loss: 6673840640.0000 - val_loss: 13457087488.0000\n",
            "Epoch 581/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 6894864384.0000 - val_loss: 12491360256.0000\n",
            "Epoch 582/3000\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 7212905472.0000 - val_loss: 13033041920.0000\n",
            "Epoch 583/3000\n",
            "8/8 [==============================] - 0s 20ms/step - loss: 7489905664.0000 - val_loss: 14868746240.0000\n",
            "Epoch 584/3000\n",
            "8/8 [==============================] - 0s 17ms/step - loss: 7308886016.0000 - val_loss: 13031854080.0000\n",
            "Epoch 585/3000\n",
            "8/8 [==============================] - 0s 18ms/step - loss: 6901793792.0000 - val_loss: 13524820992.0000\n",
            "Epoch 586/3000\n",
            "8/8 [==============================] - ETA: 0s - loss: 6956807168.0000Restoring model weights from the end of the best epoch.\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 6956807168.0000 - val_loss: 12639432704.0000\n",
            "Epoch 00586: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=model.evaluate(test_x_scaled,test_y)\n",
        "pred_y=model.predict(test_x_scaled)\n",
        "\n",
        "print('loss: ',loss)\n",
        "print('예상 입장객 수: ', pred_y[-1:])"
      ],
      "metadata": {
        "id": "wuYtJpI78Ldr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "373fe309-c591-4542-9664-faab1a7cecf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 3ms/step - loss: 16140721152.0000\n",
            "loss:  16140721152.0\n",
            "예상 입장객 수:  [[28800.125]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 강수_관측값 예측"
      ],
      "metadata": {
        "id": "SDsFe84lJEDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용 데이터\n",
        "weather.info()\n",
        "\n",
        "# input data\n",
        "weather_input = weather[['강수_관측값',\"기온\", \"습도\", \"체감온도\", \"평균풍속\",\"평균기압\", \"평균수온\", \"평균최대파고\", \"평균파주기\"]]\n",
        "weather_output = weather[['강수_관측값',\"기온\"]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYVOJdACJx1v",
        "outputId": "af2bc5ef-53b8-4acd-ec1c-3124e7804d72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1618 entries, 0 to 1617\n",
            "Data columns (total 10 columns):\n",
            " #   Column  Non-Null Count  Dtype         \n",
            "---  ------  --------------  -----         \n",
            " 0   날짜      1618 non-null   datetime64[ns]\n",
            " 1   강수_관측값  1618 non-null   float64       \n",
            " 2   기온      1618 non-null   float64       \n",
            " 3   습도      1618 non-null   float64       \n",
            " 4   체감온도    1618 non-null   float64       \n",
            " 5   평균풍속    1567 non-null   float64       \n",
            " 6   평균기압    1557 non-null   float64       \n",
            " 7   평균수온    1511 non-null   float64       \n",
            " 8   평균최대파고  1552 non-null   float64       \n",
            " 9   평균파주기   1551 non-null   float64       \n",
            "dtypes: datetime64[ns](1), float64(9)\n",
            "memory usage: 126.5 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 강수_관측값 예측을 위한 train/test split\n",
        "train_x, test_x, train_y, test_y = train_test_split(weather_input.values, weather_output.values, test_size=0.2)"
      ],
      "metadata": {
        "id": "b7jPTgp4Mgf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 강수_관측값 예측을 위한  minmax scaler\n",
        "x_mm_scaler = MinMaxScaler()\n",
        "train_x_scaled = x_mm_scaler.fit_transform(train_x)\n",
        "test_x_scaled = x_mm_scaler.transform(test_x)"
      ],
      "metadata": {
        "id": "_2sTPesjMFi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_scaled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isN-zniuwlD0",
        "outputId": "3d66ace4-abcc-4953-87ba-4463eba6f0f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1294, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_x_scaled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24-JcdGDwtbk",
        "outputId": "8ee5a01c-b1ac-4991-b166-218ef5507874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(324, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 강수_관측값 예측을 위한 data reshape\n",
        "train_x_scaled = train_x_scaled.reshape(-1, 3, 3)\n",
        "train_x_scaled = train_x_scaled.astype(float)\n",
        "test_x_scaled = test_x_scaled.reshape(-1, 3, 3)\n",
        "test_x_scaled = test_x_scaled.astype(float)"
      ],
      "metadata": {
        "id": "1u91b7POLeCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = train_y.astype(float)\n",
        "test_y = test_y.astype(float)"
      ],
      "metadata": {
        "id": "pH6k675I1Cwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 강수_관측값 예측을 위한 lstm 학습\n",
        "model=Sequential()\n",
        "model.add(LSTM(units=128,input_shape=(3,3)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(2))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vCM5bQwLpJA",
        "outputId": "eb9130ef-d9fe-420f-e683-c76e45225c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128)               67584     \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 75,970\n",
            "Trainable params: 75,970\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 진행\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=30, mode='min', verbose=1,restore_best_weights=True)\n",
        "optimizer = optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
        "hist = model.fit(train_x_scaled, train_y, epochs=500, batch_size=32, \n",
        "                validation_split=0.2,\n",
        "                callbacks = [earlyStopping],\n",
        "                verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "FOcJhjgYM_yY",
        "outputId": "17d67ca7-0c5a-4b2c-b7e5-11c3173993e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-3d277c84c2dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 학습 진행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mearlyStopping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'min'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m hist = model.fit(train_x_scaled, train_y, epochs=500, batch_size=32, \n",
            "\u001b[0;31mNameError\u001b[0m: name 'optimizers' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=model.evaluate(test_x_scaled,test_y)\n",
        "pred_y=model.predict(test_x_scaled)\n",
        "\n",
        "print('loss: ',loss)\n",
        "print('예상 강수_관측값,기온 : ', pred_y[-1:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqPThzBMNWkZ",
        "outputId": "df7efe48-1ca3-416f-c08d-e98d003a9e83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11/11 [==============================] - 0s 4ms/step - loss: 176.0946\n",
            "loss:  176.09461975097656\n",
            "예상 강수_관측값,기온 :  [[10.123506 27.850018]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 기온 예측"
      ],
      "metadata": {
        "id": "OgGOQhWUPb8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 사용 데이터\n",
        "weather.info()\n",
        "\n",
        "# input data\n",
        "weather_input = weather[[\"강수_관측값\", \"습도\", \"체감온도\", \"평균수온\", \"평균풍속\", \"평균기압\", \"평균최대파고\", \"평균파주기\"]]\n",
        "weather_output = weather[['기온']]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LvGI5ZSEPc1j",
        "outputId": "a7ecae1e-2a0d-47ac-c020-857e91dbc749"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1486 entries, 0 to 1617\n",
            "Data columns (total 10 columns):\n",
            " #   Column  Non-Null Count  Dtype         \n",
            "---  ------  --------------  -----         \n",
            " 0   날짜      1486 non-null   datetime64[ns]\n",
            " 1   강수_관측값  1486 non-null   float64       \n",
            " 2   기온      1486 non-null   float64       \n",
            " 3   습도      1486 non-null   float64       \n",
            " 4   체감온도    1486 non-null   float64       \n",
            " 5   평균풍속    1486 non-null   float64       \n",
            " 6   평균기압    1486 non-null   float64       \n",
            " 7   평균수온    1486 non-null   float64       \n",
            " 8   평균최대파고  1486 non-null   float64       \n",
            " 9   평균파주기   1486 non-null   float64       \n",
            "dtypes: datetime64[ns](1), float64(9)\n",
            "memory usage: 127.7 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 기온 예측을 위한 train/test split\n",
        "train_x, test_x, train_y, test_y = train_test_split(weather_input.values, weather_output.values, test_size=0.2)"
      ],
      "metadata": {
        "id": "5gqP54sdPkuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기온 예측을 위한  minmax scaler\n",
        "x_mm_scaler = MinMaxScaler()\n",
        "train_x_scaled = x_mm_scaler.fit_transform(train_x)\n",
        "test_x_scaled = x_mm_scaler.transform(test_x)"
      ],
      "metadata": {
        "id": "kWy7O3CtPnwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기온 예측을 위한 data reshape\n",
        "train_x_scaled = train_x_scaled.reshape(-1, 8, 1)\n",
        "test_x_scaled = test_x_scaled.reshape(-1, 8, 1)"
      ],
      "metadata": {
        "id": "ZuACAETSPqdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 기온 예측을 위한 lstm 학습\n",
        "model=Sequential()\n",
        "model.add(LSTM(units=128,input_shape=(8,1)))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsRRfq5GPwHi",
        "outputId": "d5aa8cd6-f340-48c6-cf49-08d7b21071cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_10 (LSTM)               (None, 128)               66560     \n",
            "_________________________________________________________________\n",
            "dense_57 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 74,881\n",
            "Trainable params: 74,881\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 진행\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=20, mode='min', verbose=1,restore_best_weights=True)\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "hist = model.fit(train_x_scaled, train_y, epochs=500, batch_size=16, \n",
        "                validation_split=0.2,\n",
        "                callbacks = [earlyStopping],\n",
        "                verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CksAUHLHPypQ",
        "outputId": "5185b506-f568-40be-9049-67fb80015c7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "60/60 - 6s - loss: 294.8029 - val_loss: 16.9127\n",
            "Epoch 2/500\n",
            "60/60 - 2s - loss: 14.5535 - val_loss: 14.3196\n",
            "Epoch 3/500\n",
            "60/60 - 2s - loss: 14.2070 - val_loss: 14.2903\n",
            "Epoch 4/500\n",
            "60/60 - 2s - loss: 14.2028 - val_loss: 14.9367\n",
            "Epoch 5/500\n",
            "60/60 - 2s - loss: 14.2439 - val_loss: 14.2816\n",
            "Epoch 6/500\n",
            "60/60 - 2s - loss: 14.4665 - val_loss: 14.3856\n",
            "Epoch 7/500\n",
            "60/60 - 2s - loss: 14.2717 - val_loss: 14.2550\n",
            "Epoch 8/500\n",
            "60/60 - 1s - loss: 14.1948 - val_loss: 14.6336\n",
            "Epoch 9/500\n",
            "60/60 - 1s - loss: 14.6506 - val_loss: 14.8402\n",
            "Epoch 10/500\n",
            "60/60 - 1s - loss: 14.4735 - val_loss: 14.4695\n",
            "Epoch 11/500\n",
            "60/60 - 1s - loss: 14.1548 - val_loss: 14.2540\n",
            "Epoch 12/500\n",
            "60/60 - 1s - loss: 14.2216 - val_loss: 14.6555\n",
            "Epoch 13/500\n",
            "60/60 - 1s - loss: 14.4435 - val_loss: 15.0292\n",
            "Epoch 14/500\n",
            "60/60 - 1s - loss: 14.4140 - val_loss: 14.2505\n",
            "Epoch 15/500\n",
            "60/60 - 2s - loss: 14.2542 - val_loss: 14.8203\n",
            "Epoch 16/500\n",
            "60/60 - 1s - loss: 14.3089 - val_loss: 14.4372\n",
            "Epoch 17/500\n",
            "60/60 - 1s - loss: 14.2792 - val_loss: 14.4977\n",
            "Epoch 18/500\n",
            "60/60 - 1s - loss: 14.6326 - val_loss: 14.4881\n",
            "Epoch 19/500\n",
            "60/60 - 1s - loss: 14.2296 - val_loss: 14.2401\n",
            "Epoch 20/500\n",
            "60/60 - 2s - loss: 14.2569 - val_loss: 14.2955\n",
            "Epoch 21/500\n",
            "60/60 - 2s - loss: 14.3089 - val_loss: 14.2875\n",
            "Epoch 22/500\n",
            "60/60 - 2s - loss: 14.3756 - val_loss: 14.7258\n",
            "Epoch 23/500\n",
            "60/60 - 2s - loss: 14.4070 - val_loss: 14.2728\n",
            "Epoch 24/500\n",
            "60/60 - 2s - loss: 14.2930 - val_loss: 14.2233\n",
            "Epoch 25/500\n",
            "60/60 - 2s - loss: 14.3688 - val_loss: 14.3599\n",
            "Epoch 26/500\n",
            "60/60 - 2s - loss: 14.3338 - val_loss: 14.5258\n",
            "Epoch 27/500\n",
            "60/60 - 2s - loss: 14.3556 - val_loss: 14.2242\n",
            "Epoch 28/500\n",
            "60/60 - 2s - loss: 14.2178 - val_loss: 14.2004\n",
            "Epoch 29/500\n",
            "60/60 - 2s - loss: 14.2371 - val_loss: 14.1848\n",
            "Epoch 30/500\n",
            "60/60 - 1s - loss: 14.3229 - val_loss: 14.1223\n",
            "Epoch 31/500\n",
            "60/60 - 1s - loss: 14.5962 - val_loss: 14.7317\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00031: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss=model.evaluate(test_x_scaled,test_y)\n",
        "pred_y=model.predict(test_x_scaled)\n",
        "\n",
        "print('loss: ',loss)\n",
        "print('예상 기온 예측값 : ', pred_y[-1:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fTqhRSyPzyt",
        "outputId": "726ea461-597d-4c88-e173-2e710bada5b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 4ms/step - loss: 12.3377\n",
            "loss:  12.337726593017578\n",
            "예상 기온 예측값 :  [[26.389303]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RPD3Ax6OQIZz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}