{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project_final_doing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YerBmWU2r_Yk",
        "outputId": "36d681ce-d96f-4300-f93c-6b1286100501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# google drive 연동\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, pandas as pd\n",
        "os.chdir('/content/drive/MyDrive/jiwon')\n",
        "\n",
        "weather = pd.read_csv('해운대 날씨.csv')\n",
        "customer = pd.read_csv('해운대 입장객수2.csv')"
      ],
      "metadata": {
        "id": "1Z9yA_dMsmHA"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, Dropout\n",
        "from keras.layers import Bidirectional\n",
        "from tensorflow.keras import optimizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
        "from sklearn.preprocessing import MaxAbsScaler,RobustScaler\n",
        "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "import datetime\n",
        "import time\n",
        "import inspect\n",
        "\n",
        "# 날짜를 date type으로 변경 후, 나머지는 numeric type으로 변경\n",
        "weather['날짜'] = pd.to_datetime(weather['날짜'], infer_datetime_format=True)\n",
        "weather.iloc[:,1:] = weather.iloc[:,1:].apply(pd.to_numeric)\n",
        "\n",
        "customer['방문일'] = pd.to_datetime(customer['방문일'], infer_datetime_format=True)\n",
        "customer['방문객수'] = customer['방문객수'].str.replace(\",\",\"\")\n",
        "customer.iloc[:,1:] = customer.iloc[:,1:].apply(pd.to_numeric)"
      ],
      "metadata": {
        "id": "Otkr69l0tg0t"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 합치기\n",
        "total_data = pd.merge(weather, customer, left_on='날짜', right_on=\"방문일\", how='inner')\n",
        "total_data = total_data[['강수_관측값', \"기온\", \"습도\", \"체감온도\", \"평균수온\", \"평균풍속\", \"평균기압\", \"평균최대파고\", \"평균파주기\", \"방문객수\"]]"
      ],
      "metadata": {
        "id": "MNrTID4vFigs"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측치 평균, 0 채우기\n",
        "total_data.loc[total_data['평균수온'] != total_data['평균수온'], '평균수온'] = total_data['평균수온'].mean()\n",
        "total_data.loc[total_data['평균풍속'] != total_data['평균풍속'], '평균풍속'] = total_data['평균풍속'].mean()\n",
        "total_data.loc[total_data['평균기압'] != total_data['평균기압'], '평균기압'] = total_data['평균기압'].mean()\n",
        "total_data.loc[total_data['평균최대파고'] != total_data['평균최대파고'], '평균최대파고'] = total_data['평균최대파고'].mean()\n",
        "total_data.loc[total_data['평균파주기'] != total_data['평균파주기'], '평균파주기'] = total_data['평균파주기'].mean()\n",
        "total_data.loc[total_data['방문객수'] != total_data['방문객수'], '방문객수'] = total_data['방문객수'].mean()\n",
        "# total_data = total_data.fillna(0)"
      ],
      "metadata": {
        "id": "Z7BIotw9AV1D"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 방문객 수 예측"
      ],
      "metadata": {
        "id": "BjYggYR-JBWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input, output 지정\n",
        "cos_x = total_data[['강수_관측값',\"기온\", \"습도\", \"체감온도\", \"평균수온\", \"평균풍속\", \"평균기압\", \"평균최대파고\", \"평균파주기\",\"방문객수\"]]\n",
        "cos_y = total_data[['방문객수']]"
      ],
      "metadata": {
        "id": "1-sGzI03odaU"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 방문객 수 예측을 위한 train/test split\n",
        "train_x, test_x, train_y, test_y = train_test_split(cos_x,cos_y, test_size=0.2)"
      ],
      "metadata": {
        "id": "f6h_mUXT0eeY"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 방문객 수 예측을 위한 scaler\n",
        "cos_scaler =MinMaxScaler()\n",
        "train_x = cos_scaler.fit_transform(train_x)\n",
        "test_x = cos_scaler.transform(test_x)"
      ],
      "metadata": {
        "id": "VTm66mQo0ecJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x.shape,test_x.shape #((1172, 10), (293, 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ry910jSuBoGw",
        "outputId": "a59e2fee-b21a-4064-8b9f-a99f10bc6800"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1172, 10), (293, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x=train_x.reshape(1172,2,5)\n",
        "test_x=test_x.reshape(293,2,5)"
      ],
      "metadata": {
        "id": "Or1gtkUVC9vI"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x.shape,test_x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIVCdZrIIPln",
        "outputId": "80e0425e-dbb1-4c2c-c104-c09fc3cdba89"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1172, 2, 5), (293, 2, 5))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 모델구성 / 방문객\n",
        "model=Sequential()\n",
        "model.add(LSTM(units=256,input_shape=(2,5),return_sequences=True))\n",
        "model.add(Bidirectional(LSTM(512)))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "t7LEHUe40eZ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c124f7d-aa71-4509-9c7d-ed73e72406af"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_2 (LSTM)               (None, 2, 256)            268288    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 1024)             3149824   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               131200    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,559,681\n",
            "Trainable params: 3,559,681\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 컴파일, 훈련 / 방문객\n",
        "earlyStopping=EarlyStopping(monitor='val_loss',patience=500,mode='min',verbose=1,restore_best_weights=True) \n",
        "model.compile(loss='mse',optimizer='adam')\n",
        "hist=model.fit(train_x,train_y,epochs=3000,batch_size=16,validation_split=0.1, callbacks=[earlyStopping])"
      ],
      "metadata": {
        "id": "z0dtixXcG403",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6464bdcf-2b03-4445-84ba-45b71bc9c779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3000\n",
            "66/66 [==============================] - 19s 136ms/step - loss: 28210241536.0000 - val_loss: 29535270912.0000\n",
            "Epoch 2/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 23497994240.0000 - val_loss: 19825606656.0000\n",
            "Epoch 3/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 14743996416.0000 - val_loss: 16887531520.0000\n",
            "Epoch 4/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 14222627840.0000 - val_loss: 16880852992.0000\n",
            "Epoch 5/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 14215943168.0000 - val_loss: 16886987776.0000\n",
            "Epoch 6/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 13953126400.0000 - val_loss: 16152543232.0000\n",
            "Epoch 7/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 13329133568.0000 - val_loss: 15230189568.0000\n",
            "Epoch 8/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 12418136064.0000 - val_loss: 12663090176.0000\n",
            "Epoch 9/3000\n",
            "66/66 [==============================] - 5s 75ms/step - loss: 7030867456.0000 - val_loss: 5260168192.0000\n",
            "Epoch 10/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 2384721408.0000 - val_loss: 1948797568.0000\n",
            "Epoch 11/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 744454016.0000 - val_loss: 692802432.0000\n",
            "Epoch 12/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 290930368.0000 - val_loss: 260520688.0000\n",
            "Epoch 13/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 192670048.0000 - val_loss: 172118928.0000\n",
            "Epoch 14/3000\n",
            "66/66 [==============================] - 5s 75ms/step - loss: 133900528.0000 - val_loss: 84403752.0000\n",
            "Epoch 15/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 99459600.0000 - val_loss: 76511088.0000\n",
            "Epoch 16/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 73242624.0000 - val_loss: 126813856.0000\n",
            "Epoch 17/3000\n",
            "66/66 [==============================] - 5s 75ms/step - loss: 92421336.0000 - val_loss: 38530220.0000\n",
            "Epoch 18/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 73025816.0000 - val_loss: 30323126.0000\n",
            "Epoch 19/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 35638520.0000 - val_loss: 31271844.0000\n",
            "Epoch 20/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 59086028.0000 - val_loss: 39293372.0000\n",
            "Epoch 21/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 27547798.0000 - val_loss: 23917114.0000\n",
            "Epoch 22/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 26384368.0000 - val_loss: 58662524.0000\n",
            "Epoch 23/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 37403644.0000 - val_loss: 28526098.0000\n",
            "Epoch 24/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 24286958.0000 - val_loss: 26121694.0000\n",
            "Epoch 25/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 20639736.0000 - val_loss: 13134068.0000\n",
            "Epoch 26/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 18696226.0000 - val_loss: 18606522.0000\n",
            "Epoch 27/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 12814064.0000 - val_loss: 33625760.0000\n",
            "Epoch 28/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 20515224.0000 - val_loss: 31667798.0000\n",
            "Epoch 29/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 28615194.0000 - val_loss: 16271960.0000\n",
            "Epoch 30/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 25749128.0000 - val_loss: 22862746.0000\n",
            "Epoch 31/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 28905870.0000 - val_loss: 12619992.0000\n",
            "Epoch 32/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 10370062.0000 - val_loss: 24018198.0000\n",
            "Epoch 33/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 8070857.0000 - val_loss: 11157975.0000\n",
            "Epoch 34/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 11983591.0000 - val_loss: 13017908.0000\n",
            "Epoch 35/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 8408271.0000 - val_loss: 6128865.5000\n",
            "Epoch 36/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 4363353.5000 - val_loss: 5530842.0000\n",
            "Epoch 37/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 8473883.0000 - val_loss: 28727506.0000\n",
            "Epoch 38/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 24163260.0000 - val_loss: 16920578.0000\n",
            "Epoch 39/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 30563944.0000 - val_loss: 87898360.0000\n",
            "Epoch 40/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 49641800.0000 - val_loss: 59449116.0000\n",
            "Epoch 41/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 14192138.0000 - val_loss: 10530995.0000\n",
            "Epoch 42/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 14668648.0000 - val_loss: 11532004.0000\n",
            "Epoch 43/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 7222474.5000 - val_loss: 7609261.5000\n",
            "Epoch 44/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 38410872.0000 - val_loss: 16382781.0000\n",
            "Epoch 45/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 9980700.0000 - val_loss: 10150740.0000\n",
            "Epoch 46/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 9153694.0000 - val_loss: 6269690.5000\n",
            "Epoch 47/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 15947471.0000 - val_loss: 4186030.2500\n",
            "Epoch 48/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 7576653.0000 - val_loss: 9625296.0000\n",
            "Epoch 49/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 16183067.0000 - val_loss: 32354434.0000\n",
            "Epoch 50/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 18032660.0000 - val_loss: 15377628.0000\n",
            "Epoch 51/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 10575377.0000 - val_loss: 21415624.0000\n",
            "Epoch 52/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 11473822.0000 - val_loss: 6440764.0000\n",
            "Epoch 53/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 5738964.0000 - val_loss: 6525753.0000\n",
            "Epoch 54/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 6470057.5000 - val_loss: 11283321.0000\n",
            "Epoch 55/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 4643378.0000 - val_loss: 7118902.0000\n",
            "Epoch 56/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 7640518.0000 - val_loss: 16572112.0000\n",
            "Epoch 57/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 8027344.0000 - val_loss: 6922570.0000\n",
            "Epoch 58/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 22951350.0000 - val_loss: 29199678.0000\n",
            "Epoch 59/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 17468904.0000 - val_loss: 44061804.0000\n",
            "Epoch 60/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 261716208.0000 - val_loss: 1106798336.0000\n",
            "Epoch 61/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 158739136.0000 - val_loss: 24047536.0000\n",
            "Epoch 62/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 14948270.0000 - val_loss: 10821299.0000\n",
            "Epoch 63/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 12037422.0000 - val_loss: 10108429.0000\n",
            "Epoch 64/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 7790031.0000 - val_loss: 6124058.0000\n",
            "Epoch 65/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 4651793.0000 - val_loss: 3633372.2500\n",
            "Epoch 66/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 3650846.2500 - val_loss: 4371536.0000\n",
            "Epoch 67/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 2936609.7500 - val_loss: 6987999.0000\n",
            "Epoch 68/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 2362488.5000 - val_loss: 3156162.2500\n",
            "Epoch 69/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 6382908.5000 - val_loss: 11357891.0000\n",
            "Epoch 70/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 7578809.5000 - val_loss: 10077314.0000\n",
            "Epoch 71/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 8185249.0000 - val_loss: 12306124.0000\n",
            "Epoch 72/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 3358661.0000 - val_loss: 3316872.7500\n",
            "Epoch 73/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 1833901.2500 - val_loss: 3640076.2500\n",
            "Epoch 74/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 1803063.8750 - val_loss: 4708073.0000\n",
            "Epoch 75/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 2431475.2500 - val_loss: 5350431.5000\n",
            "Epoch 76/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 3224611.0000 - val_loss: 3304823.0000\n",
            "Epoch 77/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 2779808.2500 - val_loss: 5447626.0000\n",
            "Epoch 78/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 4565610.5000 - val_loss: 5099365.0000\n",
            "Epoch 79/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 2703676.5000 - val_loss: 3002058.0000\n",
            "Epoch 80/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 15979603.0000 - val_loss: 18311792.0000\n",
            "Epoch 81/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 6033359.0000 - val_loss: 2272139.0000\n",
            "Epoch 82/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 4348330.5000 - val_loss: 5839409.5000\n",
            "Epoch 83/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 2541822.2500 - val_loss: 3637520.0000\n",
            "Epoch 84/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 3445989.2500 - val_loss: 4626607.0000\n",
            "Epoch 85/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 2790983.5000 - val_loss: 8240097.0000\n",
            "Epoch 86/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 1845026.5000 - val_loss: 2793609.7500\n",
            "Epoch 87/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 3659564.2500 - val_loss: 9267996.0000\n",
            "Epoch 88/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 2950603.5000 - val_loss: 5094762.5000\n",
            "Epoch 89/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 3417340.7500 - val_loss: 4834644.5000\n",
            "Epoch 90/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 12639350.0000 - val_loss: 10788273.0000\n",
            "Epoch 91/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 50389696.0000 - val_loss: 26443650.0000\n",
            "Epoch 92/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 13563219.0000 - val_loss: 10989860.0000\n",
            "Epoch 93/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 3226662.5000 - val_loss: 6271616.0000\n",
            "Epoch 94/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 1411027.1250 - val_loss: 5353493.0000\n",
            "Epoch 95/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 5207932.0000 - val_loss: 4013078.0000\n",
            "Epoch 96/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 3170076.7500 - val_loss: 4191406.7500\n",
            "Epoch 97/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 19436086.0000 - val_loss: 40687648.0000\n",
            "Epoch 98/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 36540740.0000 - val_loss: 11480064.0000\n",
            "Epoch 99/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 4596144.0000 - val_loss: 5349267.0000\n",
            "Epoch 100/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 3916263.2500 - val_loss: 5553925.0000\n",
            "Epoch 101/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 85358816.0000 - val_loss: 53395820.0000\n",
            "Epoch 102/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 24068064.0000 - val_loss: 8525872.0000\n",
            "Epoch 103/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 5186100.5000 - val_loss: 5293938.5000\n",
            "Epoch 104/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 1995044.3750 - val_loss: 4905930.0000\n",
            "Epoch 105/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 2918693.2500 - val_loss: 3085878.7500\n",
            "Epoch 106/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 2251501.0000 - val_loss: 2488639.7500\n",
            "Epoch 107/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 2415535.7500 - val_loss: 3609701.2500\n",
            "Epoch 108/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 2154852.0000 - val_loss: 8261503.0000\n",
            "Epoch 109/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 2472909.5000 - val_loss: 3544422.5000\n",
            "Epoch 110/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 10083405.0000 - val_loss: 9362583.0000\n",
            "Epoch 111/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 5431560.0000 - val_loss: 3480750.7500\n",
            "Epoch 112/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 3896431.2500 - val_loss: 3455718.7500\n",
            "Epoch 113/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 2280760.0000 - val_loss: 3817916.5000\n",
            "Epoch 114/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 3233201.7500 - val_loss: 3370529.7500\n",
            "Epoch 115/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 6616445.0000 - val_loss: 2825611.7500\n",
            "Epoch 116/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 4015226.5000 - val_loss: 3469861.7500\n",
            "Epoch 117/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 1221282.5000 - val_loss: 3605651.7500\n",
            "Epoch 118/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 814501.3125 - val_loss: 2222434.7500\n",
            "Epoch 119/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 1063518.0000 - val_loss: 1727981.3750\n",
            "Epoch 120/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 4176019.7500 - val_loss: 8728365.0000\n",
            "Epoch 121/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 1933611.0000 - val_loss: 5108082.5000\n",
            "Epoch 122/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 1536235.2500 - val_loss: 3445696.7500\n",
            "Epoch 123/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 2103508.2500 - val_loss: 9211352.0000\n",
            "Epoch 124/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 9914088.0000 - val_loss: 7450884.5000\n",
            "Epoch 125/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 14121567.0000 - val_loss: 35220120.0000\n",
            "Epoch 126/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 51203612.0000 - val_loss: 82554120.0000\n",
            "Epoch 127/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 32606340.0000 - val_loss: 50455572.0000\n",
            "Epoch 128/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 8273624.5000 - val_loss: 3543356.2500\n",
            "Epoch 129/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 3147120.5000 - val_loss: 4026955.7500\n",
            "Epoch 130/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 5819556.0000 - val_loss: 2602239.7500\n",
            "Epoch 131/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 2157946.0000 - val_loss: 3274030.2500\n",
            "Epoch 132/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 4856576.0000 - val_loss: 5835566.0000\n",
            "Epoch 133/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 5596563.0000 - val_loss: 10289834.0000\n",
            "Epoch 134/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 7018225.5000 - val_loss: 2533380.0000\n",
            "Epoch 135/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 1420827.2500 - val_loss: 2027158.2500\n",
            "Epoch 136/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 2713183.2500 - val_loss: 1931965.8750\n",
            "Epoch 137/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 945223.5625 - val_loss: 2117827.7500\n",
            "Epoch 138/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 1585304.1250 - val_loss: 1739685.5000\n",
            "Epoch 139/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 862993.5625 - val_loss: 2197697.0000\n",
            "Epoch 140/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 12268843.0000 - val_loss: 6022996.0000\n",
            "Epoch 141/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 2952616.5000 - val_loss: 1531631.5000\n",
            "Epoch 142/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 4457850.0000 - val_loss: 2242031.7500\n",
            "Epoch 143/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 1579047.8750 - val_loss: 10544025.0000\n",
            "Epoch 144/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 2888811.7500 - val_loss: 5108983.5000\n",
            "Epoch 145/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 14566636.0000 - val_loss: 16887418.0000\n",
            "Epoch 146/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 24493314.0000 - val_loss: 3446171.0000\n",
            "Epoch 147/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 6583503.5000 - val_loss: 9197773.0000\n",
            "Epoch 148/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 3787249.7500 - val_loss: 6008111.5000\n",
            "Epoch 149/3000\n",
            "66/66 [==============================] - 5s 76ms/step - loss: 1645130.5000 - val_loss: 1524660.2500\n",
            "Epoch 150/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 449531.1250 - val_loss: 8786956.0000\n",
            "Epoch 151/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 4152125.2500 - val_loss: 9954588.0000\n",
            "Epoch 152/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 2100591.0000 - val_loss: 3332133.0000\n",
            "Epoch 153/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 5223070.5000 - val_loss: 4488149.0000\n",
            "Epoch 154/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 4604474.0000 - val_loss: 4192936.7500\n",
            "Epoch 155/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 1755660.1250 - val_loss: 824882.6250\n",
            "Epoch 156/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 2148229.5000 - val_loss: 4649604.0000\n",
            "Epoch 157/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 4851976.5000 - val_loss: 2838073.5000\n",
            "Epoch 158/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 1841747.3750 - val_loss: 2602694.0000\n",
            "Epoch 159/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 9916656.0000 - val_loss: 28536280.0000\n",
            "Epoch 160/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 14029451.0000 - val_loss: 5801752.0000\n",
            "Epoch 161/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 3772737.2500 - val_loss: 5659829.0000\n",
            "Epoch 162/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 3757324.7500 - val_loss: 1914624.1250\n",
            "Epoch 163/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 1445958.8750 - val_loss: 2125818.7500\n",
            "Epoch 164/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 3062187.0000 - val_loss: 4829500.0000\n",
            "Epoch 165/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 4326986.5000 - val_loss: 6245842.5000\n",
            "Epoch 166/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 5459877.0000 - val_loss: 19724962.0000\n",
            "Epoch 167/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 17545824.0000 - val_loss: 2655163.7500\n",
            "Epoch 168/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 3367923.2500 - val_loss: 3643679.2500\n",
            "Epoch 169/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 3397072.7500 - val_loss: 3007673.5000\n",
            "Epoch 170/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 1280283.8750 - val_loss: 3206981.0000\n",
            "Epoch 171/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 973308.0625 - val_loss: 3449757.0000\n",
            "Epoch 172/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 7775328.0000 - val_loss: 26145666.0000\n",
            "Epoch 173/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 8794229.0000 - val_loss: 2483263.2500\n",
            "Epoch 174/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 4313118.0000 - val_loss: 3625319.7500\n",
            "Epoch 175/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 5111037.5000 - val_loss: 1808942.1250\n",
            "Epoch 176/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 1353241.6250 - val_loss: 2393539.7500\n",
            "Epoch 177/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 5878842.5000 - val_loss: 1947323.3750\n",
            "Epoch 178/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 2476587.7500 - val_loss: 6600339.0000\n",
            "Epoch 179/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 14648581.0000 - val_loss: 76541776.0000\n",
            "Epoch 180/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 18110306.0000 - val_loss: 7027973.5000\n",
            "Epoch 181/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 10843123.0000 - val_loss: 6089040.5000\n",
            "Epoch 182/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 3992044.2500 - val_loss: 2154839.5000\n",
            "Epoch 183/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 5423170.5000 - val_loss: 6909302.0000\n",
            "Epoch 184/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 8347277.0000 - val_loss: 4659127.5000\n",
            "Epoch 185/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 3361647.5000 - val_loss: 5664585.0000\n",
            "Epoch 186/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 14429994.0000 - val_loss: 7146931.0000\n",
            "Epoch 187/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 6724724.5000 - val_loss: 10279208.0000\n",
            "Epoch 188/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 2989160.5000 - val_loss: 1970330.5000\n",
            "Epoch 189/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 1607151.1250 - val_loss: 1873730.7500\n",
            "Epoch 190/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 2030624.1250 - val_loss: 3490735.7500\n",
            "Epoch 191/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 2084055.0000 - val_loss: 1906798.1250\n",
            "Epoch 192/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 4260692.5000 - val_loss: 27313276.0000\n",
            "Epoch 193/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 7886794.5000 - val_loss: 5393186.0000\n",
            "Epoch 194/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 1446878.1250 - val_loss: 2087633.1250\n",
            "Epoch 195/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 7150401.5000 - val_loss: 6515269.0000\n",
            "Epoch 196/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 33445394.0000 - val_loss: 17737596.0000\n",
            "Epoch 197/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 9598612.0000 - val_loss: 2295388.0000\n",
            "Epoch 198/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 3961314.7500 - val_loss: 2954758.0000\n",
            "Epoch 199/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 1725555.7500 - val_loss: 2852663.5000\n",
            "Epoch 200/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 1005018.7500 - val_loss: 602845.9375\n",
            "Epoch 201/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 1309485.5000 - val_loss: 4127860.2500\n",
            "Epoch 202/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 574064.3125 - val_loss: 1602483.5000\n",
            "Epoch 203/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 2215388.0000 - val_loss: 3899226.0000\n",
            "Epoch 204/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 2925910.5000 - val_loss: 14715208.0000\n",
            "Epoch 205/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 8000229.0000 - val_loss: 135815824.0000\n",
            "Epoch 206/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 91182784.0000 - val_loss: 5515452.0000\n",
            "Epoch 207/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 3195091.0000 - val_loss: 1869135.0000\n",
            "Epoch 208/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 988406.6875 - val_loss: 3033131.7500\n",
            "Epoch 209/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 847659.4375 - val_loss: 1025826.3125\n",
            "Epoch 210/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 344493.7500 - val_loss: 838245.3750\n",
            "Epoch 211/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 498854.3438 - val_loss: 1528710.5000\n",
            "Epoch 212/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 1392316.7500 - val_loss: 2143542.7500\n",
            "Epoch 213/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 861628.1875 - val_loss: 726921.3125\n",
            "Epoch 214/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 775701.2500 - val_loss: 534017.5625\n",
            "Epoch 215/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 577398.5625 - val_loss: 3633845.0000\n",
            "Epoch 216/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 1370547.7500 - val_loss: 1682185.1250\n",
            "Epoch 217/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 2692816.2500 - val_loss: 1431333.0000\n",
            "Epoch 218/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 3247565.2500 - val_loss: 2423903.2500\n",
            "Epoch 219/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 1451949.1250 - val_loss: 1449185.1250\n",
            "Epoch 220/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 795670.1875 - val_loss: 567482.6875\n",
            "Epoch 221/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 3438590.2500 - val_loss: 2132174.0000\n",
            "Epoch 222/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 4112195.0000 - val_loss: 4228038.0000\n",
            "Epoch 223/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 4632353.5000 - val_loss: 3755790.7500\n",
            "Epoch 224/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 6547227.5000 - val_loss: 1952745.3750\n",
            "Epoch 225/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 2129316.7500 - val_loss: 1743604.5000\n",
            "Epoch 226/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 818082.3125 - val_loss: 845551.9375\n",
            "Epoch 227/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 738560.3125 - val_loss: 1061723.7500\n",
            "Epoch 228/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 2093880.8750 - val_loss: 2739463.0000\n",
            "Epoch 229/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 2367890.5000 - val_loss: 3447385.0000\n",
            "Epoch 230/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 15128907.0000 - val_loss: 5450675.0000\n",
            "Epoch 231/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 3962890.2500 - val_loss: 1060300.8750\n",
            "Epoch 232/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 975737.4375 - val_loss: 1821963.8750\n",
            "Epoch 233/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 1453248.0000 - val_loss: 7284875.5000\n",
            "Epoch 234/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 4712334.0000 - val_loss: 4829043.5000\n",
            "Epoch 235/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 1791405.0000 - val_loss: 1632709.2500\n",
            "Epoch 236/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 1874479.3750 - val_loss: 2213180.2500\n",
            "Epoch 237/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 4142570.7500 - val_loss: 43792968.0000\n",
            "Epoch 238/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 64441076.0000 - val_loss: 14933607.0000\n",
            "Epoch 239/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 10979521.0000 - val_loss: 4415852.0000\n",
            "Epoch 240/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 3143133.0000 - val_loss: 4342325.0000\n",
            "Epoch 241/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 2550082.2500 - val_loss: 2370287.2500\n",
            "Epoch 242/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 1094438.0000 - val_loss: 2150116.5000\n",
            "Epoch 243/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 808479.8750 - val_loss: 2079055.5000\n",
            "Epoch 244/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 409152.7500 - val_loss: 1493648.1250\n",
            "Epoch 245/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 401512.7188 - val_loss: 1447813.7500\n",
            "Epoch 246/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 1405680.8750 - val_loss: 558724.3125\n",
            "Epoch 247/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 549771.1875 - val_loss: 697137.5625\n",
            "Epoch 248/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 657220.1875 - val_loss: 1635058.6250\n",
            "Epoch 249/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 496739.7500 - val_loss: 657586.3750\n",
            "Epoch 250/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 324435.7188 - val_loss: 1858678.8750\n",
            "Epoch 251/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 3259859.5000 - val_loss: 3293751.2500\n",
            "Epoch 252/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 825578.0000 - val_loss: 1294635.5000\n",
            "Epoch 253/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 1025848.5625 - val_loss: 2345891.5000\n",
            "Epoch 254/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 2167365.5000 - val_loss: 2007795.3750\n",
            "Epoch 255/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 2188408.5000 - val_loss: 4644210.0000\n",
            "Epoch 256/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 1463961.8750 - val_loss: 1244528.6250\n",
            "Epoch 257/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 996609.8125 - val_loss: 3031492.2500\n",
            "Epoch 258/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 14402036.0000 - val_loss: 54088036.0000\n",
            "Epoch 259/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 26387098.0000 - val_loss: 40906564.0000\n",
            "Epoch 260/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 11363970.0000 - val_loss: 21530146.0000\n",
            "Epoch 261/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 11973493.0000 - val_loss: 6871724.0000\n",
            "Epoch 262/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 3606900.0000 - val_loss: 2753391.0000\n",
            "Epoch 263/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 2056694.7500 - val_loss: 7660930.5000\n",
            "Epoch 264/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 2127696.7500 - val_loss: 2095347.5000\n",
            "Epoch 265/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 1096402.8750 - val_loss: 1570938.5000\n",
            "Epoch 266/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 1203204.8750 - val_loss: 703174.6250\n",
            "Epoch 267/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 1007339.3125 - val_loss: 1384349.0000\n",
            "Epoch 268/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 1284351.2500 - val_loss: 950823.8125\n",
            "Epoch 269/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 839438.1875 - val_loss: 4110841.0000\n",
            "Epoch 270/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 5094162.5000 - val_loss: 3220397.2500\n",
            "Epoch 271/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 1667538.6250 - val_loss: 434182.0000\n",
            "Epoch 272/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 544707.1875 - val_loss: 494284.3750\n",
            "Epoch 273/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 895067.6875 - val_loss: 508997.1875\n",
            "Epoch 274/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 1054003.1250 - val_loss: 5573518.0000\n",
            "Epoch 275/3000\n",
            "66/66 [==============================] - 5s 77ms/step - loss: 1499214.2500 - val_loss: 1377830.1250\n",
            "Epoch 276/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 870586.2500 - val_loss: 5431326.0000\n",
            "Epoch 277/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 808802.9375 - val_loss: 586681.6875\n",
            "Epoch 278/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 512612.7500 - val_loss: 879176.7500\n",
            "Epoch 279/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 1634033.0000 - val_loss: 2077735.6250\n",
            "Epoch 280/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 3940983.5000 - val_loss: 2991616.2500\n",
            "Epoch 281/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 2409192.7500 - val_loss: 6747445.0000\n",
            "Epoch 282/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 1812825.5000 - val_loss: 2333495.0000\n",
            "Epoch 283/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 4053258.2500 - val_loss: 10282516.0000\n",
            "Epoch 284/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 14753677.0000 - val_loss: 11209040.0000\n",
            "Epoch 285/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 2712090.5000 - val_loss: 1928846.7500\n",
            "Epoch 286/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 3355911.5000 - val_loss: 941081.9375\n",
            "Epoch 287/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 2289202.2500 - val_loss: 1054541.5000\n",
            "Epoch 288/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 12357332.0000 - val_loss: 34082248.0000\n",
            "Epoch 289/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 47873872.0000 - val_loss: 7217788.0000\n",
            "Epoch 290/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 6061480.0000 - val_loss: 4689186.0000\n",
            "Epoch 291/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 1041960.8125 - val_loss: 895207.5000\n",
            "Epoch 292/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 1171815.7500 - val_loss: 1575218.5000\n",
            "Epoch 293/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 1227923.3750 - val_loss: 779213.1250\n",
            "Epoch 294/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 1377855.5000 - val_loss: 2169054.2500\n",
            "Epoch 295/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 1051581.5000 - val_loss: 2876480.2500\n",
            "Epoch 296/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 1732089.6250 - val_loss: 1326391.6250\n",
            "Epoch 297/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 844398.6250 - val_loss: 1830950.0000\n",
            "Epoch 298/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 784662.9375 - val_loss: 438962.4688\n",
            "Epoch 299/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 366955.6250 - val_loss: 553276.3750\n",
            "Epoch 300/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 474310.7188 - val_loss: 1000270.0625\n",
            "Epoch 301/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 311409.7188 - val_loss: 1808460.3750\n",
            "Epoch 302/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 999155.6250 - val_loss: 860605.9375\n",
            "Epoch 303/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 1449358.2500 - val_loss: 3407990.0000\n",
            "Epoch 304/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 3588619.7500 - val_loss: 1725992.6250\n",
            "Epoch 305/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 1448855.1250 - val_loss: 1900523.2500\n",
            "Epoch 306/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 1420146.0000 - val_loss: 5537331.0000\n",
            "Epoch 307/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 18859152.0000 - val_loss: 49565808.0000\n",
            "Epoch 308/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 8000550.5000 - val_loss: 5324084.0000\n",
            "Epoch 309/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 3436188.5000 - val_loss: 15388281.0000\n",
            "Epoch 310/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 4164520.0000 - val_loss: 3065396.0000\n",
            "Epoch 311/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 1534040.7500 - val_loss: 428510.0938\n",
            "Epoch 312/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 812137.8750 - val_loss: 1476199.5000\n",
            "Epoch 313/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 546702.4375 - val_loss: 1135166.2500\n",
            "Epoch 314/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 997431.4375 - val_loss: 862840.7500\n",
            "Epoch 315/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 4698707.0000 - val_loss: 7368708.5000\n",
            "Epoch 316/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 3041021.0000 - val_loss: 1426257.6250\n",
            "Epoch 317/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 3135421.0000 - val_loss: 3660080.0000\n",
            "Epoch 318/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 2439608.7500 - val_loss: 13966384.0000\n",
            "Epoch 319/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 7761106.0000 - val_loss: 7302166.0000\n",
            "Epoch 320/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 6986632.5000 - val_loss: 7815105.0000\n",
            "Epoch 321/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 6138355.0000 - val_loss: 2251647.0000\n",
            "Epoch 322/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 1221733.3750 - val_loss: 889704.1250\n",
            "Epoch 323/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 347769.7812 - val_loss: 1097198.3750\n",
            "Epoch 324/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 481610.3125 - val_loss: 2500866.0000\n",
            "Epoch 325/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 830039.0625 - val_loss: 567814.5625\n",
            "Epoch 326/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 724227.9375 - val_loss: 702208.0000\n",
            "Epoch 327/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 568065.8750 - val_loss: 1029270.7500\n",
            "Epoch 328/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 291808.9062 - val_loss: 715663.2500\n",
            "Epoch 329/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 238211.0938 - val_loss: 928499.4375\n",
            "Epoch 330/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 6647487.5000 - val_loss: 27426584.0000\n",
            "Epoch 331/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 21400834.0000 - val_loss: 6314093.5000\n",
            "Epoch 332/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 2338530.2500 - val_loss: 6846444.0000\n",
            "Epoch 333/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 7125796.5000 - val_loss: 2983632.7500\n",
            "Epoch 334/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 4100481.2500 - val_loss: 7357508.0000\n",
            "Epoch 335/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 5447161.5000 - val_loss: 686249.2500\n",
            "Epoch 336/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 609212.7500 - val_loss: 1255161.7500\n",
            "Epoch 337/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 1041642.1250 - val_loss: 3235544.2500\n",
            "Epoch 338/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 2179443.0000 - val_loss: 1573769.5000\n",
            "Epoch 339/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 1214584.2500 - val_loss: 644580.8750\n",
            "Epoch 340/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 851465.1250 - val_loss: 1050882.2500\n",
            "Epoch 341/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 1005597.1250 - val_loss: 393507.1562\n",
            "Epoch 342/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 2331146.2500 - val_loss: 3558079.0000\n",
            "Epoch 343/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 1140418.0000 - val_loss: 740464.6875\n",
            "Epoch 344/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 437560.4375 - val_loss: 786382.8750\n",
            "Epoch 345/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 2976145.5000 - val_loss: 7974315.0000\n",
            "Epoch 346/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 11035824.0000 - val_loss: 7784887.0000\n",
            "Epoch 347/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 14989637.0000 - val_loss: 7421774.5000\n",
            "Epoch 348/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 10477353.0000 - val_loss: 6492379.0000\n",
            "Epoch 349/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 6242281.5000 - val_loss: 3368809.2500\n",
            "Epoch 350/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 5628229.0000 - val_loss: 1010244.5000\n",
            "Epoch 351/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 2566405.5000 - val_loss: 11626917.0000\n",
            "Epoch 352/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 6874764.0000 - val_loss: 5181444.5000\n",
            "Epoch 353/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 2585151.5000 - val_loss: 1702586.8750\n",
            "Epoch 354/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 2504295.2500 - val_loss: 3777542.2500\n",
            "Epoch 355/3000\n",
            "66/66 [==============================] - 5s 78ms/step - loss: 1947867.3750 - val_loss: 2088695.3750\n",
            "Epoch 356/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 638503.3125 - val_loss: 571857.4375\n",
            "Epoch 357/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 541965.6875 - val_loss: 3024554.2500\n",
            "Epoch 358/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 1339172.0000 - val_loss: 2938352.2500\n",
            "Epoch 359/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 823462.9375 - val_loss: 388237.0938\n",
            "Epoch 360/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 172888.9688 - val_loss: 581059.0000\n",
            "Epoch 361/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 1335405.2500 - val_loss: 1337004.1250\n",
            "Epoch 362/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 2840158.2500 - val_loss: 1710075.3750\n",
            "Epoch 363/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 778276.1875 - val_loss: 1239285.2500\n",
            "Epoch 364/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 2466129.7500 - val_loss: 1182918.7500\n",
            "Epoch 365/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 903926.1250 - val_loss: 676251.0000\n",
            "Epoch 366/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 402456.5000 - val_loss: 1385401.2500\n",
            "Epoch 367/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 1785511.8750 - val_loss: 10991259.0000\n",
            "Epoch 368/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 7633658.0000 - val_loss: 5477970.5000\n",
            "Epoch 369/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 2187285.0000 - val_loss: 1518651.1250\n",
            "Epoch 370/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 1184453.6250 - val_loss: 939460.6250\n",
            "Epoch 371/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 1274963.7500 - val_loss: 2425297.7500\n",
            "Epoch 372/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 1244793.6250 - val_loss: 1184338.5000\n",
            "Epoch 373/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 1199208.8750 - val_loss: 3362150.2500\n",
            "Epoch 374/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 3580918.0000 - val_loss: 1397364.3750\n",
            "Epoch 375/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 9202215.0000 - val_loss: 3258834.0000\n",
            "Epoch 376/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 902123.0625 - val_loss: 2107950.0000\n",
            "Epoch 377/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 850566.6875 - val_loss: 1245254.8750\n",
            "Epoch 378/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 1215643.7500 - val_loss: 1765805.1250\n",
            "Epoch 379/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 8596336.0000 - val_loss: 9313728.0000\n",
            "Epoch 380/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 23381080.0000 - val_loss: 9185989.0000\n",
            "Epoch 381/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 7148338.5000 - val_loss: 2079066.8750\n",
            "Epoch 382/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 3963681.5000 - val_loss: 788618.0625\n",
            "Epoch 383/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 1494485.5000 - val_loss: 883892.8750\n",
            "Epoch 384/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 541596.5000 - val_loss: 1201731.1250\n",
            "Epoch 385/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 739866.3125 - val_loss: 1058107.1250\n",
            "Epoch 386/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 495293.5000 - val_loss: 563376.6250\n",
            "Epoch 387/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 626044.3125 - val_loss: 2136793.2500\n",
            "Epoch 388/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 9836366.0000 - val_loss: 3063066.5000\n",
            "Epoch 389/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 1961725.1250 - val_loss: 3541024.7500\n",
            "Epoch 390/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 1794851.6250 - val_loss: 2186747.5000\n",
            "Epoch 391/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 1037981.0000 - val_loss: 2061504.5000\n",
            "Epoch 392/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 2069231.0000 - val_loss: 2271271.0000\n",
            "Epoch 393/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 1657842.0000 - val_loss: 1594985.7500\n",
            "Epoch 394/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 5619440.5000 - val_loss: 2244151.0000\n",
            "Epoch 395/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 1039396.1875 - val_loss: 1619644.8750\n",
            "Epoch 396/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 320993.9375 - val_loss: 755210.9375\n",
            "Epoch 397/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 1608728.5000 - val_loss: 1038320.8125\n",
            "Epoch 398/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 890060.1875 - val_loss: 4733914.0000\n",
            "Epoch 399/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 1778811.3750 - val_loss: 522594.0625\n",
            "Epoch 400/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 1131066.8750 - val_loss: 1855805.7500\n",
            "Epoch 401/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 657883.9375 - val_loss: 2119725.0000\n",
            "Epoch 402/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 1198246.0000 - val_loss: 611883.7500\n",
            "Epoch 403/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 377766.8438 - val_loss: 518212.3125\n",
            "Epoch 404/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 3505097.5000 - val_loss: 6466598.0000\n",
            "Epoch 405/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 6402376.0000 - val_loss: 2686025.0000\n",
            "Epoch 406/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 5060372.0000 - val_loss: 9547094.0000\n",
            "Epoch 407/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 5708177.0000 - val_loss: 7919717.0000\n",
            "Epoch 408/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 7128093.0000 - val_loss: 8613468.0000\n",
            "Epoch 409/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 9554600.0000 - val_loss: 1298456.0000\n",
            "Epoch 410/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 2865586.2500 - val_loss: 1394987.2500\n",
            "Epoch 411/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 2022762.7500 - val_loss: 3696513.2500\n",
            "Epoch 412/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 1266178.3750 - val_loss: 962399.3125\n",
            "Epoch 413/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 2894146.7500 - val_loss: 3756067.5000\n",
            "Epoch 414/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 1581695.7500 - val_loss: 392801.3125\n",
            "Epoch 415/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 805511.6250 - val_loss: 1227409.5000\n",
            "Epoch 416/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 808090.0000 - val_loss: 1848332.7500\n",
            "Epoch 417/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 6692579.0000 - val_loss: 3533333.7500\n",
            "Epoch 418/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 6623695.0000 - val_loss: 3906405.7500\n",
            "Epoch 419/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 15001045.0000 - val_loss: 20518500.0000\n",
            "Epoch 420/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 19543196.0000 - val_loss: 19239504.0000\n",
            "Epoch 421/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 13922641.0000 - val_loss: 2192875.0000\n",
            "Epoch 422/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 2257965.5000 - val_loss: 8087001.5000\n",
            "Epoch 423/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 2433328.0000 - val_loss: 1250817.5000\n",
            "Epoch 424/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 465227.2500 - val_loss: 764908.6875\n",
            "Epoch 425/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 244583.0312 - val_loss: 266968.5312\n",
            "Epoch 426/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 321888.3750 - val_loss: 403543.2188\n",
            "Epoch 427/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 240936.1094 - val_loss: 537071.4375\n",
            "Epoch 428/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 517787.3750 - val_loss: 1221379.2500\n",
            "Epoch 429/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 572249.6250 - val_loss: 971765.6250\n",
            "Epoch 430/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 658128.1250 - val_loss: 576486.3750\n",
            "Epoch 431/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 538236.1875 - val_loss: 751262.2500\n",
            "Epoch 432/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 844483.8750 - val_loss: 449624.4062\n",
            "Epoch 433/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 264414.2500 - val_loss: 331081.4375\n",
            "Epoch 434/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 473152.6562 - val_loss: 1450433.3750\n",
            "Epoch 435/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 411930.6250 - val_loss: 890334.6250\n",
            "Epoch 436/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 536340.3125 - val_loss: 1101634.8750\n",
            "Epoch 437/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 345612.7188 - val_loss: 912881.9375\n",
            "Epoch 438/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 2990320.2500 - val_loss: 16144549.0000\n",
            "Epoch 439/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 2973046.5000 - val_loss: 3316355.7500\n",
            "Epoch 440/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 5383969.0000 - val_loss: 9079625.0000\n",
            "Epoch 441/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 19745584.0000 - val_loss: 10331969.0000\n",
            "Epoch 442/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 10134122.0000 - val_loss: 26555182.0000\n",
            "Epoch 443/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 7095427.0000 - val_loss: 1929350.1250\n",
            "Epoch 444/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 3739134.2500 - val_loss: 2628284.0000\n",
            "Epoch 445/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 1118631.2500 - val_loss: 685012.3125\n",
            "Epoch 446/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 349701.8125 - val_loss: 727070.6250\n",
            "Epoch 447/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 307638.5000 - val_loss: 1181724.3750\n",
            "Epoch 448/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 302868.9688 - val_loss: 503475.3125\n",
            "Epoch 449/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 432496.7812 - val_loss: 757045.7500\n",
            "Epoch 450/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 277213.7188 - val_loss: 361879.2188\n",
            "Epoch 451/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 1041508.9375 - val_loss: 1197499.0000\n",
            "Epoch 452/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 541235.1875 - val_loss: 446982.2188\n",
            "Epoch 453/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 1942943.8750 - val_loss: 2464441.7500\n",
            "Epoch 454/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 970590.1250 - val_loss: 682760.6250\n",
            "Epoch 455/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 3187972.7500 - val_loss: 4541523.5000\n",
            "Epoch 456/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 4296625.0000 - val_loss: 4034436.0000\n",
            "Epoch 457/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 7002083.0000 - val_loss: 792438.5625\n",
            "Epoch 458/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 634111.0625 - val_loss: 274855.0000\n",
            "Epoch 459/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 455497.8750 - val_loss: 836268.3125\n",
            "Epoch 460/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 720878.2500 - val_loss: 935808.0000\n",
            "Epoch 461/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 610677.6875 - val_loss: 401189.9688\n",
            "Epoch 462/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 1216211.2500 - val_loss: 525213.1250\n",
            "Epoch 463/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 1971373.8750 - val_loss: 1364445.2500\n",
            "Epoch 464/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 1293071.7500 - val_loss: 1643188.2500\n",
            "Epoch 465/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 3012421.2500 - val_loss: 1188857.1250\n",
            "Epoch 466/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 4967384.0000 - val_loss: 12945469.0000\n",
            "Epoch 467/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 16033912.0000 - val_loss: 12315420.0000\n",
            "Epoch 468/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 17721322.0000 - val_loss: 19739616.0000\n",
            "Epoch 469/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 5617216.0000 - val_loss: 1906361.0000\n",
            "Epoch 470/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 1652337.2500 - val_loss: 1390074.5000\n",
            "Epoch 471/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 1177153.7500 - val_loss: 541887.2500\n",
            "Epoch 472/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 527970.4375 - val_loss: 2217392.2500\n",
            "Epoch 473/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 797975.6250 - val_loss: 476460.0000\n",
            "Epoch 474/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 454585.2188 - val_loss: 424392.1250\n",
            "Epoch 475/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 287310.1875 - val_loss: 320328.3438\n",
            "Epoch 476/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 250945.9219 - val_loss: 663540.0000\n",
            "Epoch 477/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 515898.4688 - val_loss: 531372.3125\n",
            "Epoch 478/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 1187304.3750 - val_loss: 1695200.8750\n",
            "Epoch 479/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 965373.8125 - val_loss: 1948677.2500\n",
            "Epoch 480/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 380041.3750 - val_loss: 969464.7500\n",
            "Epoch 481/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 648584.2500 - val_loss: 344698.6562\n",
            "Epoch 482/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 204721.8438 - val_loss: 345714.0312\n",
            "Epoch 483/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 367885.2188 - val_loss: 1042322.7500\n",
            "Epoch 484/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 1093733.2500 - val_loss: 1226917.8750\n",
            "Epoch 485/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 2606846.7500 - val_loss: 1181710.2500\n",
            "Epoch 486/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 1832107.2500 - val_loss: 292384.8750\n",
            "Epoch 487/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 278901.1250 - val_loss: 312843.5312\n",
            "Epoch 488/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 1032425.7500 - val_loss: 4306822.5000\n",
            "Epoch 489/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 1509698.1250 - val_loss: 926385.0000\n",
            "Epoch 490/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 2086286.1250 - val_loss: 12817231.0000\n",
            "Epoch 491/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 114667704.0000 - val_loss: 236296224.0000\n",
            "Epoch 492/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 114835416.0000 - val_loss: 10878288.0000\n",
            "Epoch 493/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 4485274.5000 - val_loss: 2759399.5000\n",
            "Epoch 494/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 1318098.8750 - val_loss: 733359.0000\n",
            "Epoch 495/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 1286268.7500 - val_loss: 2406171.0000\n",
            "Epoch 496/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 955902.2500 - val_loss: 681368.5000\n",
            "Epoch 497/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 346018.2812 - val_loss: 851431.0625\n",
            "Epoch 498/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 328069.9375 - val_loss: 666516.4375\n",
            "Epoch 499/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 391822.0938 - val_loss: 931669.3125\n",
            "Epoch 500/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 242587.1094 - val_loss: 524075.7188\n",
            "Epoch 501/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 270787.5312 - val_loss: 385196.6875\n",
            "Epoch 502/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 267498.5625 - val_loss: 1079958.8750\n",
            "Epoch 503/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 325810.9688 - val_loss: 553265.8750\n",
            "Epoch 504/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 206687.5000 - val_loss: 392095.4688\n",
            "Epoch 505/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 210827.9531 - val_loss: 573091.8125\n",
            "Epoch 506/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 219227.8750 - val_loss: 598409.1250\n",
            "Epoch 507/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 526392.8750 - val_loss: 572567.4375\n",
            "Epoch 508/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 178801.4062 - val_loss: 440433.2500\n",
            "Epoch 509/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 437128.0312 - val_loss: 983935.8750\n",
            "Epoch 510/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 352740.0312 - val_loss: 491734.3125\n",
            "Epoch 511/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 206228.6250 - val_loss: 280092.8750\n",
            "Epoch 512/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 343104.3750 - val_loss: 505962.7500\n",
            "Epoch 513/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 244204.2188 - val_loss: 417485.8438\n",
            "Epoch 514/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 219816.4531 - val_loss: 696291.8750\n",
            "Epoch 515/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 188966.3125 - val_loss: 273000.7500\n",
            "Epoch 516/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 250494.5000 - val_loss: 669010.4375\n",
            "Epoch 517/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 1724938.1250 - val_loss: 2059272.5000\n",
            "Epoch 518/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 1009348.1250 - val_loss: 1237926.7500\n",
            "Epoch 519/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 811194.0000 - val_loss: 998228.6875\n",
            "Epoch 520/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 325463.8125 - val_loss: 1127232.5000\n",
            "Epoch 521/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 284229.6250 - val_loss: 1255566.7500\n",
            "Epoch 522/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 411178.2500 - val_loss: 487113.6250\n",
            "Epoch 523/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 333517.9375 - val_loss: 613599.6875\n",
            "Epoch 524/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 229017.1250 - val_loss: 904855.2500\n",
            "Epoch 525/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 426454.9062 - val_loss: 757684.1250\n",
            "Epoch 526/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 966719.3750 - val_loss: 2249086.2500\n",
            "Epoch 527/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 489501.8125 - val_loss: 1026531.2500\n",
            "Epoch 528/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 560888.3750 - val_loss: 2433297.7500\n",
            "Epoch 529/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 1327838.7500 - val_loss: 407562.1562\n",
            "Epoch 530/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 4024994.7500 - val_loss: 14350915.0000\n",
            "Epoch 531/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 3863598.2500 - val_loss: 6010696.5000\n",
            "Epoch 532/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 4084672.7500 - val_loss: 19291624.0000\n",
            "Epoch 533/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 51290508.0000 - val_loss: 34304912.0000\n",
            "Epoch 534/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 6194371.0000 - val_loss: 1495174.6250\n",
            "Epoch 535/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 1030916.1250 - val_loss: 1140146.0000\n",
            "Epoch 536/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 1031633.1250 - val_loss: 717179.6875\n",
            "Epoch 537/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 653400.6875 - val_loss: 1246138.7500\n",
            "Epoch 538/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 477185.0312 - val_loss: 364645.5938\n",
            "Epoch 539/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 507638.8438 - val_loss: 863865.8125\n",
            "Epoch 540/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 361085.5625 - val_loss: 365378.7812\n",
            "Epoch 541/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 211559.9375 - val_loss: 347545.1250\n",
            "Epoch 542/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 328365.4375 - val_loss: 379218.2812\n",
            "Epoch 543/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 375094.7812 - val_loss: 809268.2500\n",
            "Epoch 544/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 567927.6250 - val_loss: 507900.6562\n",
            "Epoch 545/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 551343.7500 - val_loss: 785945.0000\n",
            "Epoch 546/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 1644499.6250 - val_loss: 7843085.0000\n",
            "Epoch 547/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 17277110.0000 - val_loss: 2114459.2500\n",
            "Epoch 548/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 965263.3125 - val_loss: 958230.7500\n",
            "Epoch 549/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 823677.0000 - val_loss: 629649.3750\n",
            "Epoch 550/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 377234.4688 - val_loss: 478222.9375\n",
            "Epoch 551/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 1917691.8750 - val_loss: 1503225.7500\n",
            "Epoch 552/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 765880.0625 - val_loss: 1392826.6250\n",
            "Epoch 553/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 574124.2500 - val_loss: 931178.3125\n",
            "Epoch 554/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 286631.0000 - val_loss: 424342.2188\n",
            "Epoch 555/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 237632.6406 - val_loss: 381237.0938\n",
            "Epoch 556/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 199698.2500 - val_loss: 292008.9062\n",
            "Epoch 557/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 408967.7500 - val_loss: 1278513.8750\n",
            "Epoch 558/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 256752.7656 - val_loss: 794895.7500\n",
            "Epoch 559/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 441919.1875 - val_loss: 2183607.5000\n",
            "Epoch 560/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 643649.1250 - val_loss: 387412.4688\n",
            "Epoch 561/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 366432.9688 - val_loss: 495501.4375\n",
            "Epoch 562/3000\n",
            "66/66 [==============================] - 5s 80ms/step - loss: 886887.1250 - val_loss: 375055.5938\n",
            "Epoch 563/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 370496.1562 - val_loss: 2744151.7500\n",
            "Epoch 564/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 796835.8125 - val_loss: 830447.0000\n",
            "Epoch 565/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 5417010.5000 - val_loss: 42043376.0000\n",
            "Epoch 566/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 19065994.0000 - val_loss: 10554900.0000\n",
            "Epoch 567/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 7731713.5000 - val_loss: 2499624.5000\n",
            "Epoch 568/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 3909488.7500 - val_loss: 1594597.3750\n",
            "Epoch 569/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 1042542.8750 - val_loss: 757149.9375\n",
            "Epoch 570/3000\n",
            "66/66 [==============================] - 7s 106ms/step - loss: 1506392.7500 - val_loss: 2342976.7500\n",
            "Epoch 571/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 5170017.0000 - val_loss: 2091555.0000\n",
            "Epoch 572/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 2439800.5000 - val_loss: 2279260.0000\n",
            "Epoch 573/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 2430026.2500 - val_loss: 1340427.2500\n",
            "Epoch 574/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 1026358.6250 - val_loss: 665642.6875\n",
            "Epoch 575/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 350786.0625 - val_loss: 299137.2500\n",
            "Epoch 576/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 308687.0312 - val_loss: 389712.9062\n",
            "Epoch 577/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 1295147.7500 - val_loss: 1038045.3750\n",
            "Epoch 578/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 786218.6875 - val_loss: 564589.9375\n",
            "Epoch 579/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 1006292.6875 - val_loss: 1399905.1250\n",
            "Epoch 580/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 2035262.3750 - val_loss: 2160762.0000\n",
            "Epoch 581/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 736087.0625 - val_loss: 764735.9375\n",
            "Epoch 582/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 641110.3750 - val_loss: 1865820.3750\n",
            "Epoch 583/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 1247216.5000 - val_loss: 358772.3438\n",
            "Epoch 584/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 1878200.6250 - val_loss: 2465574.7500\n",
            "Epoch 585/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 2387965.7500 - val_loss: 4065374.0000\n",
            "Epoch 586/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 3223397.7500 - val_loss: 4279562.0000\n",
            "Epoch 587/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 4294715.0000 - val_loss: 684787.1250\n",
            "Epoch 588/3000\n",
            "66/66 [==============================] - 5s 79ms/step - loss: 434372.1875 - val_loss: 505103.7812\n",
            "Epoch 589/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 834785.6875 - val_loss: 472372.9375\n",
            "Epoch 590/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 992103.3125 - val_loss: 1141372.7500\n",
            "Epoch 591/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 858426.8125 - val_loss: 996636.0625\n",
            "Epoch 592/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 5481405.5000 - val_loss: 2836310.5000\n",
            "Epoch 593/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 1028329.0625 - val_loss: 1128818.3750\n",
            "Epoch 594/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 2719373.2500 - val_loss: 1845950.0000\n",
            "Epoch 595/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 4150079.2500 - val_loss: 2083606.7500\n",
            "Epoch 596/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 9994348.0000 - val_loss: 4572410.5000\n",
            "Epoch 597/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 8359284.0000 - val_loss: 2729675.7500\n",
            "Epoch 598/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 1013932.0625 - val_loss: 877187.1250\n",
            "Epoch 599/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 574561.6875 - val_loss: 2754019.2500\n",
            "Epoch 600/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 1233781.0000 - val_loss: 1693325.7500\n",
            "Epoch 601/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 867349.8750 - val_loss: 642021.0625\n",
            "Epoch 602/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 437630.9375 - val_loss: 515668.5000\n",
            "Epoch 603/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 710433.0625 - val_loss: 3925386.2500\n",
            "Epoch 604/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 2952118.2500 - val_loss: 1871452.3750\n",
            "Epoch 605/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 1892683.1250 - val_loss: 939297.5625\n",
            "Epoch 606/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 769971.1875 - val_loss: 527058.9375\n",
            "Epoch 607/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 644238.8125 - val_loss: 2887219.5000\n",
            "Epoch 608/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 866395.1250 - val_loss: 834681.0000\n",
            "Epoch 609/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 684349.2500 - val_loss: 488030.7812\n",
            "Epoch 610/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 628940.3750 - val_loss: 2907183.2500\n",
            "Epoch 611/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 2460554.2500 - val_loss: 1848452.8750\n",
            "Epoch 612/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 3124424.2500 - val_loss: 2900479.2500\n",
            "Epoch 613/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 4341302.0000 - val_loss: 777072.2500\n",
            "Epoch 614/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 3664829.2500 - val_loss: 723298.5625\n",
            "Epoch 615/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 4370158.0000 - val_loss: 2986146.0000\n",
            "Epoch 616/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 1866425.2500 - val_loss: 2204739.5000\n",
            "Epoch 617/3000\n",
            "66/66 [==============================] - 7s 107ms/step - loss: 1846187.5000 - val_loss: 5699115.0000\n",
            "Epoch 618/3000\n",
            "66/66 [==============================] - 7s 98ms/step - loss: 2813522.0000 - val_loss: 2608146.0000\n",
            "Epoch 619/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 1862161.2500 - val_loss: 805304.1875\n",
            "Epoch 620/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 673531.5000 - val_loss: 751380.9375\n",
            "Epoch 621/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 254078.5156 - val_loss: 261356.5938\n",
            "Epoch 622/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 241903.4688 - val_loss: 393282.0312\n",
            "Epoch 623/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 470657.9688 - val_loss: 1022035.8125\n",
            "Epoch 624/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 430134.7500 - val_loss: 471812.6562\n",
            "Epoch 625/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 522204.4062 - val_loss: 2089546.0000\n",
            "Epoch 626/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 3581891.2500 - val_loss: 2603228.2500\n",
            "Epoch 627/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 6058019.0000 - val_loss: 11088769.0000\n",
            "Epoch 628/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 3369741.5000 - val_loss: 1900278.3750\n",
            "Epoch 629/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 2064625.0000 - val_loss: 5315921.0000\n",
            "Epoch 630/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 4720065.0000 - val_loss: 3107870.7500\n",
            "Epoch 631/3000\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 568289.0000 - val_loss: 466934.3750\n",
            "Epoch 632/3000\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 381213.9688 - val_loss: 444869.2812\n",
            "Epoch 633/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 303397.7500 - val_loss: 767525.8125\n",
            "Epoch 634/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 899090.3750 - val_loss: 644580.1250\n",
            "Epoch 635/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 1430889.8750 - val_loss: 1483108.2500\n",
            "Epoch 636/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 424601.4062 - val_loss: 1149474.8750\n",
            "Epoch 637/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 850593.3750 - val_loss: 441947.2188\n",
            "Epoch 638/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 175442.9375 - val_loss: 400635.4375\n",
            "Epoch 639/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 141824.2188 - val_loss: 1294619.8750\n",
            "Epoch 640/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 1278722.7500 - val_loss: 1940117.5000\n",
            "Epoch 641/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 4343621.5000 - val_loss: 11112150.0000\n",
            "Epoch 642/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 10460966.0000 - val_loss: 11183202.0000\n",
            "Epoch 643/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 11354092.0000 - val_loss: 1892922.6250\n",
            "Epoch 644/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 3782249.7500 - val_loss: 1361505.7500\n",
            "Epoch 645/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 670201.3750 - val_loss: 489329.1562\n",
            "Epoch 646/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 661394.7500 - val_loss: 158490.5781\n",
            "Epoch 647/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 960896.1875 - val_loss: 8118496.5000\n",
            "Epoch 648/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 11821522.0000 - val_loss: 1593127.1250\n",
            "Epoch 649/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 9520903.0000 - val_loss: 3690888.7500\n",
            "Epoch 650/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 1121649.5000 - val_loss: 706585.0625\n",
            "Epoch 651/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 805487.6875 - val_loss: 293227.0312\n",
            "Epoch 652/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 273916.4062 - val_loss: 344079.9062\n",
            "Epoch 653/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 182101.5000 - val_loss: 588652.2500\n",
            "Epoch 654/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 241899.7969 - val_loss: 332747.5625\n",
            "Epoch 655/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 358843.5312 - val_loss: 821480.6250\n",
            "Epoch 656/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 1161586.5000 - val_loss: 633971.2500\n",
            "Epoch 657/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 2232210.2500 - val_loss: 25425394.0000\n",
            "Epoch 658/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 6834214.0000 - val_loss: 1752182.1250\n",
            "Epoch 659/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 2713709.0000 - val_loss: 8085575.5000\n",
            "Epoch 660/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 10325640.0000 - val_loss: 2749734.7500\n",
            "Epoch 661/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 1570752.1250 - val_loss: 3722085.5000\n",
            "Epoch 662/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 1469859.0000 - val_loss: 1596584.0000\n",
            "Epoch 663/3000\n",
            "66/66 [==============================] - 7s 107ms/step - loss: 516628.5312 - val_loss: 1386962.8750\n",
            "Epoch 664/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 265766.8438 - val_loss: 291833.9062\n",
            "Epoch 665/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 377907.6875 - val_loss: 1666348.5000\n",
            "Epoch 666/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 723365.3750 - val_loss: 534198.5000\n",
            "Epoch 667/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 1209909.0000 - val_loss: 1950015.3750\n",
            "Epoch 668/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 1606153.7500 - val_loss: 2080796.8750\n",
            "Epoch 669/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 620359.5000 - val_loss: 396464.2500\n",
            "Epoch 670/3000\n",
            "66/66 [==============================] - 7s 106ms/step - loss: 470057.1250 - val_loss: 448574.1250\n",
            "Epoch 671/3000\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 974040.8750 - val_loss: 842352.2500\n",
            "Epoch 672/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 1506172.2500 - val_loss: 695959.3750\n",
            "Epoch 673/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 783029.8125 - val_loss: 4646820.5000\n",
            "Epoch 674/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 4088215.0000 - val_loss: 15309282.0000\n",
            "Epoch 675/3000\n",
            "66/66 [==============================] - 7s 109ms/step - loss: 3997677.5000 - val_loss: 1010953.2500\n",
            "Epoch 676/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 538230.0625 - val_loss: 831538.0625\n",
            "Epoch 677/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 278455.0312 - val_loss: 349407.2812\n",
            "Epoch 678/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 219681.0625 - val_loss: 517294.9375\n",
            "Epoch 679/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 1756945.8750 - val_loss: 988917.5000\n",
            "Epoch 680/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 1220278.2500 - val_loss: 951675.1250\n",
            "Epoch 681/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 1079241.1250 - val_loss: 1398666.8750\n",
            "Epoch 682/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 7768034.5000 - val_loss: 32500614.0000\n",
            "Epoch 683/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 27054246.0000 - val_loss: 16432657.0000\n",
            "Epoch 684/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 11338103.0000 - val_loss: 5060151.5000\n",
            "Epoch 685/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 1227048.7500 - val_loss: 461330.0938\n",
            "Epoch 686/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 387349.7812 - val_loss: 386483.7188\n",
            "Epoch 687/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 203889.5469 - val_loss: 476968.6875\n",
            "Epoch 688/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 471966.2500 - val_loss: 361300.0312\n",
            "Epoch 689/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 271781.4062 - val_loss: 315274.1562\n",
            "Epoch 690/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 168151.7500 - val_loss: 316515.6562\n",
            "Epoch 691/3000\n",
            "66/66 [==============================] - 6s 83ms/step - loss: 200820.1406 - val_loss: 399229.5625\n",
            "Epoch 692/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 229685.6250 - val_loss: 236498.0000\n",
            "Epoch 693/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 241422.0000 - val_loss: 563678.6250\n",
            "Epoch 694/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 246829.6562 - val_loss: 243193.1562\n",
            "Epoch 695/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 1299620.3750 - val_loss: 1748416.0000\n",
            "Epoch 696/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 766301.2500 - val_loss: 1087101.0000\n",
            "Epoch 697/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 968759.5625 - val_loss: 281619.9375\n",
            "Epoch 698/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 628964.0625 - val_loss: 964348.2500\n",
            "Epoch 699/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 291107.5312 - val_loss: 882479.8125\n",
            "Epoch 700/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 619340.1250 - val_loss: 1631078.6250\n",
            "Epoch 701/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 527749.1250 - val_loss: 410310.5625\n",
            "Epoch 702/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 259913.2969 - val_loss: 581616.7500\n",
            "Epoch 703/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 570713.0625 - val_loss: 1666336.3750\n",
            "Epoch 704/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 1252469.7500 - val_loss: 6789528.0000\n",
            "Epoch 705/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 10190058.0000 - val_loss: 5370961.0000\n",
            "Epoch 706/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 7070145.0000 - val_loss: 2116140.2500\n",
            "Epoch 707/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 1152509.8750 - val_loss: 623879.5625\n",
            "Epoch 708/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 610289.1875 - val_loss: 4815655.0000\n",
            "Epoch 709/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 2319089.0000 - val_loss: 401723.6875\n",
            "Epoch 710/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 450429.9688 - val_loss: 482112.0000\n",
            "Epoch 711/3000\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 632001.2500 - val_loss: 1786890.8750\n",
            "Epoch 712/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 425167.5938 - val_loss: 618742.1250\n",
            "Epoch 713/3000\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 457877.3438 - val_loss: 282968.4688\n",
            "Epoch 714/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 428189.1562 - val_loss: 496898.1562\n",
            "Epoch 715/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 420623.3750 - val_loss: 412201.3750\n",
            "Epoch 716/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 450962.5312 - val_loss: 2684298.7500\n",
            "Epoch 717/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 6196706.0000 - val_loss: 2409622.0000\n",
            "Epoch 718/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 1736552.8750 - val_loss: 13816209.0000\n",
            "Epoch 719/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 53509484.0000 - val_loss: 17139992.0000\n",
            "Epoch 720/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 5162482.0000 - val_loss: 10472730.0000\n",
            "Epoch 721/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 1502626.0000 - val_loss: 3985008.0000\n",
            "Epoch 722/3000\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 3671446.5000 - val_loss: 3323225.2500\n",
            "Epoch 723/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 448007.5625 - val_loss: 1818440.6250\n",
            "Epoch 724/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 554762.8750 - val_loss: 556249.5000\n",
            "Epoch 725/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 268714.7500 - val_loss: 492548.2188\n",
            "Epoch 726/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 402725.4688 - val_loss: 411578.8125\n",
            "Epoch 727/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 167954.9219 - val_loss: 207871.7656\n",
            "Epoch 728/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 143724.4844 - val_loss: 283541.5312\n",
            "Epoch 729/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 152633.3281 - val_loss: 291845.1875\n",
            "Epoch 730/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 252506.4375 - val_loss: 473401.3750\n",
            "Epoch 731/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 320681.4062 - val_loss: 499870.8438\n",
            "Epoch 732/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 1455581.8750 - val_loss: 1256118.1250\n",
            "Epoch 733/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 602677.1875 - val_loss: 845358.2500\n",
            "Epoch 734/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 688059.8750 - val_loss: 3540514.7500\n",
            "Epoch 735/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 1175391.3750 - val_loss: 598648.8125\n",
            "Epoch 736/3000\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 327453.5000 - val_loss: 303331.9688\n",
            "Epoch 737/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 460421.7188 - val_loss: 384987.5625\n",
            "Epoch 738/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 255936.5781 - val_loss: 682417.3750\n",
            "Epoch 739/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 7004135.0000 - val_loss: 22532684.0000\n",
            "Epoch 740/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 7117306.0000 - val_loss: 2482697.5000\n",
            "Epoch 741/3000\n",
            "66/66 [==============================] - 5s 81ms/step - loss: 2117192.5000 - val_loss: 1126093.8750\n",
            "Epoch 742/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 1095002.6250 - val_loss: 832125.6250\n",
            "Epoch 743/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 495740.6875 - val_loss: 484621.4688\n",
            "Epoch 744/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 641929.6250 - val_loss: 393829.8750\n",
            "Epoch 745/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 392422.1875 - val_loss: 1475026.6250\n",
            "Epoch 746/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 584119.2500 - val_loss: 662645.7500\n",
            "Epoch 747/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 504709.5625 - val_loss: 859852.3125\n",
            "Epoch 748/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 185587.0781 - val_loss: 231435.2031\n",
            "Epoch 749/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 136213.9844 - val_loss: 276475.6562\n",
            "Epoch 750/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 151229.2031 - val_loss: 584516.0625\n",
            "Epoch 751/3000\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 1310409.8750 - val_loss: 1908863.6250\n",
            "Epoch 752/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 412750.4375 - val_loss: 438341.3750\n",
            "Epoch 753/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 174736.2344 - val_loss: 183457.3750\n",
            "Epoch 754/3000\n",
            "66/66 [==============================] - 7s 107ms/step - loss: 194403.0625 - val_loss: 603565.4375\n",
            "Epoch 755/3000\n",
            "66/66 [==============================] - 7s 106ms/step - loss: 328982.2500 - val_loss: 816354.6875\n",
            "Epoch 756/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 2352279.7500 - val_loss: 2662696.7500\n",
            "Epoch 757/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 4448709.0000 - val_loss: 1530677.3750\n",
            "Epoch 758/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 10239837.0000 - val_loss: 8615250.0000\n",
            "Epoch 759/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 24343688.0000 - val_loss: 84178656.0000\n",
            "Epoch 760/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 19872752.0000 - val_loss: 1931600.1250\n",
            "Epoch 761/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 1579391.8750 - val_loss: 1910421.5000\n",
            "Epoch 762/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 665279.4375 - val_loss: 1854037.8750\n",
            "Epoch 763/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 1342281.0000 - val_loss: 1495579.1250\n",
            "Epoch 764/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 620008.5625 - val_loss: 718709.2500\n",
            "Epoch 765/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 306998.2812 - val_loss: 641609.8125\n",
            "Epoch 766/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 219188.0781 - val_loss: 759379.6875\n",
            "Epoch 767/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 157743.1875 - val_loss: 277374.9062\n",
            "Epoch 768/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 223177.7188 - val_loss: 629018.2500\n",
            "Epoch 769/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 193625.3906 - val_loss: 415752.1562\n",
            "Epoch 770/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 242746.6719 - val_loss: 1424011.8750\n",
            "Epoch 771/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 454873.3750 - val_loss: 609403.8125\n",
            "Epoch 772/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 360331.4688 - val_loss: 254504.1875\n",
            "Epoch 773/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 253460.1250 - val_loss: 1796446.2500\n",
            "Epoch 774/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 547242.9375 - val_loss: 753879.0625\n",
            "Epoch 775/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 155626.1406 - val_loss: 373006.1250\n",
            "Epoch 776/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 539981.1250 - val_loss: 1290160.0000\n",
            "Epoch 777/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 1553020.6250 - val_loss: 362672.9688\n",
            "Epoch 778/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 1604649.6250 - val_loss: 1270855.6250\n",
            "Epoch 779/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 538939.4375 - val_loss: 356844.2500\n",
            "Epoch 780/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 822394.3750 - val_loss: 3109088.5000\n",
            "Epoch 781/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 2596797.7500 - val_loss: 3803346.0000\n",
            "Epoch 782/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 25334270.0000 - val_loss: 56857508.0000\n",
            "Epoch 783/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 18334040.0000 - val_loss: 6630074.5000\n",
            "Epoch 784/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 1991220.0000 - val_loss: 738696.9375\n",
            "Epoch 785/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 525182.5000 - val_loss: 433066.8125\n",
            "Epoch 786/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 305559.2812 - val_loss: 509946.4375\n",
            "Epoch 787/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 213766.8438 - val_loss: 293969.6875\n",
            "Epoch 788/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 146169.9375 - val_loss: 290426.0625\n",
            "Epoch 789/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 220830.9062 - val_loss: 352704.6562\n",
            "Epoch 790/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 151374.0938 - val_loss: 397576.9062\n",
            "Epoch 791/3000\n",
            "66/66 [==============================] - 7s 107ms/step - loss: 280242.2500 - val_loss: 395731.7188\n",
            "Epoch 792/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 177091.1250 - val_loss: 642205.8750\n",
            "Epoch 793/3000\n",
            "66/66 [==============================] - 7s 106ms/step - loss: 249175.0781 - val_loss: 394604.4688\n",
            "Epoch 794/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 133815.5000 - val_loss: 584930.2500\n",
            "Epoch 795/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 636570.4375 - val_loss: 1043266.6875\n",
            "Epoch 796/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 782690.1875 - val_loss: 460326.1250\n",
            "Epoch 797/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 961517.9375 - val_loss: 284718.6875\n",
            "Epoch 798/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 139177.0469 - val_loss: 249302.4219\n",
            "Epoch 799/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 197740.0156 - val_loss: 852282.9375\n",
            "Epoch 800/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 6465981.0000 - val_loss: 22713822.0000\n",
            "Epoch 801/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 13451397.0000 - val_loss: 1612888.2500\n",
            "Epoch 802/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 840864.5625 - val_loss: 975480.4375\n",
            "Epoch 803/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 854787.1875 - val_loss: 798759.7500\n",
            "Epoch 804/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 975923.4375 - val_loss: 314796.5000\n",
            "Epoch 805/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 249391.8750 - val_loss: 229912.8438\n",
            "Epoch 806/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 457765.0000 - val_loss: 960329.5000\n",
            "Epoch 807/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 791579.1875 - val_loss: 644650.8750\n",
            "Epoch 808/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 263193.6875 - val_loss: 182732.8906\n",
            "Epoch 809/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 368545.8750 - val_loss: 273801.7188\n",
            "Epoch 810/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 207405.8125 - val_loss: 332428.1562\n",
            "Epoch 811/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 476281.4062 - val_loss: 468357.1875\n",
            "Epoch 812/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 363799.8750 - val_loss: 1829016.5000\n",
            "Epoch 813/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 1922566.3750 - val_loss: 2849961.0000\n",
            "Epoch 814/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 4350700.5000 - val_loss: 4469390.0000\n",
            "Epoch 815/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 7188987.0000 - val_loss: 4362024.0000\n",
            "Epoch 816/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 3775974.7500 - val_loss: 9511118.0000\n",
            "Epoch 817/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 3793521.7500 - val_loss: 506973.2188\n",
            "Epoch 818/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 1304622.7500 - val_loss: 474741.9688\n",
            "Epoch 819/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 345218.6875 - val_loss: 892720.3125\n",
            "Epoch 820/3000\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 2983224.5000 - val_loss: 1159210.2500\n",
            "Epoch 821/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 1418247.0000 - val_loss: 561996.2500\n",
            "Epoch 822/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 519084.6250 - val_loss: 571700.3125\n",
            "Epoch 823/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 1308698.5000 - val_loss: 1135342.2500\n",
            "Epoch 824/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 248465.6250 - val_loss: 466835.7188\n",
            "Epoch 825/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 1103024.2500 - val_loss: 667646.6875\n",
            "Epoch 826/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 1403606.3750 - val_loss: 1340458.1250\n",
            "Epoch 827/3000\n",
            "66/66 [==============================] - 5s 82ms/step - loss: 1159402.0000 - val_loss: 2465900.2500\n",
            "Epoch 828/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 1375391.3750 - val_loss: 898114.8750\n",
            "Epoch 829/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 3339512.2500 - val_loss: 990338.3750\n",
            "Epoch 830/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 1273543.0000 - val_loss: 635937.0625\n",
            "Epoch 831/3000\n",
            "66/66 [==============================] - 7s 105ms/step - loss: 288973.0000 - val_loss: 1393141.3750\n",
            "Epoch 832/3000\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 647275.5000 - val_loss: 1091238.6250\n",
            "Epoch 833/3000\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 932779.6875 - val_loss: 348470.3750\n",
            "Epoch 834/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 1976271.5000 - val_loss: 2374263.0000\n",
            "Epoch 835/3000\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 413549.0000 - val_loss: 285735.7188\n",
            "Epoch 836/3000\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 1368699.1250 - val_loss: 7294371.5000\n",
            "Epoch 837/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 5290403.0000 - val_loss: 6739412.5000\n",
            "Epoch 838/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 785440.5000 - val_loss: 573510.3125\n",
            "Epoch 839/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 1496904.7500 - val_loss: 1260070.1250\n",
            "Epoch 840/3000\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 2753288.5000 - val_loss: 2003270.0000\n",
            "Epoch 841/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 1227504.6250 - val_loss: 528326.1875\n",
            "Epoch 842/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 430604.1250 - val_loss: 1034008.3125\n",
            "Epoch 843/3000\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 445882.4062 - val_loss: 1131472.7500\n",
            "Epoch 844/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 466717.9375 - val_loss: 518707.0312\n",
            "Epoch 845/3000\n",
            "66/66 [==============================] - 7s 107ms/step - loss: 189366.0625 - val_loss: 479821.5625\n",
            "Epoch 846/3000\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 387859.1250 - val_loss: 609985.4375\n",
            "Epoch 847/3000\n",
            "66/66 [==============================] - 7s 106ms/step - loss: 4474307.0000 - val_loss: 3570737.0000\n",
            "Epoch 848/3000\n",
            "66/66 [==============================] - 7s 105ms/step - loss: 40681944.0000 - val_loss: 3772374.0000\n",
            "Epoch 849/3000\n",
            "66/66 [==============================] - 7s 106ms/step - loss: 3014293.5000 - val_loss: 2313152.0000\n",
            "Epoch 850/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 2127924.7500 - val_loss: 1851450.8750\n",
            "Epoch 851/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 663021.5000 - val_loss: 626884.5625\n",
            "Epoch 852/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 840901.9375 - val_loss: 376175.0625\n",
            "Epoch 853/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 1181501.1250 - val_loss: 584641.2500\n",
            "Epoch 854/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 348095.9688 - val_loss: 308288.1250\n",
            "Epoch 855/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 431817.1875 - val_loss: 711384.1875\n",
            "Epoch 856/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 548383.8125 - val_loss: 449527.3125\n",
            "Epoch 857/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 385131.5938 - val_loss: 511052.6875\n",
            "Epoch 858/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 465830.3125 - val_loss: 603358.0625\n",
            "Epoch 859/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 1038321.5625 - val_loss: 449262.0625\n",
            "Epoch 860/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 242187.5469 - val_loss: 874034.4375\n",
            "Epoch 861/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 346821.4062 - val_loss: 370095.5000\n",
            "Epoch 862/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 145885.1094 - val_loss: 213837.1875\n",
            "Epoch 863/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 455672.5312 - val_loss: 178241.3750\n",
            "Epoch 864/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 859028.0000 - val_loss: 431609.5000\n",
            "Epoch 865/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 208713.7188 - val_loss: 394612.6875\n",
            "Epoch 866/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 172744.7031 - val_loss: 312501.7188\n",
            "Epoch 867/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 159291.9844 - val_loss: 345920.1250\n",
            "Epoch 868/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 472972.6875 - val_loss: 907953.5625\n",
            "Epoch 869/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 375169.6562 - val_loss: 857269.3750\n",
            "Epoch 870/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 703227.3750 - val_loss: 583928.2500\n",
            "Epoch 871/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 257451.1406 - val_loss: 497309.3438\n",
            "Epoch 872/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 224263.3594 - val_loss: 435236.5312\n",
            "Epoch 873/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 1140693.6250 - val_loss: 527861.4375\n",
            "Epoch 874/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 667380.2500 - val_loss: 476895.1562\n",
            "Epoch 875/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 335597.5312 - val_loss: 744374.1875\n",
            "Epoch 876/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 848570.6875 - val_loss: 488794.7500\n",
            "Epoch 877/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 964560.3750 - val_loss: 1649671.3750\n",
            "Epoch 878/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 4777355.5000 - val_loss: 8411822.0000\n",
            "Epoch 879/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 10382757.0000 - val_loss: 11851284.0000\n",
            "Epoch 880/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 9494110.0000 - val_loss: 2316646.2500\n",
            "Epoch 881/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 2472072.5000 - val_loss: 830727.3125\n",
            "Epoch 882/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 977753.5000 - val_loss: 380100.8750\n",
            "Epoch 883/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 493009.6875 - val_loss: 239839.5156\n",
            "Epoch 884/3000\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 406035.2812 - val_loss: 364372.3750\n",
            "Epoch 885/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 799604.2500 - val_loss: 700157.7500\n",
            "Epoch 886/3000\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 4382317.5000 - val_loss: 2338838.0000\n",
            "Epoch 887/3000\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 818002.2500 - val_loss: 282689.2812\n",
            "Epoch 888/3000\n",
            "66/66 [==============================] - 7s 109ms/step - loss: 4840768.5000 - val_loss: 929988.1875\n",
            "Epoch 889/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 1616350.1250 - val_loss: 907031.8125\n",
            "Epoch 890/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 542329.5625 - val_loss: 642118.2500\n",
            "Epoch 891/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 285320.4688 - val_loss: 145503.1406\n",
            "Epoch 892/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 330897.0938 - val_loss: 379934.5000\n",
            "Epoch 893/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 311820.2188 - val_loss: 335059.7188\n",
            "Epoch 894/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 3113953.0000 - val_loss: 4440103.0000\n",
            "Epoch 895/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 1137300.8750 - val_loss: 717165.6250\n",
            "Epoch 896/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 2085077.5000 - val_loss: 3006281.0000\n",
            "Epoch 897/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 1242066.3750 - val_loss: 1696288.0000\n",
            "Epoch 898/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 463541.0312 - val_loss: 376178.6250\n",
            "Epoch 899/3000\n",
            "66/66 [==============================] - 5s 83ms/step - loss: 141856.7188 - val_loss: 341604.8438\n",
            "Epoch 900/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 202284.2188 - val_loss: 285560.6250\n",
            "Epoch 901/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 162705.9531 - val_loss: 921552.5000\n",
            "Epoch 902/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 5570631.5000 - val_loss: 3843954.0000\n",
            "Epoch 903/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 4579115.0000 - val_loss: 3647410.2500\n",
            "Epoch 904/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 1298577.1250 - val_loss: 475410.2188\n",
            "Epoch 905/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 2116808.7500 - val_loss: 1387019.3750\n",
            "Epoch 906/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 809576.0000 - val_loss: 399947.7188\n",
            "Epoch 907/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 205337.2500 - val_loss: 526392.3125\n",
            "Epoch 908/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 1571101.1250 - val_loss: 3787245.5000\n",
            "Epoch 909/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 1445534.1250 - val_loss: 1005697.3750\n",
            "Epoch 910/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 1328780.7500 - val_loss: 5344855.0000\n",
            "Epoch 911/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 4848316.0000 - val_loss: 7155443.0000\n",
            "Epoch 912/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 6470357.5000 - val_loss: 8056020.5000\n",
            "Epoch 913/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 5104340.0000 - val_loss: 2766608.2500\n",
            "Epoch 914/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 681467.5625 - val_loss: 243366.0156\n",
            "Epoch 915/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 266235.1875 - val_loss: 304446.5625\n",
            "Epoch 916/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 339652.6250 - val_loss: 1342527.6250\n",
            "Epoch 917/3000\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 292337.3750 - val_loss: 295719.1250\n",
            "Epoch 918/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 426049.4375 - val_loss: 861075.2500\n",
            "Epoch 919/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 337121.9375 - val_loss: 787551.5000\n",
            "Epoch 920/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 188498.4531 - val_loss: 352980.3750\n",
            "Epoch 921/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 258681.2656 - val_loss: 497548.6875\n",
            "Epoch 922/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 340927.6875 - val_loss: 326740.3438\n",
            "Epoch 923/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 349147.5000 - val_loss: 315947.7188\n",
            "Epoch 924/3000\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 995019.3750 - val_loss: 2360245.0000\n",
            "Epoch 925/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 1250079.2500 - val_loss: 2940528.5000\n",
            "Epoch 926/3000\n",
            "66/66 [==============================] - 7s 106ms/step - loss: 13706156.0000 - val_loss: 21609704.0000\n",
            "Epoch 927/3000\n",
            "66/66 [==============================] - 7s 106ms/step - loss: 41212252.0000 - val_loss: 37547460.0000\n",
            "Epoch 928/3000\n",
            "66/66 [==============================] - 7s 107ms/step - loss: 4274166.0000 - val_loss: 1813438.5000\n",
            "Epoch 929/3000\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 436773.2188 - val_loss: 483107.3125\n",
            "Epoch 930/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 209880.3281 - val_loss: 385598.7188\n",
            "Epoch 931/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 305292.3750 - val_loss: 412181.7500\n",
            "Epoch 932/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 274497.7812 - val_loss: 279247.6875\n",
            "Epoch 933/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 155190.2969 - val_loss: 437376.8438\n",
            "Epoch 934/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 249649.0000 - val_loss: 745699.1875\n",
            "Epoch 935/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 467696.5000 - val_loss: 2393851.0000\n",
            "Epoch 936/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 404620.6875 - val_loss: 489014.2500\n",
            "Epoch 937/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 204236.6094 - val_loss: 447023.4375\n",
            "Epoch 938/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 116815.5469 - val_loss: 371821.1562\n",
            "Epoch 939/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 76492.6172 - val_loss: 341326.8125\n",
            "Epoch 940/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 84388.9766 - val_loss: 247213.6875\n",
            "Epoch 941/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 222631.8125 - val_loss: 360580.1250\n",
            "Epoch 942/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 151491.5156 - val_loss: 286543.8750\n",
            "Epoch 943/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 107408.2656 - val_loss: 212522.9531\n",
            "Epoch 944/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 144464.9844 - val_loss: 509648.7500\n",
            "Epoch 945/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 292872.2812 - val_loss: 241301.1250\n",
            "Epoch 946/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 280517.5938 - val_loss: 540261.4375\n",
            "Epoch 947/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 320878.1875 - val_loss: 382412.4688\n",
            "Epoch 948/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 838175.3750 - val_loss: 967453.8750\n",
            "Epoch 949/3000\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 10573314.0000 - val_loss: 7350839.0000\n",
            "Epoch 950/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 7631149.0000 - val_loss: 35078424.0000\n",
            "Epoch 951/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 24670504.0000 - val_loss: 16715267.0000\n",
            "Epoch 952/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 3250344.0000 - val_loss: 2696966.5000\n",
            "Epoch 953/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 851151.8750 - val_loss: 611184.4375\n",
            "Epoch 954/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 572992.5000 - val_loss: 304481.0312\n",
            "Epoch 955/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 368724.2500 - val_loss: 3233285.7500\n",
            "Epoch 956/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 1080314.3750 - val_loss: 251550.5938\n",
            "Epoch 957/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 214737.9219 - val_loss: 239499.8281\n",
            "Epoch 958/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 143478.2188 - val_loss: 233820.8438\n",
            "Epoch 959/3000\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 86438.4766 - val_loss: 239493.9688\n",
            "Epoch 960/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 107978.7188 - val_loss: 299354.2812\n",
            "Epoch 961/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 121218.9375 - val_loss: 270996.3750\n",
            "Epoch 962/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 229899.4219 - val_loss: 325955.1250\n",
            "Epoch 963/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 262972.7188 - val_loss: 376520.5312\n",
            "Epoch 964/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 989830.6875 - val_loss: 399534.9688\n",
            "Epoch 965/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 384645.4375 - val_loss: 200519.3281\n",
            "Epoch 966/3000\n",
            "66/66 [==============================] - 7s 109ms/step - loss: 387580.4688 - val_loss: 1851041.0000\n",
            "Epoch 967/3000\n",
            "66/66 [==============================] - 7s 105ms/step - loss: 1168178.2500 - val_loss: 3284868.0000\n",
            "Epoch 968/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 1145886.6250 - val_loss: 265709.1875\n",
            "Epoch 969/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 225759.2969 - val_loss: 243272.7969\n",
            "Epoch 970/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 362067.7188 - val_loss: 614727.9375\n",
            "Epoch 971/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 399364.7812 - val_loss: 217416.8750\n",
            "Epoch 972/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 181700.0469 - val_loss: 233005.3750\n",
            "Epoch 973/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 202857.8438 - val_loss: 826062.0625\n",
            "Epoch 974/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 834641.4375 - val_loss: 808549.0000\n",
            "Epoch 975/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 12869271.0000 - val_loss: 50859764.0000\n",
            "Epoch 976/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 18750224.0000 - val_loss: 3480129.7500\n",
            "Epoch 977/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 20534328.0000 - val_loss: 11341939.0000\n",
            "Epoch 978/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 5202643.0000 - val_loss: 3276730.5000\n",
            "Epoch 979/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 872940.9375 - val_loss: 260993.1250\n",
            "Epoch 980/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 241992.7969 - val_loss: 379454.7500\n",
            "Epoch 981/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 308674.5312 - val_loss: 382549.8438\n",
            "Epoch 982/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 130882.7344 - val_loss: 313290.6562\n",
            "Epoch 983/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 195661.0312 - val_loss: 245640.8281\n",
            "Epoch 984/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 97409.2969 - val_loss: 208550.6250\n",
            "Epoch 985/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 89079.4531 - val_loss: 474162.5312\n",
            "Epoch 986/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 288895.8750 - val_loss: 189534.0781\n",
            "Epoch 987/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 95814.0703 - val_loss: 243210.4219\n",
            "Epoch 988/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 237107.3125 - val_loss: 864541.4375\n",
            "Epoch 989/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 279319.8125 - val_loss: 250964.4844\n",
            "Epoch 990/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 203439.8125 - val_loss: 626011.1875\n",
            "Epoch 991/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 251638.8125 - val_loss: 293878.4375\n",
            "Epoch 992/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 683653.0000 - val_loss: 1152653.2500\n",
            "Epoch 993/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 3589915.7500 - val_loss: 422391.0938\n",
            "Epoch 994/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 274174.8750 - val_loss: 264763.7188\n",
            "Epoch 995/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 126975.8516 - val_loss: 215629.7344\n",
            "Epoch 996/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 115603.3359 - val_loss: 309451.6875\n",
            "Epoch 997/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 114779.5547 - val_loss: 503683.1250\n",
            "Epoch 998/3000\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 632213.1250 - val_loss: 1697826.6250\n",
            "Epoch 999/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 4982841.5000 - val_loss: 1827584.0000\n",
            "Epoch 1000/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 2055902.5000 - val_loss: 875949.9375\n",
            "Epoch 1001/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 1707221.5000 - val_loss: 1396945.1250\n",
            "Epoch 1002/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 725512.6250 - val_loss: 803794.3750\n",
            "Epoch 1003/3000\n",
            "66/66 [==============================] - 7s 109ms/step - loss: 376716.1875 - val_loss: 393729.8438\n",
            "Epoch 1004/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 519449.5625 - val_loss: 202846.5625\n",
            "Epoch 1005/3000\n",
            "66/66 [==============================] - 7s 105ms/step - loss: 222544.0781 - val_loss: 1137149.1250\n",
            "Epoch 1006/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 233110.0000 - val_loss: 119127.1250\n",
            "Epoch 1007/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 279681.1250 - val_loss: 725339.0625\n",
            "Epoch 1008/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 3064218.7500 - val_loss: 5013440.0000\n",
            "Epoch 1009/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 2050495.1250 - val_loss: 1738104.5000\n",
            "Epoch 1010/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 1689009.0000 - val_loss: 687767.1875\n",
            "Epoch 1011/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 2746268.2500 - val_loss: 11113410.0000\n",
            "Epoch 1012/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 7245375.5000 - val_loss: 2187319.5000\n",
            "Epoch 1013/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 1275992.5000 - val_loss: 228474.8438\n",
            "Epoch 1014/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 204908.5312 - val_loss: 645656.1250\n",
            "Epoch 1015/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 11354213.0000 - val_loss: 6406824.0000\n",
            "Epoch 1016/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 11234423.0000 - val_loss: 4365974.5000\n",
            "Epoch 1017/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 13121879.0000 - val_loss: 5559793.5000\n",
            "Epoch 1018/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 655570.7500 - val_loss: 845313.8750\n",
            "Epoch 1019/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 225810.9688 - val_loss: 456897.5312\n",
            "Epoch 1020/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 345276.8125 - val_loss: 538858.2500\n",
            "Epoch 1021/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 291018.9688 - val_loss: 335148.8438\n",
            "Epoch 1022/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 166080.8906 - val_loss: 345272.3750\n",
            "Epoch 1023/3000\n",
            "66/66 [==============================] - 6s 84ms/step - loss: 314722.6562 - val_loss: 380129.8750\n",
            "Epoch 1024/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 407415.2812 - val_loss: 245711.5938\n",
            "Epoch 1025/3000\n",
            "66/66 [==============================] - 7s 109ms/step - loss: 138552.5625 - val_loss: 279165.3438\n",
            "Epoch 1026/3000\n",
            "66/66 [==============================] - 7s 106ms/step - loss: 146223.3438 - val_loss: 331581.7812\n",
            "Epoch 1027/3000\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 256772.0312 - val_loss: 349295.2188\n",
            "Epoch 1028/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 187442.2656 - val_loss: 317073.4688\n",
            "Epoch 1029/3000\n",
            "66/66 [==============================] - 7s 110ms/step - loss: 168026.9688 - val_loss: 382784.3438\n",
            "Epoch 1030/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 403643.9688 - val_loss: 270125.0938\n",
            "Epoch 1031/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 2860662.0000 - val_loss: 1031764.0000\n",
            "Epoch 1032/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 438253.4375 - val_loss: 955172.5000\n",
            "Epoch 1033/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 768468.2500 - val_loss: 2158981.5000\n",
            "Epoch 1034/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 5082495.5000 - val_loss: 11121118.0000\n",
            "Epoch 1035/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 1912449.0000 - val_loss: 868239.0000\n",
            "Epoch 1036/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 915281.6875 - val_loss: 738303.3125\n",
            "Epoch 1037/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 473468.8125 - val_loss: 184854.1406\n",
            "Epoch 1038/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 163735.8438 - val_loss: 200691.2812\n",
            "Epoch 1039/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 416261.3438 - val_loss: 347791.1875\n",
            "Epoch 1040/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 898969.9375 - val_loss: 341158.5312\n",
            "Epoch 1041/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 1543780.1250 - val_loss: 1877618.7500\n",
            "Epoch 1042/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 3648211.0000 - val_loss: 3161627.7500\n",
            "Epoch 1043/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 3262890.7500 - val_loss: 1385413.8750\n",
            "Epoch 1044/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 699535.7500 - val_loss: 996369.4375\n",
            "Epoch 1045/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 365341.5938 - val_loss: 360795.6562\n",
            "Epoch 1046/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 192727.8906 - val_loss: 351926.0938\n",
            "Epoch 1047/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 241602.2812 - val_loss: 289183.0625\n",
            "Epoch 1048/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 277708.1250 - val_loss: 434605.5625\n",
            "Epoch 1049/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 523644.8438 - val_loss: 1374663.3750\n",
            "Epoch 1050/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 1049428.1250 - val_loss: 1520895.7500\n",
            "Epoch 1051/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 4451670.5000 - val_loss: 2734963.2500\n",
            "Epoch 1052/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 1714101.0000 - val_loss: 1228864.5000\n",
            "Epoch 1053/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 1733352.8750 - val_loss: 605283.2500\n",
            "Epoch 1054/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 715553.1250 - val_loss: 619461.0000\n",
            "Epoch 1055/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 449456.1562 - val_loss: 293210.5312\n",
            "Epoch 1056/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 224022.6562 - val_loss: 356376.8750\n",
            "Epoch 1057/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 149184.7188 - val_loss: 197955.6562\n",
            "Epoch 1058/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 860422.9375 - val_loss: 1161415.0000\n",
            "Epoch 1059/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 1004422.1875 - val_loss: 1441880.8750\n",
            "Epoch 1060/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 675207.8750 - val_loss: 1792207.7500\n",
            "Epoch 1061/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 619596.5625 - val_loss: 915098.6875\n",
            "Epoch 1062/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 1662420.8750 - val_loss: 2275023.5000\n",
            "Epoch 1063/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 2142170.0000 - val_loss: 4575053.5000\n",
            "Epoch 1064/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 1773912.7500 - val_loss: 1588303.5000\n",
            "Epoch 1065/3000\n",
            "66/66 [==============================] - 7s 109ms/step - loss: 3215311.0000 - val_loss: 2879478.2500\n",
            "Epoch 1066/3000\n",
            "66/66 [==============================] - 7s 105ms/step - loss: 2206076.5000 - val_loss: 931661.9375\n",
            "Epoch 1067/3000\n",
            "66/66 [==============================] - 7s 111ms/step - loss: 505228.2812 - val_loss: 576743.3125\n",
            "Epoch 1068/3000\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 583056.2500 - val_loss: 1262781.1250\n",
            "Epoch 1069/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 2278770.2500 - val_loss: 5364984.5000\n",
            "Epoch 1070/3000\n",
            "66/66 [==============================] - 7s 112ms/step - loss: 7555783.0000 - val_loss: 4524480.5000\n",
            "Epoch 1071/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 4360122.0000 - val_loss: 549240.3125\n",
            "Epoch 1072/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 788921.1250 - val_loss: 9122865.0000\n",
            "Epoch 1073/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 2486389.5000 - val_loss: 443466.0625\n",
            "Epoch 1074/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 948848.5625 - val_loss: 742067.3750\n",
            "Epoch 1075/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 428696.9688 - val_loss: 1007223.7500\n",
            "Epoch 1076/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 245035.5938 - val_loss: 205465.4844\n",
            "Epoch 1077/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 395796.7188 - val_loss: 362410.9375\n",
            "Epoch 1078/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 166723.2500 - val_loss: 159090.6406\n",
            "Epoch 1079/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 125244.5859 - val_loss: 346905.5625\n",
            "Epoch 1080/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 1594817.3750 - val_loss: 7717753.0000\n",
            "Epoch 1081/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 5758661.0000 - val_loss: 1088232.8750\n",
            "Epoch 1082/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 576613.8125 - val_loss: 756710.5000\n",
            "Epoch 1083/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 310583.4375 - val_loss: 192796.3906\n",
            "Epoch 1084/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 286392.2500 - val_loss: 2557426.5000\n",
            "Epoch 1085/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 1290978.8750 - val_loss: 1601307.7500\n",
            "Epoch 1086/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 2175405.0000 - val_loss: 365967.0625\n",
            "Epoch 1087/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 7608216.5000 - val_loss: 1375241.0000\n",
            "Epoch 1088/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 5476206.5000 - val_loss: 4170498.5000\n",
            "Epoch 1089/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 1026079.4375 - val_loss: 472657.7812\n",
            "Epoch 1090/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 1147305.2500 - val_loss: 4768252.0000\n",
            "Epoch 1091/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 1204292.3750 - val_loss: 574424.5625\n",
            "Epoch 1092/3000\n",
            "66/66 [==============================] - 6s 85ms/step - loss: 211544.3750 - val_loss: 260548.6562\n",
            "Epoch 1093/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 107249.2031 - val_loss: 238155.1406\n",
            "Epoch 1094/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 761189.3125 - val_loss: 1281269.2500\n",
            "Epoch 1095/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 529714.3125 - val_loss: 199828.9375\n",
            "Epoch 1096/3000\n",
            "66/66 [==============================] - 7s 105ms/step - loss: 511168.0000 - val_loss: 1538610.7500\n",
            "Epoch 1097/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 1362359.2500 - val_loss: 3102846.2500\n",
            "Epoch 1098/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 9358971.0000 - val_loss: 15821384.0000\n",
            "Epoch 1099/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 4391408.0000 - val_loss: 447686.2500\n",
            "Epoch 1100/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 682625.8125 - val_loss: 510156.7812\n",
            "Epoch 1101/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 272968.3125 - val_loss: 1003302.0625\n",
            "Epoch 1102/3000\n",
            "66/66 [==============================] - 6s 86ms/step - loss: 1233266.1250 - val_loss: 512305.7188\n",
            "Epoch 1103/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 529644.4375 - val_loss: 872034.0625\n",
            "Epoch 1104/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 715380.1875 - val_loss: 2980169.5000\n",
            "Epoch 1105/3000\n",
            "66/66 [==============================] - 7s 107ms/step - loss: 1707450.5000 - val_loss: 261831.2812\n",
            "Epoch 1106/3000\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 603230.6875 - val_loss: 377346.9688\n",
            "Epoch 1107/3000\n",
            "66/66 [==============================] - 7s 112ms/step - loss: 1020906.5000 - val_loss: 5015263.5000\n",
            "Epoch 1108/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 3327225.7500 - val_loss: 6516843.5000\n",
            "Epoch 1109/3000\n",
            "66/66 [==============================] - 8s 117ms/step - loss: 1199161.2500 - val_loss: 1396001.8750\n",
            "Epoch 1110/3000\n",
            "66/66 [==============================] - 8s 119ms/step - loss: 1270932.8750 - val_loss: 2707302.2500\n",
            "Epoch 1111/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 1696738.8750 - val_loss: 291322.4688\n",
            "Epoch 1112/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 578458.5625 - val_loss: 284309.0938\n",
            "Epoch 1113/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 117005.4766 - val_loss: 386347.6562\n",
            "Epoch 1114/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 170476.0938 - val_loss: 465420.6562\n",
            "Epoch 1115/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 1047802.8750 - val_loss: 686224.1250\n",
            "Epoch 1116/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 1385460.3750 - val_loss: 784155.6875\n",
            "Epoch 1117/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 677826.1875 - val_loss: 2519256.5000\n",
            "Epoch 1118/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 878488.0000 - val_loss: 500821.5625\n",
            "Epoch 1119/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 773988.2500 - val_loss: 730217.7500\n",
            "Epoch 1120/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 1077377.7500 - val_loss: 4568078.5000\n",
            "Epoch 1121/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 2854778.2500 - val_loss: 806008.9375\n",
            "Epoch 1122/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 2448252.0000 - val_loss: 1088001.0000\n",
            "Epoch 1123/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 1017603.4375 - val_loss: 474927.5625\n",
            "Epoch 1124/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 1705569.1250 - val_loss: 13088425.0000\n",
            "Epoch 1125/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 24953096.0000 - val_loss: 22721962.0000\n",
            "Epoch 1126/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 11450367.0000 - val_loss: 9845787.0000\n",
            "Epoch 1127/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 5184630.5000 - val_loss: 4165781.0000\n",
            "Epoch 1128/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 5261848.5000 - val_loss: 1709379.6250\n",
            "Epoch 1129/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 841132.0000 - val_loss: 674158.6250\n",
            "Epoch 1130/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 232612.2812 - val_loss: 353800.8125\n",
            "Epoch 1131/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 333345.6875 - val_loss: 238460.7656\n",
            "Epoch 1132/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 282868.2188 - val_loss: 781938.9375\n",
            "Epoch 1133/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 146023.1719 - val_loss: 335708.4375\n",
            "Epoch 1134/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 96450.4141 - val_loss: 377834.7500\n",
            "Epoch 1135/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 84345.3828 - val_loss: 242349.1719\n",
            "Epoch 1136/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 106422.6328 - val_loss: 363346.1562\n",
            "Epoch 1137/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 169664.0156 - val_loss: 578811.5625\n",
            "Epoch 1138/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 200203.8750 - val_loss: 275340.5000\n",
            "Epoch 1139/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 137147.2656 - val_loss: 251311.2656\n",
            "Epoch 1140/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 322885.9375 - val_loss: 631635.3125\n",
            "Epoch 1141/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 459105.9062 - val_loss: 499047.6562\n",
            "Epoch 1142/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 206456.7969 - val_loss: 258285.9375\n",
            "Epoch 1143/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 154777.5469 - val_loss: 303881.1875\n",
            "Epoch 1144/3000\n",
            "66/66 [==============================] - 7s 106ms/step - loss: 1081860.0000 - val_loss: 2560621.0000\n",
            "Epoch 1145/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 5299548.5000 - val_loss: 1729612.6250\n",
            "Epoch 1146/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 1202392.3750 - val_loss: 321762.0000\n",
            "Epoch 1147/3000\n",
            "66/66 [==============================] - 7s 111ms/step - loss: 943251.0625 - val_loss: 489481.7500\n",
            "Epoch 1148/3000\n",
            "66/66 [==============================] - 7s 110ms/step - loss: 930862.5000 - val_loss: 826550.3750\n",
            "Epoch 1149/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 407052.2812 - val_loss: 402696.4062\n",
            "Epoch 1150/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 441132.1562 - val_loss: 862618.8750\n",
            "Epoch 1151/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 8202513.0000 - val_loss: 10772596.0000\n",
            "Epoch 1152/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 10176105.0000 - val_loss: 7185185.5000\n",
            "Epoch 1153/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 2168630.2500 - val_loss: 1799003.0000\n",
            "Epoch 1154/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 561977.5625 - val_loss: 446068.9688\n",
            "Epoch 1155/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 236065.7344 - val_loss: 502838.0000\n",
            "Epoch 1156/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 311107.0938 - val_loss: 650400.8750\n",
            "Epoch 1157/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 180681.0156 - val_loss: 521195.5938\n",
            "Epoch 1158/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 616064.5625 - val_loss: 484194.7500\n",
            "Epoch 1159/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 270932.4688 - val_loss: 311921.0625\n",
            "Epoch 1160/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 113086.2109 - val_loss: 198548.0312\n",
            "Epoch 1161/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 86340.8125 - val_loss: 274319.3125\n",
            "Epoch 1162/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 274268.4688 - val_loss: 266052.0938\n",
            "Epoch 1163/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 217286.3594 - val_loss: 496404.0312\n",
            "Epoch 1164/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 131615.7969 - val_loss: 211180.0000\n",
            "Epoch 1165/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 182460.7500 - val_loss: 559656.5625\n",
            "Epoch 1166/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 177646.8281 - val_loss: 327688.6562\n",
            "Epoch 1167/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 203909.0625 - val_loss: 715793.3750\n",
            "Epoch 1168/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 317537.0938 - val_loss: 214747.1094\n",
            "Epoch 1169/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 164050.7500 - val_loss: 208751.4531\n",
            "Epoch 1170/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 1369758.5000 - val_loss: 33676436.0000\n",
            "Epoch 1171/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 51665132.0000 - val_loss: 41590332.0000\n",
            "Epoch 1172/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 23219034.0000 - val_loss: 2342806.0000\n",
            "Epoch 1173/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 1980296.6250 - val_loss: 1516502.2500\n",
            "Epoch 1174/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 433115.1875 - val_loss: 1037705.6250\n",
            "Epoch 1175/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 239505.8438 - val_loss: 950673.0000\n",
            "Epoch 1176/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 245491.9219 - val_loss: 580726.0625\n",
            "Epoch 1177/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 312664.5625 - val_loss: 410910.7812\n",
            "Epoch 1178/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 132650.3906 - val_loss: 443880.6562\n",
            "Epoch 1179/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 278677.9375 - val_loss: 484733.5938\n",
            "Epoch 1180/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 189493.2656 - val_loss: 449794.9062\n",
            "Epoch 1181/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 106340.0859 - val_loss: 274489.2812\n",
            "Epoch 1182/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 115526.8906 - val_loss: 261094.0469\n",
            "Epoch 1183/3000\n",
            "66/66 [==============================] - 7s 112ms/step - loss: 134399.6094 - val_loss: 224798.7344\n",
            "Epoch 1184/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 168153.2188 - val_loss: 490290.4375\n",
            "Epoch 1185/3000\n",
            "66/66 [==============================] - 7s 107ms/step - loss: 125089.8125 - val_loss: 457638.3750\n",
            "Epoch 1186/3000\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 247911.6875 - val_loss: 376607.2188\n",
            "Epoch 1187/3000\n",
            "66/66 [==============================] - 7s 105ms/step - loss: 365568.9062 - val_loss: 312131.7500\n",
            "Epoch 1188/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 81293.2500 - val_loss: 257081.8125\n",
            "Epoch 1189/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 144196.2031 - val_loss: 193041.2500\n",
            "Epoch 1190/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 77064.5078 - val_loss: 187129.0000\n",
            "Epoch 1191/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 379310.8125 - val_loss: 735758.1250\n",
            "Epoch 1192/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 670417.6875 - val_loss: 1612931.0000\n",
            "Epoch 1193/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 372285.1250 - val_loss: 1110922.2500\n",
            "Epoch 1194/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 248401.0938 - val_loss: 750116.7500\n",
            "Epoch 1195/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 558068.9375 - val_loss: 493863.0312\n",
            "Epoch 1196/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 345246.3125 - val_loss: 278489.8438\n",
            "Epoch 1197/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 111619.9062 - val_loss: 208409.3594\n",
            "Epoch 1198/3000\n",
            "66/66 [==============================] - 7s 110ms/step - loss: 415431.1562 - val_loss: 566405.8125\n",
            "Epoch 1199/3000\n",
            "66/66 [==============================] - 8s 114ms/step - loss: 365472.4688 - val_loss: 815423.0000\n",
            "Epoch 1200/3000\n",
            "66/66 [==============================] - 7s 111ms/step - loss: 2872221.2500 - val_loss: 2502225.7500\n",
            "Epoch 1201/3000\n",
            "66/66 [==============================] - 8s 114ms/step - loss: 2555476.0000 - val_loss: 434787.9062\n",
            "Epoch 1202/3000\n",
            "66/66 [==============================] - 7s 112ms/step - loss: 2700023.7500 - val_loss: 2281282.2500\n",
            "Epoch 1203/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 7519435.5000 - val_loss: 10782063.0000\n",
            "Epoch 1204/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 2687061.0000 - val_loss: 989340.8125\n",
            "Epoch 1205/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 1039510.1250 - val_loss: 665118.3125\n",
            "Epoch 1206/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 294945.7500 - val_loss: 1060459.7500\n",
            "Epoch 1207/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 238531.4844 - val_loss: 231758.4219\n",
            "Epoch 1208/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 171805.9219 - val_loss: 132829.0625\n",
            "Epoch 1209/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 206127.7188 - val_loss: 412520.0000\n",
            "Epoch 1210/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 808544.8750 - val_loss: 2653346.7500\n",
            "Epoch 1211/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 1507497.3750 - val_loss: 307299.7188\n",
            "Epoch 1212/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 229743.2812 - val_loss: 826162.8750\n",
            "Epoch 1213/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 263339.6875 - val_loss: 754025.3750\n",
            "Epoch 1214/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 646597.5000 - val_loss: 2213118.7500\n",
            "Epoch 1215/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 1312254.8750 - val_loss: 774888.7500\n",
            "Epoch 1216/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 392014.3125 - val_loss: 238282.1719\n",
            "Epoch 1217/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 946045.0625 - val_loss: 1094324.5000\n",
            "Epoch 1218/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 3241133.0000 - val_loss: 1870195.3750\n",
            "Epoch 1219/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 1717438.5000 - val_loss: 556095.3125\n",
            "Epoch 1220/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 822052.4375 - val_loss: 2007141.8750\n",
            "Epoch 1221/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 882664.1875 - val_loss: 1310425.6250\n",
            "Epoch 1222/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 2520044.7500 - val_loss: 1826061.2500\n",
            "Epoch 1223/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 501233.4688 - val_loss: 916041.6250\n",
            "Epoch 1224/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 1493995.6250 - val_loss: 5511689.0000\n",
            "Epoch 1225/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 3875876.2500 - val_loss: 1104124.1250\n",
            "Epoch 1226/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 937268.0625 - val_loss: 956385.0625\n",
            "Epoch 1227/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 386842.3438 - val_loss: 338197.8438\n",
            "Epoch 1228/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 187959.5312 - val_loss: 169247.2656\n",
            "Epoch 1229/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 546437.1250 - val_loss: 2229771.0000\n",
            "Epoch 1230/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 2909329.7500 - val_loss: 7386143.0000\n",
            "Epoch 1231/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 1235165.8750 - val_loss: 693727.6875\n",
            "Epoch 1232/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 2220764.5000 - val_loss: 1070314.7500\n",
            "Epoch 1233/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 3748021.5000 - val_loss: 396821.4688\n",
            "Epoch 1234/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 1298417.8750 - val_loss: 722611.0000\n",
            "Epoch 1235/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 931938.0625 - val_loss: 514297.0938\n",
            "Epoch 1236/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 7495073.5000 - val_loss: 768567.7500\n",
            "Epoch 1237/3000\n",
            "66/66 [==============================] - 7s 112ms/step - loss: 3700487.0000 - val_loss: 1419404.7500\n",
            "Epoch 1238/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 983854.2500 - val_loss: 510408.9688\n",
            "Epoch 1239/3000\n",
            "66/66 [==============================] - 7s 111ms/step - loss: 268603.8125 - val_loss: 508371.5938\n",
            "Epoch 1240/3000\n",
            "66/66 [==============================] - 7s 111ms/step - loss: 171137.7500 - val_loss: 80876.5703\n",
            "Epoch 1241/3000\n",
            "66/66 [==============================] - 7s 107ms/step - loss: 200454.8281 - val_loss: 561297.1250\n",
            "Epoch 1242/3000\n",
            "66/66 [==============================] - 7s 105ms/step - loss: 163947.9531 - val_loss: 212789.6406\n",
            "Epoch 1243/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 188577.1875 - val_loss: 646308.5625\n",
            "Epoch 1244/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 263742.4062 - val_loss: 267801.5625\n",
            "Epoch 1245/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 1175916.3750 - val_loss: 1381880.0000\n",
            "Epoch 1246/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 2425407.7500 - val_loss: 13737518.0000\n",
            "Epoch 1247/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 14273662.0000 - val_loss: 2603550.7500\n",
            "Epoch 1248/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 7908738.0000 - val_loss: 3512006.5000\n",
            "Epoch 1249/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 5724318.5000 - val_loss: 4777103.0000\n",
            "Epoch 1250/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 1371097.1250 - val_loss: 734975.5000\n",
            "Epoch 1251/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 538422.8750 - val_loss: 394712.8125\n",
            "Epoch 1252/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 252309.5312 - val_loss: 284361.6875\n",
            "Epoch 1253/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 239035.5000 - val_loss: 263516.7812\n",
            "Epoch 1254/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 79738.9375 - val_loss: 540386.8125\n",
            "Epoch 1255/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 331361.7188 - val_loss: 1671281.6250\n",
            "Epoch 1256/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 1323285.0000 - val_loss: 559716.1875\n",
            "Epoch 1257/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 132889.0938 - val_loss: 146998.1250\n",
            "Epoch 1258/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 98908.5000 - val_loss: 449591.0938\n",
            "Epoch 1259/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 217037.5000 - val_loss: 185668.2031\n",
            "Epoch 1260/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 203109.2969 - val_loss: 510907.5625\n",
            "Epoch 1261/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 742977.6875 - val_loss: 196725.7812\n",
            "Epoch 1262/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 443953.9375 - val_loss: 301922.3125\n",
            "Epoch 1263/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 405616.9688 - val_loss: 678647.0000\n",
            "Epoch 1264/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 411695.7188 - val_loss: 855961.1250\n",
            "Epoch 1265/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 250899.2188 - val_loss: 532401.5000\n",
            "Epoch 1266/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 438894.0625 - val_loss: 769013.3125\n",
            "Epoch 1267/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 425795.9062 - val_loss: 502544.5000\n",
            "Epoch 1268/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 153178.0938 - val_loss: 302897.2188\n",
            "Epoch 1269/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 771566.6875 - val_loss: 944121.4375\n",
            "Epoch 1270/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 1830756.8750 - val_loss: 3686577.7500\n",
            "Epoch 1271/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 2511744.0000 - val_loss: 1210808.0000\n",
            "Epoch 1272/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 1926464.3750 - val_loss: 4682636.0000\n",
            "Epoch 1273/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 4413297.0000 - val_loss: 480003.7500\n",
            "Epoch 1274/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 414884.0312 - val_loss: 414092.4062\n",
            "Epoch 1275/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 289810.7188 - val_loss: 328150.2188\n",
            "Epoch 1276/3000\n",
            "66/66 [==============================] - 7s 109ms/step - loss: 3392932.7500 - val_loss: 2822985.5000\n",
            "Epoch 1277/3000\n",
            "66/66 [==============================] - 7s 107ms/step - loss: 3780314.0000 - val_loss: 2315005.7500\n",
            "Epoch 1278/3000\n",
            "66/66 [==============================] - 7s 109ms/step - loss: 3974666.5000 - val_loss: 8078931.0000\n",
            "Epoch 1279/3000\n",
            "66/66 [==============================] - 7s 110ms/step - loss: 2874343.0000 - val_loss: 1067514.8750\n",
            "Epoch 1280/3000\n",
            "66/66 [==============================] - 8s 114ms/step - loss: 728574.7500 - val_loss: 593551.1250\n",
            "Epoch 1281/3000\n",
            "66/66 [==============================] - 7s 110ms/step - loss: 665291.9375 - val_loss: 2700905.7500\n",
            "Epoch 1282/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 6842879.0000 - val_loss: 11208543.0000\n",
            "Epoch 1283/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 1606514.3750 - val_loss: 1589471.5000\n",
            "Epoch 1284/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 797971.2500 - val_loss: 2813084.7500\n",
            "Epoch 1285/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 4353077.0000 - val_loss: 2179951.0000\n",
            "Epoch 1286/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 1878658.3750 - val_loss: 541026.6875\n",
            "Epoch 1287/3000\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 550061.0625 - val_loss: 586176.2500\n",
            "Epoch 1288/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 343872.5312 - val_loss: 403057.3438\n",
            "Epoch 1289/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 782683.1875 - val_loss: 1323101.2500\n",
            "Epoch 1290/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 323719.6562 - val_loss: 348112.3125\n",
            "Epoch 1291/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 368645.6250 - val_loss: 1601182.5000\n",
            "Epoch 1292/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 1435535.1250 - val_loss: 1517379.0000\n",
            "Epoch 1293/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 3056448.5000 - val_loss: 3216172.2500\n",
            "Epoch 1294/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 1803852.3750 - val_loss: 593728.6875\n",
            "Epoch 1295/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 498521.1875 - val_loss: 253749.7188\n",
            "Epoch 1296/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 150704.9531 - val_loss: 220001.4531\n",
            "Epoch 1297/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 309457.0000 - val_loss: 1344753.0000\n",
            "Epoch 1298/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 330597.6875 - val_loss: 227795.1562\n",
            "Epoch 1299/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 775420.0000 - val_loss: 305649.4375\n",
            "Epoch 1300/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 529975.3125 - val_loss: 936535.1875\n",
            "Epoch 1301/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 471010.9688 - val_loss: 210148.3281\n",
            "Epoch 1302/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 202159.0625 - val_loss: 165360.3281\n",
            "Epoch 1303/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 3791834.0000 - val_loss: 13622116.0000\n",
            "Epoch 1304/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 18419754.0000 - val_loss: 8289056.0000\n",
            "Epoch 1305/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 3383123.5000 - val_loss: 1338940.6250\n",
            "Epoch 1306/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 981631.4375 - val_loss: 831638.8750\n",
            "Epoch 1307/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 412744.6875 - val_loss: 1220141.5000\n",
            "Epoch 1308/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 307047.0312 - val_loss: 908010.4375\n",
            "Epoch 1309/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 361996.3750 - val_loss: 361503.1562\n",
            "Epoch 1310/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 273272.4375 - val_loss: 399262.9688\n",
            "Epoch 1311/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 175588.0312 - val_loss: 193774.3750\n",
            "Epoch 1312/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 272091.5000 - val_loss: 366394.0625\n",
            "Epoch 1313/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 235436.7500 - val_loss: 488026.2500\n",
            "Epoch 1314/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 120457.4688 - val_loss: 211083.4062\n",
            "Epoch 1315/3000\n",
            "66/66 [==============================] - 8s 114ms/step - loss: 101497.8672 - val_loss: 159387.2812\n",
            "Epoch 1316/3000\n",
            "66/66 [==============================] - 7s 110ms/step - loss: 80802.4297 - val_loss: 215861.4375\n",
            "Epoch 1317/3000\n",
            "66/66 [==============================] - 8s 114ms/step - loss: 404990.4062 - val_loss: 670412.1875\n",
            "Epoch 1318/3000\n",
            "66/66 [==============================] - 7s 113ms/step - loss: 828196.2500 - val_loss: 397929.9688\n",
            "Epoch 1319/3000\n",
            "66/66 [==============================] - 7s 110ms/step - loss: 395040.9062 - val_loss: 354298.1250\n",
            "Epoch 1320/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 520008.8750 - val_loss: 519326.5000\n",
            "Epoch 1321/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 3423452.0000 - val_loss: 12278783.0000\n",
            "Epoch 1322/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 5133596.5000 - val_loss: 547131.0625\n",
            "Epoch 1323/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 804524.0000 - val_loss: 406812.3125\n",
            "Epoch 1324/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 693032.1875 - val_loss: 934261.9375\n",
            "Epoch 1325/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 428713.7188 - val_loss: 2663587.0000\n",
            "Epoch 1326/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 1752298.1250 - val_loss: 3140788.5000\n",
            "Epoch 1327/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 4272222.5000 - val_loss: 6180900.0000\n",
            "Epoch 1328/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 2918255.2500 - val_loss: 612136.1875\n",
            "Epoch 1329/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 202621.2969 - val_loss: 318235.6250\n",
            "Epoch 1330/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 278892.2812 - val_loss: 165525.0625\n",
            "Epoch 1331/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 179574.9062 - val_loss: 188590.3125\n",
            "Epoch 1332/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 134554.6406 - val_loss: 174787.2031\n",
            "Epoch 1333/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 196685.4062 - val_loss: 436768.4062\n",
            "Epoch 1334/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 224626.6406 - val_loss: 312017.4688\n",
            "Epoch 1335/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 347781.3438 - val_loss: 490157.5625\n",
            "Epoch 1336/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 365024.7500 - val_loss: 389001.3125\n",
            "Epoch 1337/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 562704.2500 - val_loss: 363834.3438\n",
            "Epoch 1338/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 404348.5000 - val_loss: 664591.8750\n",
            "Epoch 1339/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 413635.1562 - val_loss: 453122.0312\n",
            "Epoch 1340/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 518404.0000 - val_loss: 1625662.8750\n",
            "Epoch 1341/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 549241.1875 - val_loss: 382344.4375\n",
            "Epoch 1342/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 816315.6875 - val_loss: 3861137.0000\n",
            "Epoch 1343/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 37618416.0000 - val_loss: 24927938.0000\n",
            "Epoch 1344/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 4057437.2500 - val_loss: 641131.0000\n",
            "Epoch 1345/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 992232.0000 - val_loss: 853683.8125\n",
            "Epoch 1346/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 721936.0000 - val_loss: 849942.5000\n",
            "Epoch 1347/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 347462.4688 - val_loss: 381929.7812\n",
            "Epoch 1348/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 170947.3438 - val_loss: 389983.4375\n",
            "Epoch 1349/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 185603.6719 - val_loss: 319698.9062\n",
            "Epoch 1350/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 166728.5000 - val_loss: 290455.2188\n",
            "Epoch 1351/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 275736.7812 - val_loss: 1159475.6250\n",
            "Epoch 1352/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 373718.2812 - val_loss: 458452.8750\n",
            "Epoch 1353/3000\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 146401.1250 - val_loss: 383277.7500\n",
            "Epoch 1354/3000\n",
            "66/66 [==============================] - 7s 113ms/step - loss: 241515.4531 - val_loss: 430617.6250\n",
            "Epoch 1355/3000\n",
            "66/66 [==============================] - 7s 111ms/step - loss: 307646.7812 - val_loss: 583898.6875\n",
            "Epoch 1356/3000\n",
            "66/66 [==============================] - 7s 113ms/step - loss: 184597.1250 - val_loss: 372111.9688\n",
            "Epoch 1357/3000\n",
            "66/66 [==============================] - 7s 110ms/step - loss: 440274.1875 - val_loss: 149248.4062\n",
            "Epoch 1358/3000\n",
            "66/66 [==============================] - 7s 109ms/step - loss: 123553.4922 - val_loss: 387144.4688\n",
            "Epoch 1359/3000\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 133777.2344 - val_loss: 183292.5938\n",
            "Epoch 1360/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 85817.7891 - val_loss: 137107.2500\n",
            "Epoch 1361/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 342795.7812 - val_loss: 1010230.4375\n",
            "Epoch 1362/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 1105179.7500 - val_loss: 935589.5000\n",
            "Epoch 1363/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 466646.5312 - val_loss: 208483.1562\n",
            "Epoch 1364/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 464364.1562 - val_loss: 225707.7969\n",
            "Epoch 1365/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 369326.2188 - val_loss: 484899.0938\n",
            "Epoch 1366/3000\n",
            "66/66 [==============================] - 7s 112ms/step - loss: 1100148.8750 - val_loss: 1792175.1250\n",
            "Epoch 1367/3000\n",
            "66/66 [==============================] - 7s 106ms/step - loss: 1065636.0000 - val_loss: 1448779.0000\n",
            "Epoch 1368/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 1440658.5000 - val_loss: 458631.5000\n",
            "Epoch 1369/3000\n",
            "66/66 [==============================] - 7s 107ms/step - loss: 1643068.1250 - val_loss: 1397054.0000\n",
            "Epoch 1370/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 2824834.2500 - val_loss: 658598.5000\n",
            "Epoch 1371/3000\n",
            "66/66 [==============================] - 7s 112ms/step - loss: 901347.9375 - val_loss: 1633449.8750\n",
            "Epoch 1372/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 799997.8125 - val_loss: 1022770.8750\n",
            "Epoch 1373/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 1054514.6250 - val_loss: 1355073.8750\n",
            "Epoch 1374/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 890212.7500 - val_loss: 552216.4375\n",
            "Epoch 1375/3000\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 920427.3750 - val_loss: 761529.6875\n",
            "Epoch 1376/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 804650.4375 - val_loss: 1703564.5000\n",
            "Epoch 1377/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 633347.5625 - val_loss: 338600.0312\n",
            "Epoch 1378/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 543973.6875 - val_loss: 247023.5156\n",
            "Epoch 1379/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 273022.0312 - val_loss: 206130.9844\n",
            "Epoch 1380/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 174309.0938 - val_loss: 288977.0625\n",
            "Epoch 1381/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 194542.2812 - val_loss: 1428153.7500\n",
            "Epoch 1382/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 487704.6562 - val_loss: 284499.5000\n",
            "Epoch 1383/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 4387231.0000 - val_loss: 6224605.5000\n",
            "Epoch 1384/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 3999736.5000 - val_loss: 660655.8125\n",
            "Epoch 1385/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 3170908.2500 - val_loss: 9000830.0000\n",
            "Epoch 1386/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 2719986.0000 - val_loss: 1668019.2500\n",
            "Epoch 1387/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 585575.7500 - val_loss: 335388.1562\n",
            "Epoch 1388/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 195600.6250 - val_loss: 345342.5625\n",
            "Epoch 1389/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 386362.8125 - val_loss: 287054.7500\n",
            "Epoch 1390/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 364224.4688 - val_loss: 209631.5625\n",
            "Epoch 1391/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 2405595.7500 - val_loss: 13619874.0000\n",
            "Epoch 1392/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 2845336.5000 - val_loss: 3219457.0000\n",
            "Epoch 1393/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 4610868.5000 - val_loss: 779290.6875\n",
            "Epoch 1394/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 441492.8750 - val_loss: 342286.8438\n",
            "Epoch 1395/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 331978.5312 - val_loss: 278516.5000\n",
            "Epoch 1396/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 325222.9688 - val_loss: 252813.8281\n",
            "Epoch 1397/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 218550.6250 - val_loss: 1095877.7500\n",
            "Epoch 1398/3000\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 929970.1250 - val_loss: 10563636.0000\n",
            "Epoch 1399/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 2819751.2500 - val_loss: 989389.5625\n",
            "Epoch 1400/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 691875.6250 - val_loss: 502919.5625\n",
            "Epoch 1401/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 695881.5000 - val_loss: 357784.0000\n",
            "Epoch 1402/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 588167.4375 - val_loss: 238639.8125\n",
            "Epoch 1403/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 1717373.7500 - val_loss: 2053206.6250\n",
            "Epoch 1404/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 880889.5000 - val_loss: 609635.3750\n",
            "Epoch 1405/3000\n",
            "66/66 [==============================] - 8s 114ms/step - loss: 998933.6250 - val_loss: 1408551.8750\n",
            "Epoch 1406/3000\n",
            "66/66 [==============================] - 7s 111ms/step - loss: 3722185.7500 - val_loss: 1089098.0000\n",
            "Epoch 1407/3000\n",
            "66/66 [==============================] - 8s 116ms/step - loss: 1163277.0000 - val_loss: 589625.3750\n",
            "Epoch 1408/3000\n",
            "66/66 [==============================] - 7s 113ms/step - loss: 498906.0625 - val_loss: 1189015.5000\n",
            "Epoch 1409/3000\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 1294424.7500 - val_loss: 1987670.8750\n",
            "Epoch 1410/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 293693.5625 - val_loss: 525548.1250\n",
            "Epoch 1411/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 416736.6250 - val_loss: 3132000.5000\n",
            "Epoch 1412/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 1890810.6250 - val_loss: 1286002.5000\n",
            "Epoch 1413/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 844231.4375 - val_loss: 413364.8750\n",
            "Epoch 1414/3000\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 750619.6875 - val_loss: 2364114.7500\n",
            "Epoch 1415/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 3731087.5000 - val_loss: 1497446.5000\n",
            "Epoch 1416/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 6788142.0000 - val_loss: 5771917.5000\n",
            "Epoch 1417/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 2357302.7500 - val_loss: 723880.6875\n",
            "Epoch 1418/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 372433.6250 - val_loss: 586372.7500\n",
            "Epoch 1419/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 503312.9688 - val_loss: 261926.4531\n",
            "Epoch 1420/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 111152.2812 - val_loss: 510575.5000\n",
            "Epoch 1421/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 268000.6875 - val_loss: 361520.9375\n",
            "Epoch 1422/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 469753.7188 - val_loss: 183086.6094\n",
            "Epoch 1423/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 241252.3594 - val_loss: 476340.5000\n",
            "Epoch 1424/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 184565.5000 - val_loss: 220861.4062\n",
            "Epoch 1425/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 188034.7656 - val_loss: 224114.2344\n",
            "Epoch 1426/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 279781.8750 - val_loss: 997983.7500\n",
            "Epoch 1427/3000\n",
            "66/66 [==============================] - 6s 87ms/step - loss: 344774.7188 - val_loss: 489635.1875\n",
            "Epoch 1428/3000\n",
            "66/66 [==============================] - 6s 88ms/step - loss: 301292.7188 - val_loss: 555964.9375\n",
            "Epoch 1429/3000\n",
            "66/66 [==============================] - 6s 89ms/step - loss: 671833.5000 - val_loss: 1606379.0000\n",
            "Epoch 1430/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 823458.8125 - val_loss: 1383811.6250\n",
            "Epoch 1431/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 9129991.0000 - val_loss: 2009480.0000\n",
            "Epoch 1432/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 2283531.0000 - val_loss: 463613.5312\n",
            "Epoch 1433/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 1123021.0000 - val_loss: 603803.2500\n",
            "Epoch 1434/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 999725.6250 - val_loss: 716708.1250\n",
            "Epoch 1435/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 948478.3125 - val_loss: 595872.5000\n",
            "Epoch 1436/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 1168710.6250 - val_loss: 1403334.5000\n",
            "Epoch 1437/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 655290.3750 - val_loss: 731153.6875\n",
            "Epoch 1438/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 1472340.0000 - val_loss: 447416.1250\n",
            "Epoch 1439/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 900729.1250 - val_loss: 530232.1875\n",
            "Epoch 1440/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 455869.9375 - val_loss: 585978.2500\n",
            "Epoch 1441/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 1727027.1250 - val_loss: 1369078.6250\n",
            "Epoch 1442/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 588683.8750 - val_loss: 1454287.0000\n",
            "Epoch 1443/3000\n",
            "66/66 [==============================] - 8s 114ms/step - loss: 1060431.0000 - val_loss: 1435528.8750\n",
            "Epoch 1444/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 864791.2500 - val_loss: 1308264.1250\n",
            "Epoch 1445/3000\n",
            "66/66 [==============================] - 8s 116ms/step - loss: 326033.6875 - val_loss: 106148.1094\n",
            "Epoch 1446/3000\n",
            "66/66 [==============================] - 8s 116ms/step - loss: 218046.1406 - val_loss: 1868188.8750\n",
            "Epoch 1447/3000\n",
            "66/66 [==============================] - 8s 115ms/step - loss: 424751.9688 - val_loss: 304400.6250\n",
            "Epoch 1448/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 312255.0312 - val_loss: 1135157.5000\n",
            "Epoch 1449/3000\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 2321002.5000 - val_loss: 512510.0000\n",
            "Epoch 1450/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 14187042.0000 - val_loss: 20767326.0000\n",
            "Epoch 1451/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 7474926.5000 - val_loss: 1559750.1250\n",
            "Epoch 1452/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 1801842.8750 - val_loss: 826584.9375\n",
            "Epoch 1453/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 601814.0625 - val_loss: 1747487.0000\n",
            "Epoch 1454/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 347765.0625 - val_loss: 1768843.8750\n",
            "Epoch 1455/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 1312278.0000 - val_loss: 1662089.6250\n",
            "Epoch 1456/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 691502.8125 - val_loss: 174543.8906\n",
            "Epoch 1457/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 109005.2109 - val_loss: 164125.0156\n",
            "Epoch 1458/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 106881.1328 - val_loss: 137477.2656\n",
            "Epoch 1459/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 665888.7500 - val_loss: 161492.1719\n",
            "Epoch 1460/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 266365.3750 - val_loss: 89702.0547\n",
            "Epoch 1461/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 620209.4375 - val_loss: 825869.3750\n",
            "Epoch 1462/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 421312.1875 - val_loss: 424690.0625\n",
            "Epoch 1463/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 400114.8438 - val_loss: 969378.5625\n",
            "Epoch 1464/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 1434060.8750 - val_loss: 702452.8750\n",
            "Epoch 1465/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 320958.1250 - val_loss: 265496.7188\n",
            "Epoch 1466/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 265030.0938 - val_loss: 610908.7500\n",
            "Epoch 1467/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 272745.8125 - val_loss: 303511.2812\n",
            "Epoch 1468/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 139811.4531 - val_loss: 209412.5156\n",
            "Epoch 1469/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 224264.0469 - val_loss: 394098.0312\n",
            "Epoch 1470/3000\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 75958.3516 - val_loss: 185818.4375\n",
            "Epoch 1471/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 1188246.0000 - val_loss: 441014.0312\n",
            "Epoch 1472/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 319286.2812 - val_loss: 158104.0625\n",
            "Epoch 1473/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 499987.7500 - val_loss: 174230.9688\n",
            "Epoch 1474/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 189271.4375 - val_loss: 524174.9375\n",
            "Epoch 1475/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 375688.1562 - val_loss: 733797.0625\n",
            "Epoch 1476/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 10458832.0000 - val_loss: 27040534.0000\n",
            "Epoch 1477/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 20794088.0000 - val_loss: 9521333.0000\n",
            "Epoch 1478/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 9828499.0000 - val_loss: 3192440.7500\n",
            "Epoch 1479/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 1209315.0000 - val_loss: 1160882.6250\n",
            "Epoch 1480/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 612341.3125 - val_loss: 796227.8125\n",
            "Epoch 1481/3000\n",
            "66/66 [==============================] - 7s 112ms/step - loss: 212889.9844 - val_loss: 286954.9062\n",
            "Epoch 1482/3000\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 341332.5312 - val_loss: 564777.2500\n",
            "Epoch 1483/3000\n",
            "66/66 [==============================] - 7s 112ms/step - loss: 108300.5078 - val_loss: 513691.3750\n",
            "Epoch 1484/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 546890.1250 - val_loss: 1104223.7500\n",
            "Epoch 1485/3000\n",
            "66/66 [==============================] - 8s 116ms/step - loss: 396810.7188 - val_loss: 353973.0938\n",
            "Epoch 1486/3000\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 269602.3750 - val_loss: 281057.1250\n",
            "Epoch 1487/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 180172.2188 - val_loss: 107946.9844\n",
            "Epoch 1488/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 122264.1875 - val_loss: 301133.6562\n",
            "Epoch 1489/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 183597.3906 - val_loss: 167886.5781\n",
            "Epoch 1490/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 181683.5625 - val_loss: 908112.1250\n",
            "Epoch 1491/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 402045.7188 - val_loss: 284099.6875\n",
            "Epoch 1492/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 923973.5625 - val_loss: 1303632.2500\n",
            "Epoch 1493/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 4304468.5000 - val_loss: 1566390.6250\n",
            "Epoch 1494/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 9088056.0000 - val_loss: 2958367.7500\n",
            "Epoch 1495/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 1397317.6250 - val_loss: 256382.6562\n",
            "Epoch 1496/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 795756.1250 - val_loss: 478163.1250\n",
            "Epoch 1497/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 214458.9688 - val_loss: 331105.0938\n",
            "Epoch 1498/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 109441.1172 - val_loss: 226407.9688\n",
            "Epoch 1499/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 309341.5312 - val_loss: 1769472.2500\n",
            "Epoch 1500/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 412202.5000 - val_loss: 179507.4375\n",
            "Epoch 1501/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 163042.9375 - val_loss: 123776.0547\n",
            "Epoch 1502/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 1160058.6250 - val_loss: 382997.3125\n",
            "Epoch 1503/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 780262.0000 - val_loss: 241614.1719\n",
            "Epoch 1504/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 857340.4375 - val_loss: 3217537.2500\n",
            "Epoch 1505/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 3418250.0000 - val_loss: 767016.8750\n",
            "Epoch 1506/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 1399398.3750 - val_loss: 2034895.3750\n",
            "Epoch 1507/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 511316.1562 - val_loss: 508406.3438\n",
            "Epoch 1508/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 215975.8125 - val_loss: 698963.1250\n",
            "Epoch 1509/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 133300.5469 - val_loss: 196956.0156\n",
            "Epoch 1510/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 109137.7500 - val_loss: 133799.0000\n",
            "Epoch 1511/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 193955.4688 - val_loss: 264944.1875\n",
            "Epoch 1512/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 143551.4844 - val_loss: 271630.0312\n",
            "Epoch 1513/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 187920.7969 - val_loss: 133364.9531\n",
            "Epoch 1514/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 213719.1719 - val_loss: 290776.8750\n",
            "Epoch 1515/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 597533.6250 - val_loss: 1438361.3750\n",
            "Epoch 1516/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 930844.6875 - val_loss: 326449.5625\n",
            "Epoch 1517/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 487120.5938 - val_loss: 2161583.2500\n",
            "Epoch 1518/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 5302525.0000 - val_loss: 5863978.5000\n",
            "Epoch 1519/3000\n",
            "66/66 [==============================] - 7s 107ms/step - loss: 4293508.0000 - val_loss: 441505.0625\n",
            "Epoch 1520/3000\n",
            "66/66 [==============================] - 8s 116ms/step - loss: 1152286.0000 - val_loss: 561221.3750\n",
            "Epoch 1521/3000\n",
            "66/66 [==============================] - 8s 115ms/step - loss: 980174.4375 - val_loss: 624350.1250\n",
            "Epoch 1522/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 814238.9375 - val_loss: 623941.3750\n",
            "Epoch 1523/3000\n",
            "66/66 [==============================] - 8s 117ms/step - loss: 316370.9375 - val_loss: 422665.3125\n",
            "Epoch 1524/3000\n",
            "66/66 [==============================] - 7s 109ms/step - loss: 147737.6094 - val_loss: 249865.2188\n",
            "Epoch 1525/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 1076918.7500 - val_loss: 5298521.5000\n",
            "Epoch 1526/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 2148785.2500 - val_loss: 319364.5000\n",
            "Epoch 1527/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 423768.3750 - val_loss: 154069.2656\n",
            "Epoch 1528/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 389187.7812 - val_loss: 673953.5625\n",
            "Epoch 1529/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 341716.3438 - val_loss: 137664.6406\n",
            "Epoch 1530/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 503454.3750 - val_loss: 599275.4375\n",
            "Epoch 1531/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 467604.6875 - val_loss: 116245.1172\n",
            "Epoch 1532/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 412636.1250 - val_loss: 1860643.0000\n",
            "Epoch 1533/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 2346276.2500 - val_loss: 3278820.5000\n",
            "Epoch 1534/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 2958985.7500 - val_loss: 2744123.0000\n",
            "Epoch 1535/3000\n",
            "66/66 [==============================] - 6s 99ms/step - loss: 2969071.7500 - val_loss: 1105160.1250\n",
            "Epoch 1536/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 580016.0625 - val_loss: 335248.9062\n",
            "Epoch 1537/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 553911.5625 - val_loss: 807553.7500\n",
            "Epoch 1538/3000\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 365693.7500 - val_loss: 178147.6094\n",
            "Epoch 1539/3000\n",
            "66/66 [==============================] - 7s 113ms/step - loss: 344504.0000 - val_loss: 298868.6875\n",
            "Epoch 1540/3000\n",
            "66/66 [==============================] - 7s 110ms/step - loss: 536676.9375 - val_loss: 2595771.7500\n",
            "Epoch 1541/3000\n",
            "66/66 [==============================] - 8s 118ms/step - loss: 11556981.0000 - val_loss: 5928423.5000\n",
            "Epoch 1542/3000\n",
            "66/66 [==============================] - 7s 107ms/step - loss: 4250462.5000 - val_loss: 398681.5000\n",
            "Epoch 1543/3000\n",
            "66/66 [==============================] - 7s 112ms/step - loss: 525316.3750 - val_loss: 262214.0938\n",
            "Epoch 1544/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 252574.5469 - val_loss: 406495.6250\n",
            "Epoch 1545/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 401320.0000 - val_loss: 343665.2500\n",
            "Epoch 1546/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 511845.9375 - val_loss: 339836.7500\n",
            "Epoch 1547/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 818366.5000 - val_loss: 521794.3125\n",
            "Epoch 1548/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 649598.7500 - val_loss: 664880.5625\n",
            "Epoch 1549/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 519804.5938 - val_loss: 3633193.7500\n",
            "Epoch 1550/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 4622124.0000 - val_loss: 2968280.5000\n",
            "Epoch 1551/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 2106768.0000 - val_loss: 521307.8750\n",
            "Epoch 1552/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 534539.7500 - val_loss: 336956.2188\n",
            "Epoch 1553/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 525048.8750 - val_loss: 502020.1250\n",
            "Epoch 1554/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 233901.3125 - val_loss: 166185.3750\n",
            "Epoch 1555/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 110650.9609 - val_loss: 163332.3438\n",
            "Epoch 1556/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 168961.2031 - val_loss: 138545.5156\n",
            "Epoch 1557/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 131496.4062 - val_loss: 309682.4688\n",
            "Epoch 1558/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 277928.0938 - val_loss: 390925.0312\n",
            "Epoch 1559/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 233125.1406 - val_loss: 482622.5312\n",
            "Epoch 1560/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 280673.0625 - val_loss: 309440.0000\n",
            "Epoch 1561/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 288340.2812 - val_loss: 1385269.5000\n",
            "Epoch 1562/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 970233.6250 - val_loss: 1502299.8750\n",
            "Epoch 1563/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 1406081.0000 - val_loss: 161819.0469\n",
            "Epoch 1564/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 277433.0312 - val_loss: 183398.3906\n",
            "Epoch 1565/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 209239.9844 - val_loss: 381399.9375\n",
            "Epoch 1566/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 4938912.0000 - val_loss: 13361762.0000\n",
            "Epoch 1567/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 48662172.0000 - val_loss: 8479666.0000\n",
            "Epoch 1568/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 3218182.0000 - val_loss: 460284.5000\n",
            "Epoch 1569/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 664934.6250 - val_loss: 898307.5000\n",
            "Epoch 1570/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 322101.0312 - val_loss: 395747.6875\n",
            "Epoch 1571/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 169653.8594 - val_loss: 144318.6562\n",
            "Epoch 1572/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 170711.5469 - val_loss: 186083.7500\n",
            "Epoch 1573/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 115038.2656 - val_loss: 189598.3906\n",
            "Epoch 1574/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 122834.8203 - val_loss: 127295.7969\n",
            "Epoch 1575/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 96388.8359 - val_loss: 87614.8125\n",
            "Epoch 1576/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 59140.8047 - val_loss: 104569.2422\n",
            "Epoch 1577/3000\n",
            "66/66 [==============================] - 8s 114ms/step - loss: 103470.1719 - val_loss: 114548.1016\n",
            "Epoch 1578/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 69245.0078 - val_loss: 112650.1562\n",
            "Epoch 1579/3000\n",
            "66/66 [==============================] - 7s 112ms/step - loss: 99421.9766 - val_loss: 99707.8594\n",
            "Epoch 1580/3000\n",
            "66/66 [==============================] - 7s 112ms/step - loss: 94378.7812 - val_loss: 370682.2812\n",
            "Epoch 1581/3000\n",
            "66/66 [==============================] - 8s 114ms/step - loss: 106813.5938 - val_loss: 181586.9844\n",
            "Epoch 1582/3000\n",
            "66/66 [==============================] - 7s 106ms/step - loss: 67389.2969 - val_loss: 111993.7969\n",
            "Epoch 1583/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 91980.5469 - val_loss: 121434.3438\n",
            "Epoch 1584/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 194517.9531 - val_loss: 1655720.6250\n",
            "Epoch 1585/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 776862.3750 - val_loss: 131640.1875\n",
            "Epoch 1586/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 122258.0391 - val_loss: 325492.1250\n",
            "Epoch 1587/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 130577.4141 - val_loss: 103198.9766\n",
            "Epoch 1588/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 280308.2500 - val_loss: 125186.4141\n",
            "Epoch 1589/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 140559.7344 - val_loss: 79162.4453\n",
            "Epoch 1590/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 154503.2188 - val_loss: 183560.2031\n",
            "Epoch 1591/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 83748.1797 - val_loss: 152212.7969\n",
            "Epoch 1592/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 77538.9375 - val_loss: 147303.7812\n",
            "Epoch 1593/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 85945.0156 - val_loss: 149272.4844\n",
            "Epoch 1594/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 127261.5469 - val_loss: 131836.9375\n",
            "Epoch 1595/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 115551.1719 - val_loss: 216754.8906\n",
            "Epoch 1596/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 171974.0781 - val_loss: 296229.3125\n",
            "Epoch 1597/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 650915.5625 - val_loss: 314161.2500\n",
            "Epoch 1598/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 368547.5938 - val_loss: 769590.4375\n",
            "Epoch 1599/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 668676.0000 - val_loss: 1273589.3750\n",
            "Epoch 1600/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 6096122.0000 - val_loss: 3227461.5000\n",
            "Epoch 1601/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 3817781.0000 - val_loss: 3238957.0000\n",
            "Epoch 1602/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 1896453.7500 - val_loss: 1930650.6250\n",
            "Epoch 1603/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 614809.3125 - val_loss: 515171.6250\n",
            "Epoch 1604/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 522631.4688 - val_loss: 810399.9375\n",
            "Epoch 1605/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 364877.2500 - val_loss: 213310.0156\n",
            "Epoch 1606/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 91215.8672 - val_loss: 153947.0000\n",
            "Epoch 1607/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 174507.4688 - val_loss: 405506.6250\n",
            "Epoch 1608/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 600146.5625 - val_loss: 420120.2812\n",
            "Epoch 1609/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 718299.6875 - val_loss: 3203541.2500\n",
            "Epoch 1610/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 1536076.3750 - val_loss: 1427468.2500\n",
            "Epoch 1611/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 2618148.5000 - val_loss: 996487.4375\n",
            "Epoch 1612/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 769110.6250 - val_loss: 1430181.2500\n",
            "Epoch 1613/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 522503.1562 - val_loss: 1260327.6250\n",
            "Epoch 1614/3000\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 838155.4375 - val_loss: 500284.2500\n",
            "Epoch 1615/3000\n",
            "66/66 [==============================] - 8s 115ms/step - loss: 192496.1562 - val_loss: 148894.8750\n",
            "Epoch 1616/3000\n",
            "66/66 [==============================] - 7s 113ms/step - loss: 154763.6562 - val_loss: 125598.5312\n",
            "Epoch 1617/3000\n",
            "66/66 [==============================] - 7s 113ms/step - loss: 237107.8750 - val_loss: 383560.0625\n",
            "Epoch 1618/3000\n",
            "66/66 [==============================] - 7s 107ms/step - loss: 283796.2500 - val_loss: 419808.3125\n",
            "Epoch 1619/3000\n",
            "66/66 [==============================] - 7s 110ms/step - loss: 157664.6250 - val_loss: 162121.2500\n",
            "Epoch 1620/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 652146.1875 - val_loss: 1931748.5000\n",
            "Epoch 1621/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 3791882.2500 - val_loss: 1903947.0000\n",
            "Epoch 1622/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 4096619.7500 - val_loss: 1292711.5000\n",
            "Epoch 1623/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 1388926.7500 - val_loss: 1490121.7500\n",
            "Epoch 1624/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 5432040.5000 - val_loss: 2049449.1250\n",
            "Epoch 1625/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 2278598.0000 - val_loss: 1051173.7500\n",
            "Epoch 1626/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 1450612.3750 - val_loss: 626101.1250\n",
            "Epoch 1627/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 543192.6250 - val_loss: 491901.4375\n",
            "Epoch 1628/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 201840.5156 - val_loss: 102834.3750\n",
            "Epoch 1629/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 132241.0625 - val_loss: 255745.0781\n",
            "Epoch 1630/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 140227.0156 - val_loss: 1874291.5000\n",
            "Epoch 1631/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 5942181.0000 - val_loss: 21474258.0000\n",
            "Epoch 1632/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 53511920.0000 - val_loss: 25984738.0000\n",
            "Epoch 1633/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 5107505.5000 - val_loss: 340524.5000\n",
            "Epoch 1634/3000\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 326729.9688 - val_loss: 404147.4375\n",
            "Epoch 1635/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 241244.2969 - val_loss: 178461.0312\n",
            "Epoch 1636/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 109458.9141 - val_loss: 164540.5625\n",
            "Epoch 1637/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 167292.8594 - val_loss: 211869.8125\n",
            "Epoch 1638/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 100267.6328 - val_loss: 174549.5469\n",
            "Epoch 1639/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 68872.8203 - val_loss: 151968.1250\n",
            "Epoch 1640/3000\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 85183.0312 - val_loss: 245741.5781\n",
            "Epoch 1641/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 79611.4766 - val_loss: 109549.6797\n",
            "Epoch 1642/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 81599.9375 - val_loss: 212785.0469\n",
            "Epoch 1643/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 97886.5469 - val_loss: 109970.8828\n",
            "Epoch 1644/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 53991.4844 - val_loss: 87180.5703\n",
            "Epoch 1645/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 84950.3984 - val_loss: 102732.6250\n",
            "Epoch 1646/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 65535.2773 - val_loss: 164797.4844\n",
            "Epoch 1647/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 61269.3516 - val_loss: 74231.8125\n",
            "Epoch 1648/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 73215.5938 - val_loss: 251861.4375\n",
            "Epoch 1649/3000\n",
            "66/66 [==============================] - 7s 105ms/step - loss: 105398.5156 - val_loss: 172169.2656\n",
            "Epoch 1650/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 131922.1250 - val_loss: 153050.3281\n",
            "Epoch 1651/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 89466.1328 - val_loss: 112320.0703\n",
            "Epoch 1652/3000\n",
            "66/66 [==============================] - 7s 113ms/step - loss: 60390.9844 - val_loss: 129424.1875\n",
            "Epoch 1653/3000\n",
            "66/66 [==============================] - 7s 112ms/step - loss: 48291.1523 - val_loss: 94931.1250\n",
            "Epoch 1654/3000\n",
            "66/66 [==============================] - 8s 116ms/step - loss: 88229.1016 - val_loss: 140694.2500\n",
            "Epoch 1655/3000\n",
            "66/66 [==============================] - 8s 114ms/step - loss: 112287.4297 - val_loss: 142010.5469\n",
            "Epoch 1656/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 259440.5781 - val_loss: 172848.9531\n",
            "Epoch 1657/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 240986.6406 - val_loss: 354656.4062\n",
            "Epoch 1658/3000\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 133293.4219 - val_loss: 135075.1719\n",
            "Epoch 1659/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 138131.2969 - val_loss: 435998.6875\n",
            "Epoch 1660/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 429529.7812 - val_loss: 444811.1250\n",
            "Epoch 1661/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 291074.3438 - val_loss: 199855.4688\n",
            "Epoch 1662/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 171172.7812 - val_loss: 260656.5469\n",
            "Epoch 1663/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 360779.6562 - val_loss: 2649531.0000\n",
            "Epoch 1664/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 4137382.2500 - val_loss: 490973.0938\n",
            "Epoch 1665/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 1043914.4375 - val_loss: 1924552.6250\n",
            "Epoch 1666/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 1690630.5000 - val_loss: 1972004.2500\n",
            "Epoch 1667/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 1475554.5000 - val_loss: 553730.0000\n",
            "Epoch 1668/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 1140129.5000 - val_loss: 181928.6406\n",
            "Epoch 1669/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 278455.5000 - val_loss: 55130.3008\n",
            "Epoch 1670/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 626781.8125 - val_loss: 1534745.5000\n",
            "Epoch 1671/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 4118409.5000 - val_loss: 2522025.2500\n",
            "Epoch 1672/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 2607568.2500 - val_loss: 1592552.5000\n",
            "Epoch 1673/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 438891.5000 - val_loss: 225901.4531\n",
            "Epoch 1674/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 253204.6719 - val_loss: 361270.0938\n",
            "Epoch 1675/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 285407.0312 - val_loss: 247592.4844\n",
            "Epoch 1676/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 493292.5938 - val_loss: 524582.7500\n",
            "Epoch 1677/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 370833.2188 - val_loss: 170668.3906\n",
            "Epoch 1678/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 327708.0938 - val_loss: 292651.9062\n",
            "Epoch 1679/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 2770956.0000 - val_loss: 2736645.7500\n",
            "Epoch 1680/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 3977701.0000 - val_loss: 1403446.2500\n",
            "Epoch 1681/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 1159534.1250 - val_loss: 502206.8438\n",
            "Epoch 1682/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 431094.0000 - val_loss: 402804.5312\n",
            "Epoch 1683/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 424322.5312 - val_loss: 294071.7812\n",
            "Epoch 1684/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 254474.9375 - val_loss: 650345.3750\n",
            "Epoch 1685/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 183965.9062 - val_loss: 102923.6641\n",
            "Epoch 1686/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 101883.4531 - val_loss: 163303.6562\n",
            "Epoch 1687/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 323592.8125 - val_loss: 137474.4219\n",
            "Epoch 1688/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 183569.5156 - val_loss: 177121.5938\n",
            "Epoch 1689/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 418846.9688 - val_loss: 330878.9062\n",
            "Epoch 1690/3000\n",
            "66/66 [==============================] - 8s 114ms/step - loss: 3108151.5000 - val_loss: 6026084.5000\n",
            "Epoch 1691/3000\n",
            "66/66 [==============================] - 8s 116ms/step - loss: 1112580.0000 - val_loss: 196642.9375\n",
            "Epoch 1692/3000\n",
            "66/66 [==============================] - 7s 113ms/step - loss: 242533.5781 - val_loss: 664067.1250\n",
            "Epoch 1693/3000\n",
            "66/66 [==============================] - 8s 114ms/step - loss: 145993.9688 - val_loss: 269833.5312\n",
            "Epoch 1694/3000\n",
            "66/66 [==============================] - 7s 112ms/step - loss: 335613.6875 - val_loss: 1215181.1250\n",
            "Epoch 1695/3000\n",
            "66/66 [==============================] - 7s 102ms/step - loss: 545725.8125 - val_loss: 488318.0000\n",
            "Epoch 1696/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 287747.6250 - val_loss: 201889.9375\n",
            "Epoch 1697/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 166646.0469 - val_loss: 84166.5703\n",
            "Epoch 1698/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 224087.9688 - val_loss: 676449.1250\n",
            "Epoch 1699/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 3353345.0000 - val_loss: 18236926.0000\n",
            "Epoch 1700/3000\n",
            "66/66 [==============================] - 7s 112ms/step - loss: 4025306.7500 - val_loss: 2016880.3750\n",
            "Epoch 1701/3000\n",
            "66/66 [==============================] - 7s 111ms/step - loss: 820779.3750 - val_loss: 2916901.2500\n",
            "Epoch 1702/3000\n",
            "66/66 [==============================] - 8s 115ms/step - loss: 735882.2500 - val_loss: 505777.3750\n",
            "Epoch 1703/3000\n",
            "66/66 [==============================] - 8s 117ms/step - loss: 573948.0625 - val_loss: 1416051.1250\n",
            "Epoch 1704/3000\n",
            "66/66 [==============================] - 7s 109ms/step - loss: 353771.5938 - val_loss: 258925.4375\n",
            "Epoch 1705/3000\n",
            "66/66 [==============================] - 7s 106ms/step - loss: 346804.3750 - val_loss: 354968.8125\n",
            "Epoch 1706/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 502960.2812 - val_loss: 274199.5625\n",
            "Epoch 1707/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 592231.9375 - val_loss: 616948.8125\n",
            "Epoch 1708/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 435558.5625 - val_loss: 507832.2812\n",
            "Epoch 1709/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 471392.5312 - val_loss: 58144.3203\n",
            "Epoch 1710/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 121874.9141 - val_loss: 248568.9688\n",
            "Epoch 1711/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 476617.7500 - val_loss: 1436674.7500\n",
            "Epoch 1712/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 4004299.2500 - val_loss: 12557610.0000\n",
            "Epoch 1713/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 4279700.0000 - val_loss: 15690405.0000\n",
            "Epoch 1714/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 4260346.5000 - val_loss: 851752.8750\n",
            "Epoch 1715/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 408513.7500 - val_loss: 363223.3438\n",
            "Epoch 1716/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 638402.3750 - val_loss: 3359573.0000\n",
            "Epoch 1717/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 483300.0000 - val_loss: 1093428.1250\n",
            "Epoch 1718/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 413986.6875 - val_loss: 287458.2188\n",
            "Epoch 1719/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 171152.9531 - val_loss: 657417.4375\n",
            "Epoch 1720/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 149780.5469 - val_loss: 87722.0547\n",
            "Epoch 1721/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 223885.5469 - val_loss: 220013.8594\n",
            "Epoch 1722/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 391568.0625 - val_loss: 418678.3125\n",
            "Epoch 1723/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 625257.3125 - val_loss: 293865.4688\n",
            "Epoch 1724/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 543742.0625 - val_loss: 2310125.5000\n",
            "Epoch 1725/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 1721910.7500 - val_loss: 470814.7812\n",
            "Epoch 1726/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 1486542.0000 - val_loss: 1239032.2500\n",
            "Epoch 1727/3000\n",
            "66/66 [==============================] - 6s 90ms/step - loss: 1406334.8750 - val_loss: 1340772.3750\n",
            "Epoch 1728/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 458381.7500 - val_loss: 2034499.2500\n",
            "Epoch 1729/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 900822.7500 - val_loss: 960972.8125\n",
            "Epoch 1730/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 635779.9375 - val_loss: 201480.0469\n",
            "Epoch 1731/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 311503.0938 - val_loss: 318578.3438\n",
            "Epoch 1732/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 715940.4375 - val_loss: 778017.1250\n",
            "Epoch 1733/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 628882.4375 - val_loss: 640408.8750\n",
            "Epoch 1734/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 761198.1250 - val_loss: 347495.3438\n",
            "Epoch 1735/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 2174918.5000 - val_loss: 1959389.5000\n",
            "Epoch 1736/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 1445852.6250 - val_loss: 358125.0312\n",
            "Epoch 1737/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 741650.5000 - val_loss: 195610.9844\n",
            "Epoch 1738/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 4075718.7500 - val_loss: 3684620.5000\n",
            "Epoch 1739/3000\n",
            "66/66 [==============================] - 7s 110ms/step - loss: 9046767.0000 - val_loss: 8415538.0000\n",
            "Epoch 1740/3000\n",
            "66/66 [==============================] - 8s 117ms/step - loss: 3669790.0000 - val_loss: 2198458.0000\n",
            "Epoch 1741/3000\n",
            "66/66 [==============================] - 7s 106ms/step - loss: 1720304.3750 - val_loss: 340289.3125\n",
            "Epoch 1742/3000\n",
            "66/66 [==============================] - 7s 111ms/step - loss: 446689.3438 - val_loss: 311548.1250\n",
            "Epoch 1743/3000\n",
            "66/66 [==============================] - 7s 111ms/step - loss: 417603.8750 - val_loss: 537902.5625\n",
            "Epoch 1744/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 335022.0625 - val_loss: 154847.1094\n",
            "Epoch 1745/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 283742.5000 - val_loss: 61016.9102\n",
            "Epoch 1746/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 356701.8125 - val_loss: 626072.5000\n",
            "Epoch 1747/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 308496.4062 - val_loss: 455164.9688\n",
            "Epoch 1748/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 309984.2188 - val_loss: 411048.6562\n",
            "Epoch 1749/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 477451.9688 - val_loss: 553408.6875\n",
            "Epoch 1750/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 376223.7188 - val_loss: 2189367.5000\n",
            "Epoch 1751/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 1108163.1250 - val_loss: 1003833.0625\n",
            "Epoch 1752/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 389627.2812 - val_loss: 138846.8281\n",
            "Epoch 1753/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 147700.8594 - val_loss: 135692.6406\n",
            "Epoch 1754/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 490164.5625 - val_loss: 489675.9688\n",
            "Epoch 1755/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 657442.9375 - val_loss: 678088.2500\n",
            "Epoch 1756/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 417166.4062 - val_loss: 292007.3125\n",
            "Epoch 1757/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 588033.8750 - val_loss: 453345.2500\n",
            "Epoch 1758/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 3587760.0000 - val_loss: 4637790.5000\n",
            "Epoch 1759/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 3658712.7500 - val_loss: 500266.7188\n",
            "Epoch 1760/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 1247159.3750 - val_loss: 247497.9688\n",
            "Epoch 1761/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 177817.8125 - val_loss: 400649.0625\n",
            "Epoch 1762/3000\n",
            "66/66 [==============================] - 7s 105ms/step - loss: 288838.7188 - val_loss: 211297.2812\n",
            "Epoch 1763/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 146073.0469 - val_loss: 94546.3281\n",
            "Epoch 1764/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 488723.2812 - val_loss: 583683.6875\n",
            "Epoch 1765/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 136195.7969 - val_loss: 131068.3203\n",
            "Epoch 1766/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 212641.2188 - val_loss: 347767.1250\n",
            "Epoch 1767/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 303902.2500 - val_loss: 408525.2500\n",
            "Epoch 1768/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 547844.3750 - val_loss: 1509809.6250\n",
            "Epoch 1769/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 619586.5625 - val_loss: 1670351.6250\n",
            "Epoch 1770/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 1399541.8750 - val_loss: 1109452.2500\n",
            "Epoch 1771/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 1512520.6250 - val_loss: 4599071.0000\n",
            "Epoch 1772/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 9698993.0000 - val_loss: 3297180.5000\n",
            "Epoch 1773/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 2097715.0000 - val_loss: 2084218.7500\n",
            "Epoch 1774/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 758661.6875 - val_loss: 3613063.0000\n",
            "Epoch 1775/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 6451628.5000 - val_loss: 459440.8438\n",
            "Epoch 1776/3000\n",
            "66/66 [==============================] - 7s 113ms/step - loss: 2102368.7500 - val_loss: 1173204.3750\n",
            "Epoch 1777/3000\n",
            "66/66 [==============================] - 7s 113ms/step - loss: 642094.2500 - val_loss: 870280.8125\n",
            "Epoch 1778/3000\n",
            "66/66 [==============================] - 7s 112ms/step - loss: 295886.6875 - val_loss: 1674625.5000\n",
            "Epoch 1779/3000\n",
            "66/66 [==============================] - 8s 118ms/step - loss: 499485.4688 - val_loss: 226359.9375\n",
            "Epoch 1780/3000\n",
            "66/66 [==============================] - 7s 112ms/step - loss: 415444.6250 - val_loss: 414503.7812\n",
            "Epoch 1781/3000\n",
            "66/66 [==============================] - 7s 107ms/step - loss: 1001235.2500 - val_loss: 1974458.2500\n",
            "Epoch 1782/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 2980806.7500 - val_loss: 5062208.5000\n",
            "Epoch 1783/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 6655528.0000 - val_loss: 5696231.5000\n",
            "Epoch 1784/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 1517204.2500 - val_loss: 3322212.2500\n",
            "Epoch 1785/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 2195350.5000 - val_loss: 884556.1250\n",
            "Epoch 1786/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 271463.8438 - val_loss: 292404.5000\n",
            "Epoch 1787/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 362966.7188 - val_loss: 182745.0469\n",
            "Epoch 1788/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 394920.9375 - val_loss: 230643.2500\n",
            "Epoch 1789/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 290461.5938 - val_loss: 399100.3750\n",
            "Epoch 1790/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 216940.6094 - val_loss: 629044.5000\n",
            "Epoch 1791/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 11574866.0000 - val_loss: 18586708.0000\n",
            "Epoch 1792/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 6658110.5000 - val_loss: 3739998.0000\n",
            "Epoch 1793/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 1783012.1250 - val_loss: 1114092.7500\n",
            "Epoch 1794/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 526819.1250 - val_loss: 516641.7812\n",
            "Epoch 1795/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 165789.7500 - val_loss: 503687.3750\n",
            "Epoch 1796/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 569661.4375 - val_loss: 164699.2656\n",
            "Epoch 1797/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 124320.1484 - val_loss: 146318.4062\n",
            "Epoch 1798/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 159253.2031 - val_loss: 713121.9375\n",
            "Epoch 1799/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 526412.0625 - val_loss: 119218.6094\n",
            "Epoch 1800/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 108639.8594 - val_loss: 47996.8516\n",
            "Epoch 1801/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 75988.2188 - val_loss: 105894.0000\n",
            "Epoch 1802/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 188814.1719 - val_loss: 372337.3750\n",
            "Epoch 1803/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 189092.2969 - val_loss: 1208224.6250\n",
            "Epoch 1804/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 540638.3750 - val_loss: 186409.0156\n",
            "Epoch 1805/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 117707.9453 - val_loss: 398679.1250\n",
            "Epoch 1806/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 921970.1250 - val_loss: 876428.1875\n",
            "Epoch 1807/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 1507535.8750 - val_loss: 958734.1250\n",
            "Epoch 1808/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 1196999.6250 - val_loss: 953730.2500\n",
            "Epoch 1809/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 321989.0312 - val_loss: 160248.0469\n",
            "Epoch 1810/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 120339.6406 - val_loss: 133801.4531\n",
            "Epoch 1811/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 271289.6562 - val_loss: 192402.3125\n",
            "Epoch 1812/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 121042.3906 - val_loss: 163632.6719\n",
            "Epoch 1813/3000\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 73678.6406 - val_loss: 158751.5156\n",
            "Epoch 1814/3000\n",
            "66/66 [==============================] - 7s 109ms/step - loss: 281783.8438 - val_loss: 336793.7188\n",
            "Epoch 1815/3000\n",
            "66/66 [==============================] - 8s 116ms/step - loss: 309217.0938 - val_loss: 61705.3008\n",
            "Epoch 1816/3000\n",
            "66/66 [==============================] - 8s 115ms/step - loss: 159918.0000 - val_loss: 70970.5078\n",
            "Epoch 1817/3000\n",
            "66/66 [==============================] - 8s 116ms/step - loss: 350301.2500 - val_loss: 326707.9062\n",
            "Epoch 1818/3000\n",
            "66/66 [==============================] - 8s 118ms/step - loss: 238060.4219 - val_loss: 855304.8125\n",
            "Epoch 1819/3000\n",
            "66/66 [==============================] - 7s 98ms/step - loss: 537266.0625 - val_loss: 337158.8438\n",
            "Epoch 1820/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 549825.8125 - val_loss: 397723.1250\n",
            "Epoch 1821/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 460023.3438 - val_loss: 631353.2500\n",
            "Epoch 1822/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 2254543.0000 - val_loss: 6320480.0000\n",
            "Epoch 1823/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 3393254.5000 - val_loss: 2798289.7500\n",
            "Epoch 1824/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 2000828.5000 - val_loss: 1940414.2500\n",
            "Epoch 1825/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 2891724.5000 - val_loss: 693101.4375\n",
            "Epoch 1826/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 252058.2500 - val_loss: 437694.8125\n",
            "Epoch 1827/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 1362994.1250 - val_loss: 3676056.2500\n",
            "Epoch 1828/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 5920753.0000 - val_loss: 5847485.5000\n",
            "Epoch 1829/3000\n",
            "66/66 [==============================] - 6s 91ms/step - loss: 2424933.7500 - val_loss: 2371859.5000\n",
            "Epoch 1830/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 740149.0625 - val_loss: 1321829.2500\n",
            "Epoch 1831/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 588016.4375 - val_loss: 712138.9375\n",
            "Epoch 1832/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 352148.1875 - val_loss: 137929.2344\n",
            "Epoch 1833/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 143449.3594 - val_loss: 321798.4062\n",
            "Epoch 1834/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 1995975.1250 - val_loss: 139361.0938\n",
            "Epoch 1835/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 906298.0000 - val_loss: 886331.9375\n",
            "Epoch 1836/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 419225.3438 - val_loss: 360565.6875\n",
            "Epoch 1837/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 301692.8750 - val_loss: 851244.4375\n",
            "Epoch 1838/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 192740.9688 - val_loss: 457116.4688\n",
            "Epoch 1839/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 576446.3750 - val_loss: 858050.5625\n",
            "Epoch 1840/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 326094.6562 - val_loss: 106607.1172\n",
            "Epoch 1841/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 63616.3320 - val_loss: 116050.3906\n",
            "Epoch 1842/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 306824.7188 - val_loss: 170692.8594\n",
            "Epoch 1843/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 287781.4688 - val_loss: 178104.0469\n",
            "Epoch 1844/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 258668.5625 - val_loss: 115015.3281\n",
            "Epoch 1845/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 154758.1875 - val_loss: 257094.2031\n",
            "Epoch 1846/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 429409.5000 - val_loss: 103676.7656\n",
            "Epoch 1847/3000\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 221325.8281 - val_loss: 787604.5000\n",
            "Epoch 1848/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 3551663.5000 - val_loss: 14478680.0000\n",
            "Epoch 1849/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 9825043.0000 - val_loss: 958227.3125\n",
            "Epoch 1850/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 774675.6875 - val_loss: 1042392.9375\n",
            "Epoch 1851/3000\n",
            "66/66 [==============================] - 7s 109ms/step - loss: 404466.6875 - val_loss: 165486.2812\n",
            "Epoch 1852/3000\n",
            "66/66 [==============================] - 8s 118ms/step - loss: 482071.7188 - val_loss: 740396.6250\n",
            "Epoch 1853/3000\n",
            "66/66 [==============================] - 7s 110ms/step - loss: 318896.2812 - val_loss: 422194.8438\n",
            "Epoch 1854/3000\n",
            "66/66 [==============================] - 8s 115ms/step - loss: 126064.0859 - val_loss: 399713.5625\n",
            "Epoch 1855/3000\n",
            "66/66 [==============================] - 8s 117ms/step - loss: 93056.3203 - val_loss: 170650.3281\n",
            "Epoch 1856/3000\n",
            "66/66 [==============================] - 7s 107ms/step - loss: 102937.8438 - val_loss: 306289.1250\n",
            "Epoch 1857/3000\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 221799.2969 - val_loss: 184770.3594\n",
            "Epoch 1858/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 198961.9688 - val_loss: 425380.3438\n",
            "Epoch 1859/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 428860.7500 - val_loss: 200948.0000\n",
            "Epoch 1860/3000\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 469179.4375 - val_loss: 260847.3906\n",
            "Epoch 1861/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 632735.3125 - val_loss: 366956.0938\n",
            "Epoch 1862/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 679132.5625 - val_loss: 416820.9375\n",
            "Epoch 1863/3000\n",
            "66/66 [==============================] - 8s 115ms/step - loss: 3895436.2500 - val_loss: 11773189.0000\n",
            "Epoch 1864/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 4542062.0000 - val_loss: 988417.8125\n",
            "Epoch 1865/3000\n",
            "66/66 [==============================] - 8s 118ms/step - loss: 575767.0625 - val_loss: 144885.8750\n",
            "Epoch 1866/3000\n",
            "66/66 [==============================] - 8s 117ms/step - loss: 420216.3750 - val_loss: 157501.2812\n",
            "Epoch 1867/3000\n",
            "66/66 [==============================] - 7s 109ms/step - loss: 191530.6719 - val_loss: 319265.9062\n",
            "Epoch 1868/3000\n",
            "66/66 [==============================] - 7s 110ms/step - loss: 150344.6250 - val_loss: 146788.1250\n",
            "Epoch 1869/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 174228.5938 - val_loss: 351895.0938\n",
            "Epoch 1870/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 168616.6562 - val_loss: 128744.1172\n",
            "Epoch 1871/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 459756.3125 - val_loss: 4448849.5000\n",
            "Epoch 1872/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 1668054.0000 - val_loss: 417044.0938\n",
            "Epoch 1873/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 458020.8125 - val_loss: 219046.7812\n",
            "Epoch 1874/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 232128.7031 - val_loss: 119427.2344\n",
            "Epoch 1875/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 268859.2188 - val_loss: 655664.1875\n",
            "Epoch 1876/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 181291.6875 - val_loss: 192192.2031\n",
            "Epoch 1877/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 198307.2188 - val_loss: 1603858.5000\n",
            "Epoch 1878/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 929043.3750 - val_loss: 816652.8750\n",
            "Epoch 1879/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 1523096.6250 - val_loss: 2580806.2500\n",
            "Epoch 1880/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 3326446.7500 - val_loss: 933930.3750\n",
            "Epoch 1881/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 1083584.0000 - val_loss: 2806981.0000\n",
            "Epoch 1882/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 6773462.5000 - val_loss: 639413.2500\n",
            "Epoch 1883/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 264037.3750 - val_loss: 251445.7656\n",
            "Epoch 1884/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 669239.8125 - val_loss: 381006.0938\n",
            "Epoch 1885/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 407025.4062 - val_loss: 775971.4375\n",
            "Epoch 1886/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 2552907.7500 - val_loss: 893488.0000\n",
            "Epoch 1887/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 630636.1875 - val_loss: 958757.1250\n",
            "Epoch 1888/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 1465455.2500 - val_loss: 2393194.2500\n",
            "Epoch 1889/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 514720.9062 - val_loss: 283818.3125\n",
            "Epoch 1890/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 358561.9688 - val_loss: 563980.3750\n",
            "Epoch 1891/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 591807.0000 - val_loss: 1971499.2500\n",
            "Epoch 1892/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 1236975.6250 - val_loss: 477037.9375\n",
            "Epoch 1893/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 819552.5000 - val_loss: 184236.1875\n",
            "Epoch 1894/3000\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 249041.2344 - val_loss: 436606.0000\n",
            "Epoch 1895/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 1526226.2500 - val_loss: 2129938.2500\n",
            "Epoch 1896/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 2099466.2500 - val_loss: 1363779.3750\n",
            "Epoch 1897/3000\n",
            "66/66 [==============================] - 7s 107ms/step - loss: 862383.5625 - val_loss: 586973.0000\n",
            "Epoch 1898/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 354652.1562 - val_loss: 168995.5625\n",
            "Epoch 1899/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 220583.5000 - val_loss: 774672.5000\n",
            "Epoch 1900/3000\n",
            "66/66 [==============================] - 8s 118ms/step - loss: 378011.4688 - val_loss: 1358543.7500\n",
            "Epoch 1901/3000\n",
            "66/66 [==============================] - 8s 116ms/step - loss: 1225722.6250 - val_loss: 3674200.5000\n",
            "Epoch 1902/3000\n",
            "66/66 [==============================] - 8s 120ms/step - loss: 15065592.0000 - val_loss: 8909409.0000\n",
            "Epoch 1903/3000\n",
            "66/66 [==============================] - 8s 116ms/step - loss: 9918075.0000 - val_loss: 4029317.0000\n",
            "Epoch 1904/3000\n",
            "66/66 [==============================] - 7s 106ms/step - loss: 982102.5000 - val_loss: 753389.2500\n",
            "Epoch 1905/3000\n",
            "66/66 [==============================] - 7s 104ms/step - loss: 258633.9219 - val_loss: 176198.1562\n",
            "Epoch 1906/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 163573.1875 - val_loss: 141188.9844\n",
            "Epoch 1907/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 186767.2656 - val_loss: 246590.2344\n",
            "Epoch 1908/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 131680.9531 - val_loss: 183602.1094\n",
            "Epoch 1909/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 143333.1875 - val_loss: 219337.8906\n",
            "Epoch 1910/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 124796.2422 - val_loss: 117535.1094\n",
            "Epoch 1911/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 294415.0000 - val_loss: 610643.0000\n",
            "Epoch 1912/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 659196.1250 - val_loss: 343741.6562\n",
            "Epoch 1913/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 278309.0938 - val_loss: 266752.0625\n",
            "Epoch 1914/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 398508.9375 - val_loss: 1354244.8750\n",
            "Epoch 1915/3000\n",
            "66/66 [==============================] - 7s 105ms/step - loss: 1937116.2500 - val_loss: 326538.9688\n",
            "Epoch 1916/3000\n",
            "66/66 [==============================] - 7s 98ms/step - loss: 463670.6562 - val_loss: 259910.8125\n",
            "Epoch 1917/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 148852.2188 - val_loss: 582965.6250\n",
            "Epoch 1918/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 166454.0156 - val_loss: 194908.1406\n",
            "Epoch 1919/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 72988.6797 - val_loss: 83924.9453\n",
            "Epoch 1920/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 60244.1758 - val_loss: 72085.1875\n",
            "Epoch 1921/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 52707.2734 - val_loss: 73240.8281\n",
            "Epoch 1922/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 95203.2188 - val_loss: 36414.7383\n",
            "Epoch 1923/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 222656.7188 - val_loss: 441276.1562\n",
            "Epoch 1924/3000\n",
            "66/66 [==============================] - 7s 107ms/step - loss: 203084.0156 - val_loss: 304704.6875\n",
            "Epoch 1925/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 87850.7578 - val_loss: 80809.0703\n",
            "Epoch 1926/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 458837.0000 - val_loss: 939645.0625\n",
            "Epoch 1927/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 659449.0000 - val_loss: 11459099.0000\n",
            "Epoch 1928/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 1732892.5000 - val_loss: 668548.1875\n",
            "Epoch 1929/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 507208.0938 - val_loss: 844436.6250\n",
            "Epoch 1930/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 1188400.7500 - val_loss: 1026100.8750\n",
            "Epoch 1931/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 5776173.0000 - val_loss: 3708634.5000\n",
            "Epoch 1932/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 1208790.1250 - val_loss: 1177258.2500\n",
            "Epoch 1933/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 339009.3750 - val_loss: 282983.0625\n",
            "Epoch 1934/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 231753.3281 - val_loss: 93639.1328\n",
            "Epoch 1935/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 281819.0312 - val_loss: 373814.4688\n",
            "Epoch 1936/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 93957.5078 - val_loss: 79109.3906\n",
            "Epoch 1937/3000\n",
            "66/66 [==============================] - 8s 115ms/step - loss: 215757.2344 - val_loss: 882180.0000\n",
            "Epoch 1938/3000\n",
            "66/66 [==============================] - 7s 106ms/step - loss: 188948.8125 - val_loss: 74665.4453\n",
            "Epoch 1939/3000\n",
            "66/66 [==============================] - 7s 107ms/step - loss: 636957.1250 - val_loss: 1432519.0000\n",
            "Epoch 1940/3000\n",
            "66/66 [==============================] - 7s 113ms/step - loss: 5608324.5000 - val_loss: 8913001.0000\n",
            "Epoch 1941/3000\n",
            "66/66 [==============================] - 7s 108ms/step - loss: 3846093.5000 - val_loss: 1184747.0000\n",
            "Epoch 1942/3000\n",
            "66/66 [==============================] - 7s 110ms/step - loss: 5610264.0000 - val_loss: 13408567.0000\n",
            "Epoch 1943/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 8400550.0000 - val_loss: 1605803.5000\n",
            "Epoch 1944/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 1202363.8750 - val_loss: 149808.1406\n",
            "Epoch 1945/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 206914.7500 - val_loss: 137062.8281\n",
            "Epoch 1946/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 99399.2422 - val_loss: 80944.7031\n",
            "Epoch 1947/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 91975.1328 - val_loss: 115382.9062\n",
            "Epoch 1948/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 134748.5000 - val_loss: 125342.8750\n",
            "Epoch 1949/3000\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 121864.8828 - val_loss: 89188.2969\n",
            "Epoch 1950/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 83208.6641 - val_loss: 133838.7969\n",
            "Epoch 1951/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 98830.3906 - val_loss: 95936.0156\n",
            "Epoch 1952/3000\n",
            "66/66 [==============================] - 7s 105ms/step - loss: 65684.8906 - val_loss: 135533.1406\n",
            "Epoch 1953/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 131223.9531 - val_loss: 773747.4375\n",
            "Epoch 1954/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 907430.7500 - val_loss: 4874209.5000\n",
            "Epoch 1955/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 3964214.7500 - val_loss: 3842288.0000\n",
            "Epoch 1956/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 5785446.0000 - val_loss: 1278321.1250\n",
            "Epoch 1957/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 6058733.0000 - val_loss: 20474230.0000\n",
            "Epoch 1958/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 9792171.0000 - val_loss: 9795994.0000\n",
            "Epoch 1959/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 4012938.5000 - val_loss: 1320078.6250\n",
            "Epoch 1960/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 458753.0938 - val_loss: 482620.4375\n",
            "Epoch 1961/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 278808.0625 - val_loss: 308437.1562\n",
            "Epoch 1962/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 108847.1016 - val_loss: 82972.5625\n",
            "Epoch 1963/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 101594.9219 - val_loss: 138197.3438\n",
            "Epoch 1964/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 113074.8281 - val_loss: 584237.8750\n",
            "Epoch 1965/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 234931.9688 - val_loss: 91990.2344\n",
            "Epoch 1966/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 70538.3281 - val_loss: 168165.1094\n",
            "Epoch 1967/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 89162.4141 - val_loss: 216880.5938\n",
            "Epoch 1968/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 111511.5078 - val_loss: 164516.3125\n",
            "Epoch 1969/3000\n",
            "66/66 [==============================] - 7s 106ms/step - loss: 503207.8438 - val_loss: 215215.1719\n",
            "Epoch 1970/3000\n",
            "66/66 [==============================] - 7s 98ms/step - loss: 233160.0312 - val_loss: 225052.2812\n",
            "Epoch 1971/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 104561.6406 - val_loss: 133897.3125\n",
            "Epoch 1972/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 82885.9844 - val_loss: 44741.8047\n",
            "Epoch 1973/3000\n",
            "66/66 [==============================] - 7s 105ms/step - loss: 51270.7266 - val_loss: 76408.7656\n",
            "Epoch 1974/3000\n",
            "66/66 [==============================] - 8s 117ms/step - loss: 89479.6016 - val_loss: 57234.3281\n",
            "Epoch 1975/3000\n",
            "66/66 [==============================] - 8s 115ms/step - loss: 206310.5000 - val_loss: 88511.9062\n",
            "Epoch 1976/3000\n",
            "66/66 [==============================] - 7s 113ms/step - loss: 75963.6562 - val_loss: 312799.3750\n",
            "Epoch 1977/3000\n",
            "66/66 [==============================] - 8s 115ms/step - loss: 1313068.1250 - val_loss: 1119730.7500\n",
            "Epoch 1978/3000\n",
            "66/66 [==============================] - 8s 116ms/step - loss: 662046.4375 - val_loss: 1189482.0000\n",
            "Epoch 1979/3000\n",
            "66/66 [==============================] - 7s 112ms/step - loss: 332847.6875 - val_loss: 100088.3984\n",
            "Epoch 1980/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 399817.2500 - val_loss: 837157.8125\n",
            "Epoch 1981/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 284018.0000 - val_loss: 135024.7969\n",
            "Epoch 1982/3000\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 182988.5312 - val_loss: 185627.5469\n",
            "Epoch 1983/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 72212.2422 - val_loss: 292624.8438\n",
            "Epoch 1984/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 111365.7344 - val_loss: 119870.6562\n",
            "Epoch 1985/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 85472.5781 - val_loss: 107857.4375\n",
            "Epoch 1986/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 81304.0156 - val_loss: 172729.0000\n",
            "Epoch 1987/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 255636.5469 - val_loss: 178614.7656\n",
            "Epoch 1988/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 990764.0625 - val_loss: 1002116.1250\n",
            "Epoch 1989/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 4438231.0000 - val_loss: 4739666.5000\n",
            "Epoch 1990/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 16526647.0000 - val_loss: 13853096.0000\n",
            "Epoch 1991/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 3945501.7500 - val_loss: 3439788.7500\n",
            "Epoch 1992/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 434831.9688 - val_loss: 457391.4688\n",
            "Epoch 1993/3000\n",
            "66/66 [==============================] - 6s 96ms/step - loss: 621379.0000 - val_loss: 813050.9375\n",
            "Epoch 1994/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 367172.1875 - val_loss: 200120.6875\n",
            "Epoch 1995/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 240919.2344 - val_loss: 1151671.7500\n",
            "Epoch 1996/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 174499.4688 - val_loss: 465938.8750\n",
            "Epoch 1997/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 187354.6562 - val_loss: 62361.2305\n",
            "Epoch 1998/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 79032.1016 - val_loss: 59004.5547\n",
            "Epoch 1999/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 136315.5938 - val_loss: 461738.1250\n",
            "Epoch 2000/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 684396.1875 - val_loss: 324026.8438\n",
            "Epoch 2001/3000\n",
            "66/66 [==============================] - 6s 92ms/step - loss: 1494629.0000 - val_loss: 5454396.5000\n",
            "Epoch 2002/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 1444360.7500 - val_loss: 877031.8125\n",
            "Epoch 2003/3000\n",
            "66/66 [==============================] - 7s 99ms/step - loss: 346620.5000 - val_loss: 183395.3594\n",
            "Epoch 2004/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 272851.2500 - val_loss: 586268.9375\n",
            "Epoch 2005/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 423289.2812 - val_loss: 149624.7500\n",
            "Epoch 2006/3000\n",
            "66/66 [==============================] - 6s 98ms/step - loss: 97407.3438 - val_loss: 45232.0898\n",
            "Epoch 2007/3000\n",
            "66/66 [==============================] - 7s 107ms/step - loss: 59835.0820 - val_loss: 266250.7188\n",
            "Epoch 2008/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 385132.3750 - val_loss: 187091.3906\n",
            "Epoch 2009/3000\n",
            "66/66 [==============================] - 7s 101ms/step - loss: 239803.5000 - val_loss: 840689.3750\n",
            "Epoch 2010/3000\n",
            "66/66 [==============================] - 7s 100ms/step - loss: 767602.5625 - val_loss: 262330.3438\n",
            "Epoch 2011/3000\n",
            "66/66 [==============================] - 7s 112ms/step - loss: 582125.1875 - val_loss: 1531755.8750\n",
            "Epoch 2012/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 1320320.2500 - val_loss: 400254.4062\n",
            "Epoch 2013/3000\n",
            "66/66 [==============================] - 8s 114ms/step - loss: 689431.8750 - val_loss: 294412.2188\n",
            "Epoch 2014/3000\n",
            "66/66 [==============================] - 7s 105ms/step - loss: 1110572.7500 - val_loss: 718590.1875\n",
            "Epoch 2015/3000\n",
            "66/66 [==============================] - 7s 113ms/step - loss: 405573.5938 - val_loss: 209620.1719\n",
            "Epoch 2016/3000\n",
            "66/66 [==============================] - 7s 103ms/step - loss: 199091.3125 - val_loss: 197782.6875\n",
            "Epoch 2017/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 279087.3750 - val_loss: 1346549.7500\n",
            "Epoch 2018/3000\n",
            "66/66 [==============================] - 6s 97ms/step - loss: 3459710.7500 - val_loss: 8247053.0000\n",
            "Epoch 2019/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 7977292.5000 - val_loss: 5405190.0000\n",
            "Epoch 2020/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 1805592.5000 - val_loss: 1126952.3750\n",
            "Epoch 2021/3000\n",
            "66/66 [==============================] - 6s 93ms/step - loss: 1002908.9375 - val_loss: 468040.8125\n",
            "Epoch 2022/3000\n",
            "66/66 [==============================] - 6s 94ms/step - loss: 309889.3125 - val_loss: 531907.0625\n",
            "Epoch 2023/3000\n",
            "66/66 [==============================] - 6s 95ms/step - loss: 476823.6250 - val_loss: 406795.0938\n",
            "Epoch 2024/3000\n",
            "66/66 [==============================] - 8s 114ms/step - loss: 245815.0000 - val_loss: 364631.1875\n",
            "Epoch 2025/3000\n",
            "12/66 [====>.........................] - ETA: 5s - loss: 161195.7812"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 평가, 예측 / 방문객\n",
        "loss=model.evaluate(test_x,test_y)\n",
        "pred_y=model.predict(test_x)\n",
        "\n",
        "print('loss: ',loss)\n",
        "print('예상 입장객 수: ', pred_y[-1:])"
      ],
      "metadata": {
        "id": "wuYtJpI78Ldr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daab522f-00e8-497a-9607-5114d99dbb0b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 20ms/step - loss: 2515360.0000\n",
            "loss:  2515360.0\n",
            "예상 입장객 수:  [[120265.625]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss:  10817543168.0\n",
        "예상 입장객 수:  [[89993.17]] \n",
        "-random state 지정 / 에포 300 / 페이션트 50\n",
        "loss:  11032627200.0\n",
        "예상 입장객 수:  [[65531.715]]\n",
        "-random state 빼봄 / 같은조건\n",
        "loss:  10427985920.0\n",
        "예상 입장객 수:  [[244709.86]]\n",
        "-minmax로 바꿔보자\n",
        "loss:  10741933056.0\n",
        "예상 입장객 수:  [[61856.137]]\n",
        "-data 바꿈!\n",
        "loss:  1966186.0\n",
        "예상 입장객 수:  [[6984.8716]]\n",
        "\n",
        "loss:  2515360.0\n",
        "예상 입장객 수:  [[120265.625]]"
      ],
      "metadata": {
        "id": "HmkTHS01ZWKs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 날씨_예측"
      ],
      "metadata": {
        "id": "SDsFe84lJEDn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input data\n",
        "weather_input = total_data[['강수_관측값',\"기온\", \"습도\", \"체감온도\", \"평균수온\", \"평균풍속\", \"평균기압\", \"평균최대파고\", \"평균파주기\"]]\n",
        "weather_output = total_data[['강수_관측값','기온']]"
      ],
      "metadata": {
        "id": "LYVOJdACJx1v"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 강수_관측값 예측을 위한 train/test split\n",
        "train_x, test_x, train_y, test_y = train_test_split(weather_input, weather_output, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "b7jPTgp4Mgf6"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 강수_관측값 예측을 위한  minmax scaler\n",
        "min_scaler = MinMaxScaler()\n",
        "train_x_scaled = min_scaler.fit_transform(train_x)\n",
        "test_x_scaled = min_scaler.transform(test_x)"
      ],
      "metadata": {
        "id": "_2sTPesjMFi5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x_scaled.shape,test_x_scaled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut_48KYWimFq",
        "outputId": "0f457029-df68-4421-f2ec-d7bd8b4ffe20"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1172, 9), (293, 9))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_x_scaled.astype(float)\n",
        "test_x = test_x_scaled.astype(float)\n",
        "train_y = train_y.astype(float)\n",
        "test_y = test_y.astype(float)"
      ],
      "metadata": {
        "id": "1u91b7POLeCo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x = train_x_scaled.reshape(1172, 3, 3)\n",
        "test_x = test_x_scaled.reshape(293, 3, 3)"
      ],
      "metadata": {
        "id": "N6hROX4-HcrA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x.shape, test_x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubML9MDSi1aq",
        "outputId": "6479ad49-b7eb-43b1-f739-f0251ea0a671"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1172, 3, 3), (293, 3, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2.모델구성 / 날씨\n",
        "model=Sequential()\n",
        "model.add(LSTM(units=256,input_shape=(3,3),return_sequences=True))\n",
        "model.add(Bidirectional(LSTM(512)))\n",
        "model.add(Dense(256,activation='swish'))\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dense(64,activation='swish'))\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(16,activation='swish'))\n",
        "model.add(Dense(2))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vCM5bQwLpJA",
        "outputId": "4834bf2b-d2b0-41af-aea9-acc842fcf444"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 3, 256)            266240    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 1024)             3149824   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               262400    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 34        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,722,258\n",
            "Trainable params: 3,722,258\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 컴파일 훈련 / 날씨\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=500, mode='min', verbose=1,restore_best_weights=True)\n",
        "optimizer = optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='mean_squared_error', optimizer=optimizer)\n",
        "hist = model.fit(train_x, train_y, epochs=3000, batch_size=1024, \n",
        "                validation_split=0.2,\n",
        "                callbacks = [earlyStopping],\n",
        "                verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOcJhjgYM_yY",
        "outputId": "bb0a7939-95c9-4d06-8547-96ddd94c723a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
            "Epoch 501/3000\n",
            "1/1 - 1s - loss: 0.8757 - val_loss: 0.4787 - 1s/epoch - 1s/step\n",
            "Epoch 502/3000\n",
            "1/1 - 1s - loss: 0.5155 - val_loss: 0.4594 - 1s/epoch - 1s/step\n",
            "Epoch 503/3000\n",
            "1/1 - 1s - loss: 0.4872 - val_loss: 0.7311 - 1s/epoch - 1s/step\n",
            "Epoch 504/3000\n",
            "1/1 - 1s - loss: 0.7638 - val_loss: 0.6530 - 1s/epoch - 1s/step\n",
            "Epoch 505/3000\n",
            "1/1 - 1s - loss: 0.6675 - val_loss: 0.8449 - 1s/epoch - 1s/step\n",
            "Epoch 506/3000\n",
            "1/1 - 1s - loss: 0.8805 - val_loss: 0.4814 - 1s/epoch - 1s/step\n",
            "Epoch 507/3000\n",
            "1/1 - 1s - loss: 0.5017 - val_loss: 0.4638 - 1s/epoch - 1s/step\n",
            "Epoch 508/3000\n",
            "1/1 - 1s - loss: 0.4808 - val_loss: 0.6740 - 1s/epoch - 1s/step\n",
            "Epoch 509/3000\n",
            "1/1 - 1s - loss: 0.6674 - val_loss: 0.5012 - 1s/epoch - 1s/step\n",
            "Epoch 510/3000\n",
            "1/1 - 1s - loss: 0.5187 - val_loss: 0.3993 - 1s/epoch - 1s/step\n",
            "Epoch 511/3000\n",
            "1/1 - 1s - loss: 0.4294 - val_loss: 0.4237 - 1s/epoch - 1s/step\n",
            "Epoch 512/3000\n",
            "1/1 - 1s - loss: 0.4683 - val_loss: 0.5233 - 1s/epoch - 1s/step\n",
            "Epoch 513/3000\n",
            "1/1 - 1s - loss: 0.5362 - val_loss: 0.6288 - 1s/epoch - 1s/step\n",
            "Epoch 514/3000\n",
            "1/1 - 1s - loss: 0.6629 - val_loss: 0.4723 - 1s/epoch - 1s/step\n",
            "Epoch 515/3000\n",
            "1/1 - 1s - loss: 0.4982 - val_loss: 0.3899 - 1s/epoch - 1s/step\n",
            "Epoch 516/3000\n",
            "1/1 - 1s - loss: 0.4227 - val_loss: 0.4020 - 1s/epoch - 1s/step\n",
            "Epoch 517/3000\n",
            "1/1 - 1s - loss: 0.4362 - val_loss: 0.4728 - 1s/epoch - 1s/step\n",
            "Epoch 518/3000\n",
            "1/1 - 1s - loss: 0.4979 - val_loss: 0.6695 - 1s/epoch - 1s/step\n",
            "Epoch 519/3000\n",
            "1/1 - 1s - loss: 0.7181 - val_loss: 0.5901 - 1s/epoch - 1s/step\n",
            "Epoch 520/3000\n",
            "1/1 - 1s - loss: 0.6159 - val_loss: 0.9012 - 1s/epoch - 1s/step\n",
            "Epoch 521/3000\n",
            "1/1 - 1s - loss: 0.9139 - val_loss: 0.5080 - 1s/epoch - 1s/step\n",
            "Epoch 522/3000\n",
            "1/1 - 1s - loss: 0.5355 - val_loss: 0.4032 - 1s/epoch - 1s/step\n",
            "Epoch 523/3000\n",
            "1/1 - 1s - loss: 0.4282 - val_loss: 0.5134 - 1s/epoch - 1s/step\n",
            "Epoch 524/3000\n",
            "1/1 - 1s - loss: 0.5290 - val_loss: 0.5105 - 1s/epoch - 1s/step\n",
            "Epoch 525/3000\n",
            "1/1 - 1s - loss: 0.5258 - val_loss: 0.4712 - 1s/epoch - 1s/step\n",
            "Epoch 526/3000\n",
            "1/1 - 1s - loss: 0.5177 - val_loss: 0.3844 - 1s/epoch - 1s/step\n",
            "Epoch 527/3000\n",
            "1/1 - 1s - loss: 0.4142 - val_loss: 0.4018 - 1s/epoch - 1s/step\n",
            "Epoch 528/3000\n",
            "1/1 - 1s - loss: 0.4238 - val_loss: 0.4822 - 1s/epoch - 1s/step\n",
            "Epoch 529/3000\n",
            "1/1 - 1s - loss: 0.5031 - val_loss: 0.4313 - 1s/epoch - 1s/step\n",
            "Epoch 530/3000\n",
            "1/1 - 1s - loss: 0.4569 - val_loss: 0.3727 - 1s/epoch - 1s/step\n",
            "Epoch 531/3000\n",
            "1/1 - 1s - loss: 0.4027 - val_loss: 0.3530 - 1s/epoch - 1s/step\n",
            "Epoch 532/3000\n",
            "1/1 - 1s - loss: 0.3886 - val_loss: 0.4039 - 1s/epoch - 1s/step\n",
            "Epoch 533/3000\n",
            "1/1 - 1s - loss: 0.4324 - val_loss: 0.5212 - 1s/epoch - 1s/step\n",
            "Epoch 534/3000\n",
            "1/1 - 1s - loss: 0.5790 - val_loss: 0.5807 - 1s/epoch - 1s/step\n",
            "Epoch 535/3000\n",
            "1/1 - 1s - loss: 0.6049 - val_loss: 1.2581 - 1s/epoch - 1s/step\n",
            "Epoch 536/3000\n",
            "1/1 - 1s - loss: 1.2499 - val_loss: 0.6048 - 1s/epoch - 1s/step\n",
            "Epoch 537/3000\n",
            "1/1 - 1s - loss: 0.6456 - val_loss: 0.4064 - 1s/epoch - 1s/step\n",
            "Epoch 538/3000\n",
            "1/1 - 1s - loss: 0.4327 - val_loss: 0.4997 - 1s/epoch - 1s/step\n",
            "Epoch 539/3000\n",
            "1/1 - 1s - loss: 0.5113 - val_loss: 0.5719 - 1s/epoch - 1s/step\n",
            "Epoch 540/3000\n",
            "1/1 - 1s - loss: 0.5814 - val_loss: 0.7091 - 1s/epoch - 1s/step\n",
            "Epoch 541/3000\n",
            "1/1 - 1s - loss: 0.7639 - val_loss: 0.4445 - 1s/epoch - 1s/step\n",
            "Epoch 542/3000\n",
            "1/1 - 1s - loss: 0.4662 - val_loss: 0.3827 - 1s/epoch - 1s/step\n",
            "Epoch 543/3000\n",
            "1/1 - 1s - loss: 0.4043 - val_loss: 0.5232 - 1s/epoch - 1s/step\n",
            "Epoch 544/3000\n",
            "1/1 - 1s - loss: 0.5239 - val_loss: 0.4467 - 1s/epoch - 1s/step\n",
            "Epoch 545/3000\n",
            "1/1 - 1s - loss: 0.4720 - val_loss: 0.3716 - 1s/epoch - 1s/step\n",
            "Epoch 546/3000\n",
            "1/1 - 1s - loss: 0.3943 - val_loss: 0.3699 - 1s/epoch - 1s/step\n",
            "Epoch 547/3000\n",
            "1/1 - 1s - loss: 0.4028 - val_loss: 0.4453 - 1s/epoch - 1s/step\n",
            "Epoch 548/3000\n",
            "1/1 - 1s - loss: 0.4665 - val_loss: 0.5527 - 1s/epoch - 1s/step\n",
            "Epoch 549/3000\n",
            "1/1 - 1s - loss: 0.6074 - val_loss: 0.4644 - 1s/epoch - 1s/step\n",
            "Epoch 550/3000\n",
            "1/1 - 1s - loss: 0.4884 - val_loss: 0.4649 - 1s/epoch - 1s/step\n",
            "Epoch 551/3000\n",
            "1/1 - 1s - loss: 0.4931 - val_loss: 0.3659 - 1s/epoch - 1s/step\n",
            "Epoch 552/3000\n",
            "1/1 - 1s - loss: 0.4003 - val_loss: 0.3492 - 1s/epoch - 1s/step\n",
            "Epoch 553/3000\n",
            "1/1 - 1s - loss: 0.3835 - val_loss: 0.3991 - 1s/epoch - 1s/step\n",
            "Epoch 554/3000\n",
            "1/1 - 1s - loss: 0.4396 - val_loss: 0.4555 - 1s/epoch - 1s/step\n",
            "Epoch 555/3000\n",
            "1/1 - 1s - loss: 0.4823 - val_loss: 0.7204 - 1s/epoch - 1s/step\n",
            "Epoch 556/3000\n",
            "1/1 - 1s - loss: 0.7623 - val_loss: 0.5804 - 1s/epoch - 1s/step\n",
            "Epoch 557/3000\n",
            "1/1 - 1s - loss: 0.5981 - val_loss: 0.8051 - 1s/epoch - 1s/step\n",
            "Epoch 558/3000\n",
            "1/1 - 1s - loss: 0.7932 - val_loss: 0.4196 - 1s/epoch - 1s/step\n",
            "Epoch 559/3000\n",
            "1/1 - 1s - loss: 0.4548 - val_loss: 0.4528 - 1s/epoch - 1s/step\n",
            "Epoch 560/3000\n",
            "1/1 - 1s - loss: 0.4792 - val_loss: 0.7631 - 1s/epoch - 1s/step\n",
            "Epoch 561/3000\n",
            "1/1 - 1s - loss: 0.7730 - val_loss: 0.4929 - 1s/epoch - 1s/step\n",
            "Epoch 562/3000\n",
            "1/1 - 1s - loss: 0.5050 - val_loss: 0.3491 - 1s/epoch - 1s/step\n",
            "Epoch 563/3000\n",
            "1/1 - 1s - loss: 0.3876 - val_loss: 0.3798 - 1s/epoch - 1s/step\n",
            "Epoch 564/3000\n",
            "1/1 - 1s - loss: 0.4138 - val_loss: 0.4499 - 1s/epoch - 1s/step\n",
            "Epoch 565/3000\n",
            "1/1 - 1s - loss: 0.4659 - val_loss: 0.4798 - 1s/epoch - 1s/step\n",
            "Epoch 566/3000\n",
            "1/1 - 1s - loss: 0.4872 - val_loss: 0.3505 - 1s/epoch - 1s/step\n",
            "Epoch 567/3000\n",
            "1/1 - 1s - loss: 0.3777 - val_loss: 0.3726 - 1s/epoch - 1s/step\n",
            "Epoch 568/3000\n",
            "1/1 - 1s - loss: 0.4003 - val_loss: 0.4908 - 1s/epoch - 1s/step\n",
            "Epoch 569/3000\n",
            "1/1 - 1s - loss: 0.5285 - val_loss: 0.4664 - 1s/epoch - 1s/step\n",
            "Epoch 570/3000\n",
            "1/1 - 1s - loss: 0.4902 - val_loss: 0.6404 - 1s/epoch - 1s/step\n",
            "Epoch 571/3000\n",
            "1/1 - 1s - loss: 0.6756 - val_loss: 0.4631 - 1s/epoch - 1s/step\n",
            "Epoch 572/3000\n",
            "1/1 - 1s - loss: 0.4897 - val_loss: 0.4244 - 1s/epoch - 1s/step\n",
            "Epoch 573/3000\n",
            "1/1 - 1s - loss: 0.4457 - val_loss: 0.3313 - 1s/epoch - 1s/step\n",
            "Epoch 574/3000\n",
            "1/1 - 1s - loss: 0.3614 - val_loss: 0.3687 - 1s/epoch - 1s/step\n",
            "Epoch 575/3000\n",
            "1/1 - 1s - loss: 0.3943 - val_loss: 0.4933 - 1s/epoch - 1s/step\n",
            "Epoch 576/3000\n",
            "1/1 - 1s - loss: 0.5329 - val_loss: 0.4561 - 1s/epoch - 1s/step\n",
            "Epoch 577/3000\n",
            "1/1 - 1s - loss: 0.4739 - val_loss: 0.4799 - 1s/epoch - 1s/step\n",
            "Epoch 578/3000\n",
            "1/1 - 1s - loss: 0.5126 - val_loss: 0.3632 - 1s/epoch - 1s/step\n",
            "Epoch 579/3000\n",
            "1/1 - 1s - loss: 0.3866 - val_loss: 0.3281 - 1s/epoch - 1s/step\n",
            "Epoch 580/3000\n",
            "1/1 - 1s - loss: 0.3535 - val_loss: 0.3756 - 1s/epoch - 1s/step\n",
            "Epoch 581/3000\n",
            "1/1 - 1s - loss: 0.3966 - val_loss: 0.3840 - 1s/epoch - 1s/step\n",
            "Epoch 582/3000\n",
            "1/1 - 1s - loss: 0.4050 - val_loss: 0.3790 - 1s/epoch - 1s/step\n",
            "Epoch 583/3000\n",
            "1/1 - 1s - loss: 0.4159 - val_loss: 0.3413 - 1s/epoch - 1s/step\n",
            "Epoch 584/3000\n",
            "1/1 - 1s - loss: 0.3666 - val_loss: 0.3045 - 1s/epoch - 1s/step\n",
            "Epoch 585/3000\n",
            "1/1 - 1s - loss: 0.3417 - val_loss: 0.2980 - 1s/epoch - 1s/step\n",
            "Epoch 586/3000\n",
            "1/1 - 1s - loss: 0.3309 - val_loss: 0.3068 - 1s/epoch - 1s/step\n",
            "Epoch 587/3000\n",
            "1/1 - 1s - loss: 0.3369 - val_loss: 0.3186 - 1s/epoch - 1s/step\n",
            "Epoch 588/3000\n",
            "1/1 - 1s - loss: 0.3532 - val_loss: 0.3349 - 1s/epoch - 1s/step\n",
            "Epoch 589/3000\n",
            "1/1 - 1s - loss: 0.3633 - val_loss: 0.3788 - 1s/epoch - 1s/step\n",
            "Epoch 590/3000\n",
            "1/1 - 1s - loss: 0.4192 - val_loss: 0.4323 - 1s/epoch - 1s/step\n",
            "Epoch 591/3000\n",
            "1/1 - 1s - loss: 0.4575 - val_loss: 0.9105 - 1s/epoch - 1s/step\n",
            "Epoch 592/3000\n",
            "1/1 - 1s - loss: 0.9171 - val_loss: 0.7300 - 1s/epoch - 1s/step\n",
            "Epoch 593/3000\n",
            "1/1 - 1s - loss: 0.7578 - val_loss: 1.6608 - 1s/epoch - 1s/step\n",
            "Epoch 594/3000\n",
            "1/1 - 1s - loss: 1.5938 - val_loss: 0.4699 - 1s/epoch - 1s/step\n",
            "Epoch 595/3000\n",
            "1/1 - 1s - loss: 0.5127 - val_loss: 0.8766 - 1s/epoch - 1s/step\n",
            "Epoch 596/3000\n",
            "1/1 - 1s - loss: 0.9016 - val_loss: 2.4356 - 1s/epoch - 1s/step\n",
            "Epoch 597/3000\n",
            "1/1 - 1s - loss: 2.4377 - val_loss: 0.4086 - 1s/epoch - 1s/step\n",
            "Epoch 598/3000\n",
            "1/1 - 1s - loss: 0.4245 - val_loss: 2.6604 - 1s/epoch - 1s/step\n",
            "Epoch 599/3000\n",
            "1/1 - 1s - loss: 2.6545 - val_loss: 13.3072 - 1s/epoch - 1s/step\n",
            "Epoch 600/3000\n",
            "1/1 - 1s - loss: 13.7816 - val_loss: 5.2783 - 1s/epoch - 1s/step\n",
            "Epoch 601/3000\n",
            "1/1 - 1s - loss: 5.1103 - val_loss: 13.8574 - 1s/epoch - 1s/step\n",
            "Epoch 602/3000\n",
            "1/1 - 1s - loss: 15.3477 - val_loss: 10.9222 - 1s/epoch - 1s/step\n",
            "Epoch 603/3000\n",
            "1/1 - 1s - loss: 10.6026 - val_loss: 16.5136 - 1s/epoch - 1s/step\n",
            "Epoch 604/3000\n",
            "1/1 - 1s - loss: 16.4036 - val_loss: 3.6924 - 1s/epoch - 1s/step\n",
            "Epoch 605/3000\n",
            "1/1 - 1s - loss: 3.5891 - val_loss: 16.6596 - 1s/epoch - 1s/step\n",
            "Epoch 606/3000\n",
            "1/1 - 1s - loss: 17.2220 - val_loss: 4.4357 - 1s/epoch - 1s/step\n",
            "Epoch 607/3000\n",
            "1/1 - 1s - loss: 4.4305 - val_loss: 14.0928 - 1s/epoch - 1s/step\n",
            "Epoch 608/3000\n",
            "1/1 - 1s - loss: 14.9284 - val_loss: 4.4854 - 1s/epoch - 1s/step\n",
            "Epoch 609/3000\n",
            "1/1 - 1s - loss: 4.8871 - val_loss: 7.5319 - 1s/epoch - 1s/step\n",
            "Epoch 610/3000\n",
            "1/1 - 1s - loss: 7.4796 - val_loss: 6.9526 - 1s/epoch - 1s/step\n",
            "Epoch 611/3000\n",
            "1/1 - 1s - loss: 6.8741 - val_loss: 2.8593 - 1s/epoch - 1s/step\n",
            "Epoch 612/3000\n",
            "1/1 - 1s - loss: 3.1373 - val_loss: 8.0429 - 1s/epoch - 1s/step\n",
            "Epoch 613/3000\n",
            "1/1 - 1s - loss: 8.5798 - val_loss: 3.2526 - 1s/epoch - 1s/step\n",
            "Epoch 614/3000\n",
            "1/1 - 1s - loss: 3.4398 - val_loss: 4.1558 - 1s/epoch - 1s/step\n",
            "Epoch 615/3000\n",
            "1/1 - 1s - loss: 4.0418 - val_loss: 5.6931 - 1s/epoch - 1s/step\n",
            "Epoch 616/3000\n",
            "1/1 - 1s - loss: 5.6495 - val_loss: 1.9177 - 1s/epoch - 1s/step\n",
            "Epoch 617/3000\n",
            "1/1 - 1s - loss: 2.0444 - val_loss: 4.4082 - 1s/epoch - 1s/step\n",
            "Epoch 618/3000\n",
            "1/1 - 1s - loss: 5.0660 - val_loss: 2.6216 - 1s/epoch - 1s/step\n",
            "Epoch 619/3000\n",
            "1/1 - 1s - loss: 3.0459 - val_loss: 2.3497 - 1s/epoch - 1s/step\n",
            "Epoch 620/3000\n",
            "1/1 - 1s - loss: 2.3705 - val_loss: 3.7067 - 1s/epoch - 1s/step\n",
            "Epoch 621/3000\n",
            "1/1 - 1s - loss: 3.6128 - val_loss: 1.5442 - 1s/epoch - 1s/step\n",
            "Epoch 622/3000\n",
            "1/1 - 1s - loss: 1.7341 - val_loss: 3.1872 - 1s/epoch - 1s/step\n",
            "Epoch 623/3000\n",
            "1/1 - 1s - loss: 3.4768 - val_loss: 1.9743 - 1s/epoch - 1s/step\n",
            "Epoch 624/3000\n",
            "1/1 - 1s - loss: 2.0767 - val_loss: 1.6862 - 1s/epoch - 1s/step\n",
            "Epoch 625/3000\n",
            "1/1 - 1s - loss: 1.6044 - val_loss: 3.1908 - 1s/epoch - 1s/step\n",
            "Epoch 626/3000\n",
            "1/1 - 1s - loss: 3.0138 - val_loss: 0.9799 - 1s/epoch - 1s/step\n",
            "Epoch 627/3000\n",
            "1/1 - 1s - loss: 0.9718 - val_loss: 1.8750 - 1s/epoch - 1s/step\n",
            "Epoch 628/3000\n",
            "1/1 - 1s - loss: 2.0405 - val_loss: 1.6827 - 1s/epoch - 1s/step\n",
            "Epoch 629/3000\n",
            "1/1 - 1s - loss: 1.8995 - val_loss: 0.7402 - 1s/epoch - 1s/step\n",
            "Epoch 630/3000\n",
            "1/1 - 1s - loss: 0.7876 - val_loss: 2.2099 - 1s/epoch - 1s/step\n",
            "Epoch 631/3000\n",
            "1/1 - 1s - loss: 2.0351 - val_loss: 0.7599 - 1s/epoch - 1s/step\n",
            "Epoch 632/3000\n",
            "1/1 - 1s - loss: 0.7795 - val_loss: 1.3075 - 1s/epoch - 1s/step\n",
            "Epoch 633/3000\n",
            "1/1 - 1s - loss: 1.4404 - val_loss: 1.0352 - 1s/epoch - 1s/step\n",
            "Epoch 634/3000\n",
            "1/1 - 1s - loss: 1.0904 - val_loss: 0.9947 - 1s/epoch - 1s/step\n",
            "Epoch 635/3000\n",
            "1/1 - 1s - loss: 0.9007 - val_loss: 1.4953 - 1s/epoch - 1s/step\n",
            "Epoch 636/3000\n",
            "1/1 - 1s - loss: 1.3243 - val_loss: 0.7439 - 1s/epoch - 1s/step\n",
            "Epoch 637/3000\n",
            "1/1 - 1s - loss: 0.6711 - val_loss: 1.1269 - 1s/epoch - 1s/step\n",
            "Epoch 638/3000\n",
            "1/1 - 1s - loss: 1.1727 - val_loss: 0.7528 - 1s/epoch - 1s/step\n",
            "Epoch 639/3000\n",
            "1/1 - 1s - loss: 0.8099 - val_loss: 0.8223 - 1s/epoch - 1s/step\n",
            "Epoch 640/3000\n",
            "1/1 - 1s - loss: 0.7824 - val_loss: 1.0274 - 1s/epoch - 1s/step\n",
            "Epoch 641/3000\n",
            "1/1 - 1s - loss: 0.9794 - val_loss: 0.5701 - 1s/epoch - 1s/step\n",
            "Epoch 642/3000\n",
            "1/1 - 1s - loss: 0.6558 - val_loss: 0.8341 - 1s/epoch - 1s/step\n",
            "Epoch 643/3000\n",
            "1/1 - 1s - loss: 0.9395 - val_loss: 0.5711 - 1s/epoch - 1s/step\n",
            "Epoch 644/3000\n",
            "1/1 - 1s - loss: 0.6046 - val_loss: 0.9186 - 1s/epoch - 1s/step\n",
            "Epoch 645/3000\n",
            "1/1 - 1s - loss: 0.8907 - val_loss: 0.5368 - 1s/epoch - 1s/step\n",
            "Epoch 646/3000\n",
            "1/1 - 1s - loss: 0.5785 - val_loss: 0.6510 - 1s/epoch - 1s/step\n",
            "Epoch 647/3000\n",
            "1/1 - 1s - loss: 0.7573 - val_loss: 0.5511 - 1s/epoch - 1s/step\n",
            "Epoch 648/3000\n",
            "1/1 - 1s - loss: 0.6590 - val_loss: 0.5325 - 1s/epoch - 1s/step\n",
            "Epoch 649/3000\n",
            "1/1 - 1s - loss: 0.5784 - val_loss: 0.6441 - 1s/epoch - 1s/step\n",
            "Epoch 650/3000\n",
            "1/1 - 1s - loss: 0.6740 - val_loss: 0.4779 - 1s/epoch - 1s/step\n",
            "Epoch 651/3000\n",
            "1/1 - 1s - loss: 0.5796 - val_loss: 0.5444 - 1s/epoch - 1s/step\n",
            "Epoch 652/3000\n",
            "1/1 - 1s - loss: 0.6549 - val_loss: 0.4550 - 1s/epoch - 1s/step\n",
            "Epoch 653/3000\n",
            "1/1 - 1s - loss: 0.5114 - val_loss: 0.6488 - 1s/epoch - 1s/step\n",
            "Epoch 654/3000\n",
            "1/1 - 1s - loss: 0.6534 - val_loss: 0.4507 - 1s/epoch - 1s/step\n",
            "Epoch 655/3000\n",
            "1/1 - 1s - loss: 0.4880 - val_loss: 0.5431 - 1s/epoch - 1s/step\n",
            "Epoch 656/3000\n",
            "1/1 - 1s - loss: 0.6031 - val_loss: 0.4615 - 1s/epoch - 1s/step\n",
            "Epoch 657/3000\n",
            "1/1 - 1s - loss: 0.5102 - val_loss: 0.5192 - 1s/epoch - 1s/step\n",
            "Epoch 658/3000\n",
            "1/1 - 1s - loss: 0.5323 - val_loss: 0.4996 - 1s/epoch - 1s/step\n",
            "Epoch 659/3000\n",
            "1/1 - 1s - loss: 0.5234 - val_loss: 0.4289 - 1s/epoch - 1s/step\n",
            "Epoch 660/3000\n",
            "1/1 - 1s - loss: 0.4962 - val_loss: 0.4519 - 1s/epoch - 1s/step\n",
            "Epoch 661/3000\n",
            "1/1 - 1s - loss: 0.5257 - val_loss: 0.4235 - 1s/epoch - 1s/step\n",
            "Epoch 662/3000\n",
            "1/1 - 1s - loss: 0.4654 - val_loss: 0.5018 - 1s/epoch - 1s/step\n",
            "Epoch 663/3000\n",
            "1/1 - 1s - loss: 0.5197 - val_loss: 0.4084 - 1s/epoch - 1s/step\n",
            "Epoch 664/3000\n",
            "1/1 - 1s - loss: 0.4520 - val_loss: 0.4352 - 1s/epoch - 1s/step\n",
            "Epoch 665/3000\n",
            "1/1 - 1s - loss: 0.4958 - val_loss: 0.4050 - 1s/epoch - 1s/step\n",
            "Epoch 666/3000\n",
            "1/1 - 1s - loss: 0.4581 - val_loss: 0.4327 - 1s/epoch - 1s/step\n",
            "Epoch 667/3000\n",
            "1/1 - 1s - loss: 0.4654 - val_loss: 0.4187 - 1s/epoch - 1s/step\n",
            "Epoch 668/3000\n",
            "1/1 - 1s - loss: 0.4555 - val_loss: 0.3889 - 1s/epoch - 1s/step\n",
            "Epoch 669/3000\n",
            "1/1 - 1s - loss: 0.4493 - val_loss: 0.3850 - 1s/epoch - 1s/step\n",
            "Epoch 670/3000\n",
            "1/1 - 1s - loss: 0.4514 - val_loss: 0.3824 - 1s/epoch - 1s/step\n",
            "Epoch 671/3000\n",
            "1/1 - 1s - loss: 0.4330 - val_loss: 0.4036 - 1s/epoch - 1s/step\n",
            "Epoch 672/3000\n",
            "1/1 - 1s - loss: 0.4464 - val_loss: 0.3692 - 1s/epoch - 1s/step\n",
            "Epoch 673/3000\n",
            "1/1 - 1s - loss: 0.4230 - val_loss: 0.3825 - 1s/epoch - 1s/step\n",
            "Epoch 674/3000\n",
            "1/1 - 1s - loss: 0.4374 - val_loss: 0.3745 - 1s/epoch - 1s/step\n",
            "Epoch 675/3000\n",
            "1/1 - 1s - loss: 0.4161 - val_loss: 0.3948 - 1s/epoch - 1s/step\n",
            "Epoch 676/3000\n",
            "1/1 - 1s - loss: 0.4295 - val_loss: 0.3639 - 1s/epoch - 1s/step\n",
            "Epoch 677/3000\n",
            "1/1 - 1s - loss: 0.4105 - val_loss: 0.3660 - 1s/epoch - 1s/step\n",
            "Epoch 678/3000\n",
            "1/1 - 1s - loss: 0.4214 - val_loss: 0.3563 - 1s/epoch - 1s/step\n",
            "Epoch 679/3000\n",
            "1/1 - 1s - loss: 0.4041 - val_loss: 0.3759 - 1s/epoch - 1s/step\n",
            "Epoch 680/3000\n",
            "1/1 - 1s - loss: 0.4155 - val_loss: 0.3531 - 1s/epoch - 1s/step\n",
            "Epoch 681/3000\n",
            "1/1 - 1s - loss: 0.3999 - val_loss: 0.3543 - 1s/epoch - 1s/step\n",
            "Epoch 682/3000\n",
            "1/1 - 1s - loss: 0.4064 - val_loss: 0.3503 - 1s/epoch - 1s/step\n",
            "Epoch 683/3000\n",
            "1/1 - 1s - loss: 0.3951 - val_loss: 0.3633 - 1s/epoch - 1s/step\n",
            "Epoch 684/3000\n",
            "1/1 - 1s - loss: 0.4014 - val_loss: 0.3472 - 1s/epoch - 1s/step\n",
            "Epoch 685/3000\n",
            "1/1 - 1s - loss: 0.3903 - val_loss: 0.3465 - 1s/epoch - 1s/step\n",
            "Epoch 686/3000\n",
            "1/1 - 1s - loss: 0.3949 - val_loss: 0.3411 - 1s/epoch - 1s/step\n",
            "Epoch 687/3000\n",
            "1/1 - 1s - loss: 0.3862 - val_loss: 0.3476 - 1s/epoch - 1s/step\n",
            "Epoch 688/3000\n",
            "1/1 - 1s - loss: 0.3896 - val_loss: 0.3352 - 1s/epoch - 1s/step\n",
            "Epoch 689/3000\n",
            "1/1 - 1s - loss: 0.3821 - val_loss: 0.3340 - 1s/epoch - 1s/step\n",
            "Epoch 690/3000\n",
            "1/1 - 1s - loss: 0.3844 - val_loss: 0.3325 - 1s/epoch - 1s/step\n",
            "Epoch 691/3000\n",
            "1/1 - 1s - loss: 0.3777 - val_loss: 0.3393 - 1s/epoch - 1s/step\n",
            "Epoch 692/3000\n",
            "1/1 - 1s - loss: 0.3797 - val_loss: 0.3311 - 1s/epoch - 1s/step\n",
            "Epoch 693/3000\n",
            "1/1 - 1s - loss: 0.3739 - val_loss: 0.3290 - 1s/epoch - 1s/step\n",
            "Epoch 694/3000\n",
            "1/1 - 1s - loss: 0.3747 - val_loss: 0.3266 - 1s/epoch - 1s/step\n",
            "Epoch 695/3000\n",
            "1/1 - 1s - loss: 0.3701 - val_loss: 0.3293 - 1s/epoch - 1s/step\n",
            "Epoch 696/3000\n",
            "1/1 - 1s - loss: 0.3706 - val_loss: 0.3223 - 1s/epoch - 1s/step\n",
            "Epoch 697/3000\n",
            "1/1 - 1s - loss: 0.3663 - val_loss: 0.3205 - 1s/epoch - 1s/step\n",
            "Epoch 698/3000\n",
            "1/1 - 1s - loss: 0.3665 - val_loss: 0.3194 - 1s/epoch - 1s/step\n",
            "Epoch 699/3000\n",
            "1/1 - 1s - loss: 0.3627 - val_loss: 0.3210 - 1s/epoch - 1s/step\n",
            "Epoch 700/3000\n",
            "1/1 - 1s - loss: 0.3624 - val_loss: 0.3159 - 1s/epoch - 1s/step\n",
            "Epoch 701/3000\n",
            "1/1 - 1s - loss: 0.3592 - val_loss: 0.3144 - 1s/epoch - 1s/step\n",
            "Epoch 702/3000\n",
            "1/1 - 1s - loss: 0.3585 - val_loss: 0.3138 - 1s/epoch - 1s/step\n",
            "Epoch 703/3000\n",
            "1/1 - 1s - loss: 0.3557 - val_loss: 0.3138 - 1s/epoch - 1s/step\n",
            "Epoch 704/3000\n",
            "1/1 - 1s - loss: 0.3549 - val_loss: 0.3090 - 1s/epoch - 1s/step\n",
            "Epoch 705/3000\n",
            "1/1 - 1s - loss: 0.3524 - val_loss: 0.3069 - 1s/epoch - 1s/step\n",
            "Epoch 706/3000\n",
            "1/1 - 1s - loss: 0.3513 - val_loss: 0.3065 - 1s/epoch - 1s/step\n",
            "Epoch 707/3000\n",
            "1/1 - 1s - loss: 0.3492 - val_loss: 0.3057 - 1s/epoch - 1s/step\n",
            "Epoch 708/3000\n",
            "1/1 - 1s - loss: 0.3478 - val_loss: 0.3033 - 1s/epoch - 1s/step\n",
            "Epoch 709/3000\n",
            "1/1 - 1s - loss: 0.3461 - val_loss: 0.3025 - 1s/epoch - 1s/step\n",
            "Epoch 710/3000\n",
            "1/1 - 1s - loss: 0.3445 - val_loss: 0.3025 - 1s/epoch - 1s/step\n",
            "Epoch 711/3000\n",
            "1/1 - 1s - loss: 0.3430 - val_loss: 0.3005 - 1s/epoch - 1s/step\n",
            "Epoch 712/3000\n",
            "1/1 - 1s - loss: 0.3412 - val_loss: 0.2982 - 1s/epoch - 1s/step\n",
            "Epoch 713/3000\n",
            "1/1 - 1s - loss: 0.3400 - val_loss: 0.2970 - 1s/epoch - 1s/step\n",
            "Epoch 714/3000\n",
            "1/1 - 1s - loss: 0.3381 - val_loss: 0.2969 - 1s/epoch - 1s/step\n",
            "Epoch 715/3000\n",
            "1/1 - 1s - loss: 0.3370 - val_loss: 0.2949 - 1s/epoch - 1s/step\n",
            "Epoch 716/3000\n",
            "1/1 - 1s - loss: 0.3352 - val_loss: 0.2935 - 1s/epoch - 1s/step\n",
            "Epoch 717/3000\n",
            "1/1 - 1s - loss: 0.3341 - val_loss: 0.2926 - 1s/epoch - 1s/step\n",
            "Epoch 718/3000\n",
            "1/1 - 1s - loss: 0.3324 - val_loss: 0.2917 - 1s/epoch - 1s/step\n",
            "Epoch 719/3000\n",
            "1/1 - 1s - loss: 0.3312 - val_loss: 0.2897 - 1s/epoch - 1s/step\n",
            "Epoch 720/3000\n",
            "1/1 - 1s - loss: 0.3296 - val_loss: 0.2883 - 1s/epoch - 1s/step\n",
            "Epoch 721/3000\n",
            "1/1 - 1s - loss: 0.3283 - val_loss: 0.2874 - 1s/epoch - 1s/step\n",
            "Epoch 722/3000\n",
            "1/1 - 1s - loss: 0.3269 - val_loss: 0.2860 - 1s/epoch - 1s/step\n",
            "Epoch 723/3000\n",
            "1/1 - 1s - loss: 0.3256 - val_loss: 0.2845 - 1s/epoch - 1s/step\n",
            "Epoch 724/3000\n",
            "1/1 - 1s - loss: 0.3243 - val_loss: 0.2836 - 1s/epoch - 1s/step\n",
            "Epoch 725/3000\n",
            "1/1 - 1s - loss: 0.3228 - val_loss: 0.2830 - 1s/epoch - 1s/step\n",
            "Epoch 726/3000\n",
            "1/1 - 1s - loss: 0.3216 - val_loss: 0.2816 - 1s/epoch - 1s/step\n",
            "Epoch 727/3000\n",
            "1/1 - 1s - loss: 0.3202 - val_loss: 0.2803 - 1s/epoch - 1s/step\n",
            "Epoch 728/3000\n",
            "1/1 - 1s - loss: 0.3191 - val_loss: 0.2792 - 1s/epoch - 1s/step\n",
            "Epoch 729/3000\n",
            "1/1 - 1s - loss: 0.3177 - val_loss: 0.2782 - 1s/epoch - 1s/step\n",
            "Epoch 730/3000\n",
            "1/1 - 1s - loss: 0.3165 - val_loss: 0.2769 - 1s/epoch - 1s/step\n",
            "Epoch 731/3000\n",
            "1/1 - 1s - loss: 0.3153 - val_loss: 0.2760 - 1s/epoch - 1s/step\n",
            "Epoch 732/3000\n",
            "1/1 - 1s - loss: 0.3141 - val_loss: 0.2752 - 1s/epoch - 1s/step\n",
            "Epoch 733/3000\n",
            "1/1 - 1s - loss: 0.3130 - val_loss: 0.2738 - 1s/epoch - 1s/step\n",
            "Epoch 734/3000\n",
            "1/1 - 1s - loss: 0.3117 - val_loss: 0.2726 - 1s/epoch - 1s/step\n",
            "Epoch 735/3000\n",
            "1/1 - 1s - loss: 0.3106 - val_loss: 0.2717 - 1s/epoch - 1s/step\n",
            "Epoch 736/3000\n",
            "1/1 - 1s - loss: 0.3094 - val_loss: 0.2710 - 1s/epoch - 1s/step\n",
            "Epoch 737/3000\n",
            "1/1 - 1s - loss: 0.3083 - val_loss: 0.2701 - 1s/epoch - 1s/step\n",
            "Epoch 738/3000\n",
            "1/1 - 1s - loss: 0.3072 - val_loss: 0.2692 - 1s/epoch - 1s/step\n",
            "Epoch 739/3000\n",
            "1/1 - 1s - loss: 0.3061 - val_loss: 0.2681 - 1s/epoch - 1s/step\n",
            "Epoch 740/3000\n",
            "1/1 - 1s - loss: 0.3050 - val_loss: 0.2668 - 1s/epoch - 1s/step\n",
            "Epoch 741/3000\n",
            "1/1 - 1s - loss: 0.3039 - val_loss: 0.2657 - 1s/epoch - 1s/step\n",
            "Epoch 742/3000\n",
            "1/1 - 1s - loss: 0.3028 - val_loss: 0.2649 - 1s/epoch - 1s/step\n",
            "Epoch 743/3000\n",
            "1/1 - 1s - loss: 0.3018 - val_loss: 0.2640 - 1s/epoch - 1s/step\n",
            "Epoch 744/3000\n",
            "1/1 - 1s - loss: 0.3007 - val_loss: 0.2633 - 1s/epoch - 1s/step\n",
            "Epoch 745/3000\n",
            "1/1 - 1s - loss: 0.2997 - val_loss: 0.2625 - 1s/epoch - 1s/step\n",
            "Epoch 746/3000\n",
            "1/1 - 1s - loss: 0.2987 - val_loss: 0.2618 - 1s/epoch - 1s/step\n",
            "Epoch 747/3000\n",
            "1/1 - 1s - loss: 0.2977 - val_loss: 0.2609 - 1s/epoch - 1s/step\n",
            "Epoch 748/3000\n",
            "1/1 - 1s - loss: 0.2967 - val_loss: 0.2601 - 1s/epoch - 1s/step\n",
            "Epoch 749/3000\n",
            "1/1 - 1s - loss: 0.2957 - val_loss: 0.2593 - 1s/epoch - 1s/step\n",
            "Epoch 750/3000\n",
            "1/1 - 1s - loss: 0.2947 - val_loss: 0.2586 - 1s/epoch - 1s/step\n",
            "Epoch 751/3000\n",
            "1/1 - 1s - loss: 0.2938 - val_loss: 0.2578 - 1s/epoch - 1s/step\n",
            "Epoch 752/3000\n",
            "1/1 - 1s - loss: 0.2928 - val_loss: 0.2571 - 1s/epoch - 1s/step\n",
            "Epoch 753/3000\n",
            "1/1 - 1s - loss: 0.2919 - val_loss: 0.2563 - 1s/epoch - 1s/step\n",
            "Epoch 754/3000\n",
            "1/1 - 1s - loss: 0.2910 - val_loss: 0.2555 - 1s/epoch - 1s/step\n",
            "Epoch 755/3000\n",
            "1/1 - 1s - loss: 0.2900 - val_loss: 0.2546 - 1s/epoch - 1s/step\n",
            "Epoch 756/3000\n",
            "1/1 - 1s - loss: 0.2891 - val_loss: 0.2537 - 1s/epoch - 1s/step\n",
            "Epoch 757/3000\n",
            "1/1 - 1s - loss: 0.2882 - val_loss: 0.2529 - 1s/epoch - 1s/step\n",
            "Epoch 758/3000\n",
            "1/1 - 1s - loss: 0.2873 - val_loss: 0.2521 - 1s/epoch - 1s/step\n",
            "Epoch 759/3000\n",
            "1/1 - 1s - loss: 0.2865 - val_loss: 0.2515 - 1s/epoch - 1s/step\n",
            "Epoch 760/3000\n",
            "1/1 - 1s - loss: 0.2856 - val_loss: 0.2508 - 1s/epoch - 1s/step\n",
            "Epoch 761/3000\n",
            "1/1 - 1s - loss: 0.2847 - val_loss: 0.2501 - 1s/epoch - 1s/step\n",
            "Epoch 762/3000\n",
            "1/1 - 1s - loss: 0.2839 - val_loss: 0.2494 - 1s/epoch - 1s/step\n",
            "Epoch 763/3000\n",
            "1/1 - 1s - loss: 0.2830 - val_loss: 0.2487 - 1s/epoch - 1s/step\n",
            "Epoch 764/3000\n",
            "1/1 - 1s - loss: 0.2822 - val_loss: 0.2480 - 1s/epoch - 1s/step\n",
            "Epoch 765/3000\n",
            "1/1 - 1s - loss: 0.2813 - val_loss: 0.2473 - 1s/epoch - 1s/step\n",
            "Epoch 766/3000\n",
            "1/1 - 1s - loss: 0.2805 - val_loss: 0.2467 - 1s/epoch - 1s/step\n",
            "Epoch 767/3000\n",
            "1/1 - 1s - loss: 0.2797 - val_loss: 0.2461 - 1s/epoch - 1s/step\n",
            "Epoch 768/3000\n",
            "1/1 - 1s - loss: 0.2789 - val_loss: 0.2454 - 1s/epoch - 1s/step\n",
            "Epoch 769/3000\n",
            "1/1 - 1s - loss: 0.2781 - val_loss: 0.2446 - 1s/epoch - 1s/step\n",
            "Epoch 770/3000\n",
            "1/1 - 1s - loss: 0.2774 - val_loss: 0.2439 - 1s/epoch - 1s/step\n",
            "Epoch 771/3000\n",
            "1/1 - 1s - loss: 0.2767 - val_loss: 0.2433 - 1s/epoch - 1s/step\n",
            "Epoch 772/3000\n",
            "1/1 - 1s - loss: 0.2758 - val_loss: 0.2429 - 1s/epoch - 1s/step\n",
            "Epoch 773/3000\n",
            "1/1 - 1s - loss: 0.2751 - val_loss: 0.2424 - 1s/epoch - 1s/step\n",
            "Epoch 774/3000\n",
            "1/1 - 1s - loss: 0.2743 - val_loss: 0.2416 - 1s/epoch - 1s/step\n",
            "Epoch 775/3000\n",
            "1/1 - 1s - loss: 0.2735 - val_loss: 0.2406 - 1s/epoch - 1s/step\n",
            "Epoch 776/3000\n",
            "1/1 - 1s - loss: 0.2727 - val_loss: 0.2398 - 1s/epoch - 1s/step\n",
            "Epoch 777/3000\n",
            "1/1 - 1s - loss: 0.2720 - val_loss: 0.2392 - 1s/epoch - 1s/step\n",
            "Epoch 778/3000\n",
            "1/1 - 1s - loss: 0.2713 - val_loss: 0.2387 - 1s/epoch - 1s/step\n",
            "Epoch 779/3000\n",
            "1/1 - 1s - loss: 0.2705 - val_loss: 0.2384 - 1s/epoch - 1s/step\n",
            "Epoch 780/3000\n",
            "1/1 - 1s - loss: 0.2698 - val_loss: 0.2379 - 1s/epoch - 1s/step\n",
            "Epoch 781/3000\n",
            "1/1 - 1s - loss: 0.2691 - val_loss: 0.2372 - 1s/epoch - 1s/step\n",
            "Epoch 782/3000\n",
            "1/1 - 1s - loss: 0.2683 - val_loss: 0.2364 - 1s/epoch - 1s/step\n",
            "Epoch 783/3000\n",
            "1/1 - 1s - loss: 0.2676 - val_loss: 0.2359 - 1s/epoch - 1s/step\n",
            "Epoch 784/3000\n",
            "1/1 - 1s - loss: 0.2669 - val_loss: 0.2354 - 1s/epoch - 1s/step\n",
            "Epoch 785/3000\n",
            "1/1 - 1s - loss: 0.2662 - val_loss: 0.2351 - 1s/epoch - 1s/step\n",
            "Epoch 786/3000\n",
            "1/1 - 1s - loss: 0.2655 - val_loss: 0.2346 - 1s/epoch - 1s/step\n",
            "Epoch 787/3000\n",
            "1/1 - 1s - loss: 0.2648 - val_loss: 0.2339 - 1s/epoch - 1s/step\n",
            "Epoch 788/3000\n",
            "1/1 - 1s - loss: 0.2641 - val_loss: 0.2332 - 1s/epoch - 1s/step\n",
            "Epoch 789/3000\n",
            "1/1 - 1s - loss: 0.2634 - val_loss: 0.2325 - 1s/epoch - 1s/step\n",
            "Epoch 790/3000\n",
            "1/1 - 1s - loss: 0.2628 - val_loss: 0.2320 - 1s/epoch - 1s/step\n",
            "Epoch 791/3000\n",
            "1/1 - 1s - loss: 0.2621 - val_loss: 0.2315 - 1s/epoch - 1s/step\n",
            "Epoch 792/3000\n",
            "1/1 - 1s - loss: 0.2614 - val_loss: 0.2309 - 1s/epoch - 1s/step\n",
            "Epoch 793/3000\n",
            "1/1 - 1s - loss: 0.2609 - val_loss: 0.2301 - 1s/epoch - 1s/step\n",
            "Epoch 794/3000\n",
            "1/1 - 1s - loss: 0.2602 - val_loss: 0.2295 - 1s/epoch - 1s/step\n",
            "Epoch 795/3000\n",
            "1/1 - 1s - loss: 0.2595 - val_loss: 0.2291 - 1s/epoch - 1s/step\n",
            "Epoch 796/3000\n",
            "1/1 - 1s - loss: 0.2589 - val_loss: 0.2285 - 1s/epoch - 1s/step\n",
            "Epoch 797/3000\n",
            "1/1 - 1s - loss: 0.2583 - val_loss: 0.2278 - 1s/epoch - 1s/step\n",
            "Epoch 798/3000\n",
            "1/1 - 1s - loss: 0.2576 - val_loss: 0.2271 - 1s/epoch - 1s/step\n",
            "Epoch 799/3000\n",
            "1/1 - 1s - loss: 0.2570 - val_loss: 0.2263 - 1s/epoch - 1s/step\n",
            "Epoch 800/3000\n",
            "1/1 - 1s - loss: 0.2564 - val_loss: 0.2258 - 1s/epoch - 1s/step\n",
            "Epoch 801/3000\n",
            "1/1 - 1s - loss: 0.2557 - val_loss: 0.2254 - 1s/epoch - 1s/step\n",
            "Epoch 802/3000\n",
            "1/1 - 1s - loss: 0.2551 - val_loss: 0.2250 - 1s/epoch - 1s/step\n",
            "Epoch 803/3000\n",
            "1/1 - 1s - loss: 0.2545 - val_loss: 0.2244 - 1s/epoch - 1s/step\n",
            "Epoch 804/3000\n",
            "1/1 - 1s - loss: 0.2538 - val_loss: 0.2239 - 1s/epoch - 1s/step\n",
            "Epoch 805/3000\n",
            "1/1 - 1s - loss: 0.2532 - val_loss: 0.2232 - 1s/epoch - 1s/step\n",
            "Epoch 806/3000\n",
            "1/1 - 1s - loss: 0.2526 - val_loss: 0.2228 - 1s/epoch - 1s/step\n",
            "Epoch 807/3000\n",
            "1/1 - 1s - loss: 0.2520 - val_loss: 0.2224 - 1s/epoch - 1s/step\n",
            "Epoch 808/3000\n",
            "1/1 - 1s - loss: 0.2513 - val_loss: 0.2219 - 1s/epoch - 1s/step\n",
            "Epoch 809/3000\n",
            "1/1 - 1s - loss: 0.2507 - val_loss: 0.2214 - 1s/epoch - 1s/step\n",
            "Epoch 810/3000\n",
            "1/1 - 1s - loss: 0.2501 - val_loss: 0.2208 - 1s/epoch - 1s/step\n",
            "Epoch 811/3000\n",
            "1/1 - 1s - loss: 0.2495 - val_loss: 0.2202 - 1s/epoch - 1s/step\n",
            "Epoch 812/3000\n",
            "1/1 - 1s - loss: 0.2489 - val_loss: 0.2197 - 1s/epoch - 1s/step\n",
            "Epoch 813/3000\n",
            "1/1 - 1s - loss: 0.2483 - val_loss: 0.2192 - 1s/epoch - 1s/step\n",
            "Epoch 814/3000\n",
            "1/1 - 1s - loss: 0.2477 - val_loss: 0.2186 - 1s/epoch - 1s/step\n",
            "Epoch 815/3000\n",
            "1/1 - 1s - loss: 0.2470 - val_loss: 0.2181 - 1s/epoch - 1s/step\n",
            "Epoch 816/3000\n",
            "1/1 - 1s - loss: 0.2464 - val_loss: 0.2175 - 1s/epoch - 1s/step\n",
            "Epoch 817/3000\n",
            "1/1 - 1s - loss: 0.2458 - val_loss: 0.2169 - 1s/epoch - 1s/step\n",
            "Epoch 818/3000\n",
            "1/1 - 1s - loss: 0.2452 - val_loss: 0.2163 - 1s/epoch - 1s/step\n",
            "Epoch 819/3000\n",
            "1/1 - 1s - loss: 0.2447 - val_loss: 0.2158 - 1s/epoch - 1s/step\n",
            "Epoch 820/3000\n",
            "1/1 - 1s - loss: 0.2440 - val_loss: 0.2154 - 1s/epoch - 1s/step\n",
            "Epoch 821/3000\n",
            "1/1 - 1s - loss: 0.2435 - val_loss: 0.2149 - 1s/epoch - 1s/step\n",
            "Epoch 822/3000\n",
            "1/1 - 1s - loss: 0.2429 - val_loss: 0.2143 - 1s/epoch - 1s/step\n",
            "Epoch 823/3000\n",
            "1/1 - 1s - loss: 0.2423 - val_loss: 0.2138 - 1s/epoch - 1s/step\n",
            "Epoch 824/3000\n",
            "1/1 - 1s - loss: 0.2417 - val_loss: 0.2133 - 1s/epoch - 1s/step\n",
            "Epoch 825/3000\n",
            "1/1 - 1s - loss: 0.2411 - val_loss: 0.2129 - 1s/epoch - 1s/step\n",
            "Epoch 826/3000\n",
            "1/1 - 1s - loss: 0.2406 - val_loss: 0.2125 - 1s/epoch - 1s/step\n",
            "Epoch 827/3000\n",
            "1/1 - 1s - loss: 0.2400 - val_loss: 0.2120 - 1s/epoch - 1s/step\n",
            "Epoch 828/3000\n",
            "1/1 - 1s - loss: 0.2394 - val_loss: 0.2115 - 1s/epoch - 1s/step\n",
            "Epoch 829/3000\n",
            "1/1 - 1s - loss: 0.2389 - val_loss: 0.2111 - 1s/epoch - 1s/step\n",
            "Epoch 830/3000\n",
            "1/1 - 1s - loss: 0.2383 - val_loss: 0.2106 - 1s/epoch - 1s/step\n",
            "Epoch 831/3000\n",
            "1/1 - 1s - loss: 0.2378 - val_loss: 0.2102 - 1s/epoch - 1s/step\n",
            "Epoch 832/3000\n",
            "1/1 - 1s - loss: 0.2372 - val_loss: 0.2098 - 1s/epoch - 1s/step\n",
            "Epoch 833/3000\n",
            "1/1 - 1s - loss: 0.2367 - val_loss: 0.2093 - 1s/epoch - 1s/step\n",
            "Epoch 834/3000\n",
            "1/1 - 1s - loss: 0.2361 - val_loss: 0.2088 - 1s/epoch - 1s/step\n",
            "Epoch 835/3000\n",
            "1/1 - 1s - loss: 0.2359 - val_loss: 0.2083 - 1s/epoch - 1s/step\n",
            "Epoch 836/3000\n",
            "1/1 - 1s - loss: 0.2353 - val_loss: 0.2079 - 1s/epoch - 1s/step\n",
            "Epoch 837/3000\n",
            "1/1 - 1s - loss: 0.2345 - val_loss: 0.2078 - 1s/epoch - 1s/step\n",
            "Epoch 838/3000\n",
            "1/1 - 1s - loss: 0.2342 - val_loss: 0.2070 - 1s/epoch - 1s/step\n",
            "Epoch 839/3000\n",
            "1/1 - 1s - loss: 0.2335 - val_loss: 0.2060 - 1s/epoch - 1s/step\n",
            "Epoch 840/3000\n",
            "1/1 - 1s - loss: 0.2331 - val_loss: 0.2053 - 1s/epoch - 1s/step\n",
            "Epoch 841/3000\n",
            "1/1 - 1s - loss: 0.2325 - val_loss: 0.2050 - 1s/epoch - 1s/step\n",
            "Epoch 842/3000\n",
            "1/1 - 1s - loss: 0.2319 - val_loss: 0.2050 - 1s/epoch - 1s/step\n",
            "Epoch 843/3000\n",
            "1/1 - 1s - loss: 0.2314 - val_loss: 0.2045 - 1s/epoch - 1s/step\n",
            "Epoch 844/3000\n",
            "1/1 - 1s - loss: 0.2308 - val_loss: 0.2037 - 1s/epoch - 1s/step\n",
            "Epoch 845/3000\n",
            "1/1 - 1s - loss: 0.2302 - val_loss: 0.2030 - 1s/epoch - 1s/step\n",
            "Epoch 846/3000\n",
            "1/1 - 1s - loss: 0.2297 - val_loss: 0.2028 - 1s/epoch - 1s/step\n",
            "Epoch 847/3000\n",
            "1/1 - 1s - loss: 0.2292 - val_loss: 0.2027 - 1s/epoch - 1s/step\n",
            "Epoch 848/3000\n",
            "1/1 - 1s - loss: 0.2286 - val_loss: 0.2022 - 1s/epoch - 1s/step\n",
            "Epoch 849/3000\n",
            "1/1 - 1s - loss: 0.2281 - val_loss: 0.2014 - 1s/epoch - 1s/step\n",
            "Epoch 850/3000\n",
            "1/1 - 1s - loss: 0.2275 - val_loss: 0.2007 - 1s/epoch - 1s/step\n",
            "Epoch 851/3000\n",
            "1/1 - 1s - loss: 0.2269 - val_loss: 0.2003 - 1s/epoch - 1s/step\n",
            "Epoch 852/3000\n",
            "1/1 - 1s - loss: 0.2265 - val_loss: 0.1996 - 1s/epoch - 1s/step\n",
            "Epoch 853/3000\n",
            "1/1 - 1s - loss: 0.2264 - val_loss: 0.1997 - 1s/epoch - 1s/step\n",
            "Epoch 854/3000\n",
            "1/1 - 1s - loss: 0.2262 - val_loss: 0.1987 - 1s/epoch - 1s/step\n",
            "Epoch 855/3000\n",
            "1/1 - 1s - loss: 0.2254 - val_loss: 0.1978 - 1s/epoch - 1s/step\n",
            "Epoch 856/3000\n",
            "1/1 - 1s - loss: 0.2245 - val_loss: 0.1964 - 1s/epoch - 1s/step\n",
            "Epoch 857/3000\n",
            "1/1 - 1s - loss: 0.2234 - val_loss: 0.1955 - 1s/epoch - 1s/step\n",
            "Epoch 858/3000\n",
            "1/1 - 1s - loss: 0.2230 - val_loss: 0.1955 - 1s/epoch - 1s/step\n",
            "Epoch 859/3000\n",
            "1/1 - 1s - loss: 0.2230 - val_loss: 0.1956 - 1s/epoch - 1s/step\n",
            "Epoch 860/3000\n",
            "1/1 - 1s - loss: 0.2234 - val_loss: 0.1973 - 1s/epoch - 1s/step\n",
            "Epoch 861/3000\n",
            "1/1 - 1s - loss: 0.2251 - val_loss: 0.2013 - 1s/epoch - 1s/step\n",
            "Epoch 862/3000\n",
            "1/1 - 1s - loss: 0.2300 - val_loss: 0.2082 - 1s/epoch - 1s/step\n",
            "Epoch 863/3000\n",
            "1/1 - 1s - loss: 0.2360 - val_loss: 0.2129 - 1s/epoch - 1s/step\n",
            "Epoch 864/3000\n",
            "1/1 - 1s - loss: 0.2415 - val_loss: 0.2059 - 1s/epoch - 1s/step\n",
            "Epoch 865/3000\n",
            "1/1 - 1s - loss: 0.2337 - val_loss: 0.1961 - 1s/epoch - 1s/step\n",
            "Epoch 866/3000\n",
            "1/1 - 1s - loss: 0.2220 - val_loss: 0.1932 - 1s/epoch - 1s/step\n",
            "Epoch 867/3000\n",
            "1/1 - 1s - loss: 0.2198 - val_loss: 0.2010 - 1s/epoch - 1s/step\n",
            "Epoch 868/3000\n",
            "1/1 - 1s - loss: 0.2277 - val_loss: 0.2051 - 1s/epoch - 1s/step\n",
            "Epoch 869/3000\n",
            "1/1 - 1s - loss: 0.2321 - val_loss: 0.1983 - 1s/epoch - 1s/step\n",
            "Epoch 870/3000\n",
            "1/1 - 1s - loss: 0.2244 - val_loss: 0.1919 - 1s/epoch - 1s/step\n",
            "Epoch 871/3000\n",
            "1/1 - 1s - loss: 0.2165 - val_loss: 0.1926 - 1s/epoch - 1s/step\n",
            "Epoch 872/3000\n",
            "1/1 - 1s - loss: 0.2180 - val_loss: 0.1987 - 1s/epoch - 1s/step\n",
            "Epoch 873/3000\n",
            "1/1 - 1s - loss: 0.2248 - val_loss: 0.2032 - 1s/epoch - 1s/step\n",
            "Epoch 874/3000\n",
            "1/1 - 1s - loss: 0.2300 - val_loss: 0.1991 - 1s/epoch - 1s/step\n",
            "Epoch 875/3000\n",
            "1/1 - 1s - loss: 0.2255 - val_loss: 0.1939 - 1s/epoch - 1s/step\n",
            "Epoch 876/3000\n",
            "1/1 - 1s - loss: 0.2178 - val_loss: 0.1890 - 1s/epoch - 1s/step\n",
            "Epoch 877/3000\n",
            "1/1 - 1s - loss: 0.2130 - val_loss: 0.1920 - 1s/epoch - 1s/step\n",
            "Epoch 878/3000\n",
            "1/1 - 1s - loss: 0.2170 - val_loss: 0.1960 - 1s/epoch - 1s/step\n",
            "Epoch 879/3000\n",
            "1/1 - 1s - loss: 0.2221 - val_loss: 0.1931 - 1s/epoch - 1s/step\n",
            "Epoch 880/3000\n",
            "1/1 - 1s - loss: 0.2182 - val_loss: 0.1891 - 1s/epoch - 1s/step\n",
            "Epoch 881/3000\n",
            "1/1 - 1s - loss: 0.2127 - val_loss: 0.1873 - 1s/epoch - 1s/step\n",
            "Epoch 882/3000\n",
            "1/1 - 1s - loss: 0.2111 - val_loss: 0.1883 - 1s/epoch - 1s/step\n",
            "Epoch 883/3000\n",
            "1/1 - 1s - loss: 0.2136 - val_loss: 0.1904 - 1s/epoch - 1s/step\n",
            "Epoch 884/3000\n",
            "1/1 - 1s - loss: 0.2163 - val_loss: 0.1883 - 1s/epoch - 1s/step\n",
            "Epoch 885/3000\n",
            "1/1 - 1s - loss: 0.2144 - val_loss: 0.1863 - 1s/epoch - 1s/step\n",
            "Epoch 886/3000\n",
            "1/1 - 1s - loss: 0.2115 - val_loss: 0.1835 - 1s/epoch - 1s/step\n",
            "Epoch 887/3000\n",
            "1/1 - 1s - loss: 0.2087 - val_loss: 0.1826 - 1s/epoch - 1s/step\n",
            "Epoch 888/3000\n",
            "1/1 - 1s - loss: 0.2077 - val_loss: 0.1834 - 1s/epoch - 1s/step\n",
            "Epoch 889/3000\n",
            "1/1 - 1s - loss: 0.2086 - val_loss: 0.1844 - 1s/epoch - 1s/step\n",
            "Epoch 890/3000\n",
            "1/1 - 1s - loss: 0.2097 - val_loss: 0.1852 - 1s/epoch - 1s/step\n",
            "Epoch 891/3000\n",
            "1/1 - 1s - loss: 0.2099 - val_loss: 0.1839 - 1s/epoch - 1s/step\n",
            "Epoch 892/3000\n",
            "1/1 - 1s - loss: 0.2083 - val_loss: 0.1827 - 1s/epoch - 1s/step\n",
            "Epoch 893/3000\n",
            "1/1 - 1s - loss: 0.2066 - val_loss: 0.1807 - 1s/epoch - 1s/step\n",
            "Epoch 894/3000\n",
            "1/1 - 1s - loss: 0.2050 - val_loss: 0.1801 - 1s/epoch - 1s/step\n",
            "Epoch 895/3000\n",
            "1/1 - 1s - loss: 0.2044 - val_loss: 0.1806 - 1s/epoch - 1s/step\n",
            "Epoch 896/3000\n",
            "1/1 - 1s - loss: 0.2046 - val_loss: 0.1807 - 1s/epoch - 1s/step\n",
            "Epoch 897/3000\n",
            "1/1 - 1s - loss: 0.2049 - val_loss: 0.1813 - 1s/epoch - 1s/step\n",
            "Epoch 898/3000\n",
            "1/1 - 1s - loss: 0.2049 - val_loss: 0.1798 - 1s/epoch - 1s/step\n",
            "Epoch 899/3000\n",
            "1/1 - 1s - loss: 0.2041 - val_loss: 0.1793 - 1s/epoch - 1s/step\n",
            "Epoch 900/3000\n",
            "1/1 - 1s - loss: 0.2031 - val_loss: 0.1781 - 1s/epoch - 1s/step\n",
            "Epoch 901/3000\n",
            "1/1 - 1s - loss: 0.2021 - val_loss: 0.1777 - 1s/epoch - 1s/step\n",
            "Epoch 902/3000\n",
            "1/1 - 1s - loss: 0.2013 - val_loss: 0.1774 - 1s/epoch - 1s/step\n",
            "Epoch 903/3000\n",
            "1/1 - 1s - loss: 0.2008 - val_loss: 0.1772 - 1s/epoch - 1s/step\n",
            "Epoch 904/3000\n",
            "1/1 - 1s - loss: 0.2007 - val_loss: 0.1774 - 1s/epoch - 1s/step\n",
            "Epoch 905/3000\n",
            "1/1 - 1s - loss: 0.2006 - val_loss: 0.1768 - 1s/epoch - 1s/step\n",
            "Epoch 906/3000\n",
            "1/1 - 1s - loss: 0.2003 - val_loss: 0.1768 - 1s/epoch - 1s/step\n",
            "Epoch 907/3000\n",
            "1/1 - 1s - loss: 0.2000 - val_loss: 0.1760 - 1s/epoch - 1s/step\n",
            "Epoch 908/3000\n",
            "1/1 - 1s - loss: 0.1994 - val_loss: 0.1759 - 1s/epoch - 1s/step\n",
            "Epoch 909/3000\n",
            "1/1 - 1s - loss: 0.1989 - val_loss: 0.1749 - 1s/epoch - 1s/step\n",
            "Epoch 910/3000\n",
            "1/1 - 1s - loss: 0.1982 - val_loss: 0.1746 - 1s/epoch - 1s/step\n",
            "Epoch 911/3000\n",
            "1/1 - 1s - loss: 0.1976 - val_loss: 0.1739 - 1s/epoch - 1s/step\n",
            "Epoch 912/3000\n",
            "1/1 - 1s - loss: 0.1971 - val_loss: 0.1737 - 1s/epoch - 1s/step\n",
            "Epoch 913/3000\n",
            "1/1 - 1s - loss: 0.1966 - val_loss: 0.1732 - 1s/epoch - 1s/step\n",
            "Epoch 914/3000\n",
            "1/1 - 1s - loss: 0.1962 - val_loss: 0.1730 - 1s/epoch - 1s/step\n",
            "Epoch 915/3000\n",
            "1/1 - 1s - loss: 0.1957 - val_loss: 0.1726 - 1s/epoch - 1s/step\n",
            "Epoch 916/3000\n",
            "1/1 - 1s - loss: 0.1953 - val_loss: 0.1722 - 1s/epoch - 1s/step\n",
            "Epoch 917/3000\n",
            "1/1 - 1s - loss: 0.1949 - val_loss: 0.1719 - 1s/epoch - 1s/step\n",
            "Epoch 918/3000\n",
            "1/1 - 1s - loss: 0.1945 - val_loss: 0.1716 - 1s/epoch - 1s/step\n",
            "Epoch 919/3000\n",
            "1/1 - 1s - loss: 0.1941 - val_loss: 0.1714 - 1s/epoch - 1s/step\n",
            "Epoch 920/3000\n",
            "1/1 - 1s - loss: 0.1937 - val_loss: 0.1711 - 1s/epoch - 1s/step\n",
            "Epoch 921/3000\n",
            "1/1 - 1s - loss: 0.1933 - val_loss: 0.1709 - 1s/epoch - 1s/step\n",
            "Epoch 922/3000\n",
            "1/1 - 1s - loss: 0.1929 - val_loss: 0.1705 - 1s/epoch - 1s/step\n",
            "Epoch 923/3000\n",
            "1/1 - 1s - loss: 0.1926 - val_loss: 0.1706 - 1s/epoch - 1s/step\n",
            "Epoch 924/3000\n",
            "1/1 - 1s - loss: 0.1923 - val_loss: 0.1702 - 1s/epoch - 1s/step\n",
            "Epoch 925/3000\n",
            "1/1 - 1s - loss: 0.1922 - val_loss: 0.1718 - 1s/epoch - 1s/step\n",
            "Epoch 926/3000\n",
            "1/1 - 1s - loss: 0.1932 - val_loss: 0.1737 - 1s/epoch - 1s/step\n",
            "Epoch 927/3000\n",
            "1/1 - 1s - loss: 0.1963 - val_loss: 0.1845 - 1s/epoch - 1s/step\n",
            "Epoch 928/3000\n",
            "1/1 - 1s - loss: 0.2049 - val_loss: 0.1943 - 1s/epoch - 1s/step\n",
            "Epoch 929/3000\n",
            "1/1 - 1s - loss: 0.2197 - val_loss: 0.2336 - 1s/epoch - 1s/step\n",
            "Epoch 930/3000\n",
            "1/1 - 1s - loss: 0.2517 - val_loss: 0.2365 - 1s/epoch - 1s/step\n",
            "Epoch 931/3000\n",
            "1/1 - 1s - loss: 0.2661 - val_loss: 0.2799 - 1s/epoch - 1s/step\n",
            "Epoch 932/3000\n",
            "1/1 - 1s - loss: 0.2915 - val_loss: 0.2026 - 1s/epoch - 1s/step\n",
            "Epoch 933/3000\n",
            "1/1 - 1s - loss: 0.2267 - val_loss: 0.1779 - 1s/epoch - 1s/step\n",
            "Epoch 934/3000\n",
            "1/1 - 1s - loss: 0.1952 - val_loss: 0.2129 - 1s/epoch - 1s/step\n",
            "Epoch 935/3000\n",
            "1/1 - 1s - loss: 0.2315 - val_loss: 0.2231 - 1s/epoch - 1s/step\n",
            "Epoch 936/3000\n",
            "1/1 - 1s - loss: 0.2463 - val_loss: 0.2291 - 1s/epoch - 1s/step\n",
            "Epoch 937/3000\n",
            "1/1 - 1s - loss: 0.2395 - val_loss: 0.1818 - 1s/epoch - 1s/step\n",
            "Epoch 938/3000\n",
            "1/1 - 1s - loss: 0.2006 - val_loss: 0.1844 - 1s/epoch - 1s/step\n",
            "Epoch 939/3000\n",
            "1/1 - 1s - loss: 0.2068 - val_loss: 0.2260 - 1s/epoch - 1s/step\n",
            "Epoch 940/3000\n",
            "1/1 - 1s - loss: 0.2432 - val_loss: 0.2180 - 1s/epoch - 1s/step\n",
            "Epoch 941/3000\n",
            "1/1 - 1s - loss: 0.2423 - val_loss: 0.2227 - 1s/epoch - 1s/step\n",
            "Epoch 942/3000\n",
            "1/1 - 1s - loss: 0.2388 - val_loss: 0.1818 - 1s/epoch - 1s/step\n",
            "Epoch 943/3000\n",
            "1/1 - 1s - loss: 0.2070 - val_loss: 0.1700 - 1s/epoch - 1s/step\n",
            "Epoch 944/3000\n",
            "1/1 - 1s - loss: 0.1896 - val_loss: 0.1836 - 1s/epoch - 1s/step\n",
            "Epoch 945/3000\n",
            "1/1 - 1s - loss: 0.2015 - val_loss: 0.1994 - 1s/epoch - 1s/step\n",
            "Epoch 946/3000\n",
            "1/1 - 1s - loss: 0.2232 - val_loss: 0.2211 - 1s/epoch - 1s/step\n",
            "Epoch 947/3000\n",
            "1/1 - 1s - loss: 0.2421 - val_loss: 0.1922 - 1s/epoch - 1s/step\n",
            "Epoch 948/3000\n",
            "1/1 - 1s - loss: 0.2166 - val_loss: 0.1765 - 1s/epoch - 1s/step\n",
            "Epoch 949/3000\n",
            "1/1 - 1s - loss: 0.1931 - val_loss: 0.1716 - 1s/epoch - 1s/step\n",
            "Epoch 950/3000\n",
            "1/1 - 1s - loss: 0.1897 - val_loss: 0.1829 - 1s/epoch - 1s/step\n",
            "Epoch 951/3000\n",
            "1/1 - 1s - loss: 0.2069 - val_loss: 0.2023 - 1s/epoch - 1s/step\n",
            "Epoch 952/3000\n",
            "1/1 - 1s - loss: 0.2245 - val_loss: 0.1845 - 1s/epoch - 1s/step\n",
            "Epoch 953/3000\n",
            "1/1 - 1s - loss: 0.2081 - val_loss: 0.1741 - 1s/epoch - 1s/step\n",
            "Epoch 954/3000\n",
            "1/1 - 1s - loss: 0.1921 - val_loss: 0.1646 - 1s/epoch - 1s/step\n",
            "Epoch 955/3000\n",
            "1/1 - 1s - loss: 0.1847 - val_loss: 0.1685 - 1s/epoch - 1s/step\n",
            "Epoch 956/3000\n",
            "1/1 - 1s - loss: 0.1911 - val_loss: 0.1824 - 1s/epoch - 1s/step\n",
            "Epoch 957/3000\n",
            "1/1 - 1s - loss: 0.2017 - val_loss: 0.1776 - 1s/epoch - 1s/step\n",
            "Epoch 958/3000\n",
            "1/1 - 1s - loss: 0.1994 - val_loss: 0.1746 - 1s/epoch - 1s/step\n",
            "Epoch 959/3000\n",
            "1/1 - 1s - loss: 0.1931 - val_loss: 0.1637 - 1s/epoch - 1s/step\n",
            "Epoch 960/3000\n",
            "1/1 - 1s - loss: 0.1839 - val_loss: 0.1626 - 1s/epoch - 1s/step\n",
            "Epoch 961/3000\n",
            "1/1 - 1s - loss: 0.1817 - val_loss: 0.1686 - 1s/epoch - 1s/step\n",
            "Epoch 962/3000\n",
            "1/1 - 1s - loss: 0.1861 - val_loss: 0.1695 - 1s/epoch - 1s/step\n",
            "Epoch 963/3000\n",
            "1/1 - 1s - loss: 0.1899 - val_loss: 0.1713 - 1s/epoch - 1s/step\n",
            "Epoch 964/3000\n",
            "1/1 - 1s - loss: 0.1904 - val_loss: 0.1638 - 1s/epoch - 1s/step\n",
            "Epoch 965/3000\n",
            "1/1 - 1s - loss: 0.1842 - val_loss: 0.1614 - 1s/epoch - 1s/step\n",
            "Epoch 966/3000\n",
            "1/1 - 1s - loss: 0.1797 - val_loss: 0.1602 - 1s/epoch - 1s/step\n",
            "Epoch 967/3000\n",
            "1/1 - 1s - loss: 0.1787 - val_loss: 0.1605 - 1s/epoch - 1s/step\n",
            "Epoch 968/3000\n",
            "1/1 - 1s - loss: 0.1809 - val_loss: 0.1652 - 1s/epoch - 1s/step\n",
            "Epoch 969/3000\n",
            "1/1 - 1s - loss: 0.1845 - val_loss: 0.1633 - 1s/epoch - 1s/step\n",
            "Epoch 970/3000\n",
            "1/1 - 1s - loss: 0.1845 - val_loss: 0.1658 - 1s/epoch - 1s/step\n",
            "Epoch 971/3000\n",
            "1/1 - 1s - loss: 0.1838 - val_loss: 0.1601 - 1s/epoch - 1s/step\n",
            "Epoch 972/3000\n",
            "1/1 - 1s - loss: 0.1802 - val_loss: 0.1587 - 1s/epoch - 1s/step\n",
            "Epoch 973/3000\n",
            "1/1 - 1s - loss: 0.1770 - val_loss: 0.1566 - 1s/epoch - 1s/step\n",
            "Epoch 974/3000\n",
            "1/1 - 1s - loss: 0.1756 - val_loss: 0.1573 - 1s/epoch - 1s/step\n",
            "Epoch 975/3000\n",
            "1/1 - 1s - loss: 0.1769 - val_loss: 0.1612 - 1s/epoch - 1s/step\n",
            "Epoch 976/3000\n",
            "1/1 - 1s - loss: 0.1794 - val_loss: 0.1609 - 1s/epoch - 1s/step\n",
            "Epoch 977/3000\n",
            "1/1 - 1s - loss: 0.1806 - val_loss: 0.1656 - 1s/epoch - 1s/step\n",
            "Epoch 978/3000\n",
            "1/1 - 1s - loss: 0.1819 - val_loss: 0.1598 - 1s/epoch - 1s/step\n",
            "Epoch 979/3000\n",
            "1/1 - 1s - loss: 0.1793 - val_loss: 0.1591 - 1s/epoch - 1s/step\n",
            "Epoch 980/3000\n",
            "1/1 - 1s - loss: 0.1762 - val_loss: 0.1553 - 1s/epoch - 1s/step\n",
            "Epoch 981/3000\n",
            "1/1 - 1s - loss: 0.1739 - val_loss: 0.1547 - 1s/epoch - 1s/step\n",
            "Epoch 982/3000\n",
            "1/1 - 1s - loss: 0.1731 - val_loss: 0.1557 - 1s/epoch - 1s/step\n",
            "Epoch 983/3000\n",
            "1/1 - 1s - loss: 0.1732 - val_loss: 0.1556 - 1s/epoch - 1s/step\n",
            "Epoch 984/3000\n",
            "1/1 - 1s - loss: 0.1744 - val_loss: 0.1594 - 1s/epoch - 1s/step\n",
            "Epoch 985/3000\n",
            "1/1 - 1s - loss: 0.1757 - val_loss: 0.1567 - 1s/epoch - 1s/step\n",
            "Epoch 986/3000\n",
            "1/1 - 1s - loss: 0.1757 - val_loss: 0.1591 - 1s/epoch - 1s/step\n",
            "Epoch 987/3000\n",
            "1/1 - 1s - loss: 0.1759 - val_loss: 0.1559 - 1s/epoch - 1s/step\n",
            "Epoch 988/3000\n",
            "1/1 - 1s - loss: 0.1749 - val_loss: 0.1579 - 1s/epoch - 1s/step\n",
            "Epoch 989/3000\n",
            "1/1 - 1s - loss: 0.1743 - val_loss: 0.1546 - 1s/epoch - 1s/step\n",
            "Epoch 990/3000\n",
            "1/1 - 1s - loss: 0.1732 - val_loss: 0.1558 - 1s/epoch - 1s/step\n",
            "Epoch 991/3000\n",
            "1/1 - 1s - loss: 0.1722 - val_loss: 0.1527 - 1s/epoch - 1s/step\n",
            "Epoch 992/3000\n",
            "1/1 - 1s - loss: 0.1709 - val_loss: 0.1530 - 1s/epoch - 1s/step\n",
            "Epoch 993/3000\n",
            "1/1 - 1s - loss: 0.1700 - val_loss: 0.1516 - 1s/epoch - 1s/step\n",
            "Epoch 994/3000\n",
            "1/1 - 1s - loss: 0.1694 - val_loss: 0.1518 - 1s/epoch - 1s/step\n",
            "Epoch 995/3000\n",
            "1/1 - 1s - loss: 0.1688 - val_loss: 0.1511 - 1s/epoch - 1s/step\n",
            "Epoch 996/3000\n",
            "1/1 - 1s - loss: 0.1684 - val_loss: 0.1510 - 1s/epoch - 1s/step\n",
            "Epoch 997/3000\n",
            "1/1 - 1s - loss: 0.1681 - val_loss: 0.1507 - 1s/epoch - 1s/step\n",
            "Epoch 998/3000\n",
            "1/1 - 1s - loss: 0.1677 - val_loss: 0.1502 - 1s/epoch - 1s/step\n",
            "Epoch 999/3000\n",
            "1/1 - 1s - loss: 0.1675 - val_loss: 0.1504 - 1s/epoch - 1s/step\n",
            "Epoch 1000/3000\n",
            "1/1 - 1s - loss: 0.1672 - val_loss: 0.1497 - 1s/epoch - 1s/step\n",
            "Epoch 1001/3000\n",
            "1/1 - 1s - loss: 0.1670 - val_loss: 0.1507 - 1s/epoch - 1s/step\n",
            "Epoch 1002/3000\n",
            "1/1 - 1s - loss: 0.1669 - val_loss: 0.1497 - 1s/epoch - 1s/step\n",
            "Epoch 1003/3000\n",
            "1/1 - 1s - loss: 0.1669 - val_loss: 0.1515 - 1s/epoch - 1s/step\n",
            "Epoch 1004/3000\n",
            "1/1 - 1s - loss: 0.1672 - val_loss: 0.1502 - 1s/epoch - 1s/step\n",
            "Epoch 1005/3000\n",
            "1/1 - 1s - loss: 0.1678 - val_loss: 0.1547 - 1s/epoch - 1s/step\n",
            "Epoch 1006/3000\n",
            "1/1 - 1s - loss: 0.1698 - val_loss: 0.1549 - 1s/epoch - 1s/step\n",
            "Epoch 1007/3000\n",
            "1/1 - 1s - loss: 0.1733 - val_loss: 0.1701 - 1s/epoch - 1s/step\n",
            "Epoch 1008/3000\n",
            "1/1 - 1s - loss: 0.1832 - val_loss: 0.1731 - 1s/epoch - 1s/step\n",
            "Epoch 1009/3000\n",
            "1/1 - 1s - loss: 0.1937 - val_loss: 0.2213 - 1s/epoch - 1s/step\n",
            "Epoch 1010/3000\n",
            "1/1 - 1s - loss: 0.2309 - val_loss: 0.2252 - 1s/epoch - 1s/step\n",
            "Epoch 1011/3000\n",
            "1/1 - 1s - loss: 0.2505 - val_loss: 0.3564 - 1s/epoch - 1s/step\n",
            "Epoch 1012/3000\n",
            "1/1 - 1s - loss: 0.3560 - val_loss: 0.2744 - 1s/epoch - 1s/step\n",
            "Epoch 1013/3000\n",
            "1/1 - 1s - loss: 0.3067 - val_loss: 0.2828 - 1s/epoch - 1s/step\n",
            "Epoch 1014/3000\n",
            "1/1 - 1s - loss: 0.2761 - val_loss: 0.1644 - 1s/epoch - 1s/step\n",
            "Epoch 1015/3000\n",
            "1/1 - 1s - loss: 0.1767 - val_loss: 0.2059 - 1s/epoch - 1s/step\n",
            "Epoch 1016/3000\n",
            "1/1 - 1s - loss: 0.2251 - val_loss: 0.3338 - 1s/epoch - 1s/step\n",
            "Epoch 1017/3000\n",
            "1/1 - 1s - loss: 0.3470 - val_loss: 0.2481 - 1s/epoch - 1s/step\n",
            "Epoch 1018/3000\n",
            "1/1 - 1s - loss: 0.2720 - val_loss: 0.1948 - 1s/epoch - 1s/step\n",
            "Epoch 1019/3000\n",
            "1/1 - 1s - loss: 0.1941 - val_loss: 0.1947 - 1s/epoch - 1s/step\n",
            "Epoch 1020/3000\n",
            "1/1 - 1s - loss: 0.1954 - val_loss: 0.2197 - 1s/epoch - 1s/step\n",
            "Epoch 1021/3000\n",
            "1/1 - 1s - loss: 0.2465 - val_loss: 0.2678 - 1s/epoch - 1s/step\n",
            "Epoch 1022/3000\n",
            "1/1 - 1s - loss: 0.2768 - val_loss: 0.1923 - 1s/epoch - 1s/step\n",
            "Epoch 1023/3000\n",
            "1/1 - 1s - loss: 0.2112 - val_loss: 0.1561 - 1s/epoch - 1s/step\n",
            "Epoch 1024/3000\n",
            "1/1 - 1s - loss: 0.1680 - val_loss: 0.1621 - 1s/epoch - 1s/step\n",
            "Epoch 1025/3000\n",
            "1/1 - 1s - loss: 0.1741 - val_loss: 0.1751 - 1s/epoch - 1s/step\n",
            "Epoch 1026/3000\n",
            "1/1 - 1s - loss: 0.2007 - val_loss: 0.2110 - 1s/epoch - 1s/step\n",
            "Epoch 1027/3000\n",
            "1/1 - 1s - loss: 0.2203 - val_loss: 0.1789 - 1s/epoch - 1s/step\n",
            "Epoch 1028/3000\n",
            "1/1 - 1s - loss: 0.2000 - val_loss: 0.1701 - 1s/epoch - 1s/step\n",
            "Epoch 1029/3000\n",
            "1/1 - 1s - loss: 0.1854 - val_loss: 0.1466 - 1s/epoch - 1s/step\n",
            "Epoch 1030/3000\n",
            "1/1 - 1s - loss: 0.1666 - val_loss: 0.1436 - 1s/epoch - 1s/step\n",
            "Epoch 1031/3000\n",
            "1/1 - 1s - loss: 0.1613 - val_loss: 0.1528 - 1s/epoch - 1s/step\n",
            "Epoch 1032/3000\n",
            "1/1 - 1s - loss: 0.1677 - val_loss: 0.1540 - 1s/epoch - 1s/step\n",
            "Epoch 1033/3000\n",
            "1/1 - 1s - loss: 0.1751 - val_loss: 0.1694 - 1s/epoch - 1s/step\n",
            "Epoch 1034/3000\n",
            "1/1 - 1s - loss: 0.1855 - val_loss: 0.1605 - 1s/epoch - 1s/step\n",
            "Epoch 1035/3000\n",
            "1/1 - 1s - loss: 0.1819 - val_loss: 0.1719 - 1s/epoch - 1s/step\n",
            "Epoch 1036/3000\n",
            "1/1 - 1s - loss: 0.1840 - val_loss: 0.1525 - 1s/epoch - 1s/step\n",
            "Epoch 1037/3000\n",
            "1/1 - 1s - loss: 0.1714 - val_loss: 0.1466 - 1s/epoch - 1s/step\n",
            "Epoch 1038/3000\n",
            "1/1 - 1s - loss: 0.1608 - val_loss: 0.1426 - 1s/epoch - 1s/step\n",
            "Epoch 1039/3000\n",
            "1/1 - 1s - loss: 0.1577 - val_loss: 0.1477 - 1s/epoch - 1s/step\n",
            "Epoch 1040/3000\n",
            "1/1 - 1s - loss: 0.1632 - val_loss: 0.1602 - 1s/epoch - 1s/step\n",
            "Epoch 1041/3000\n",
            "1/1 - 1s - loss: 0.1721 - val_loss: 0.1573 - 1s/epoch - 1s/step\n",
            "Epoch 1042/3000\n",
            "1/1 - 1s - loss: 0.1732 - val_loss: 0.1632 - 1s/epoch - 1s/step\n",
            "Epoch 1043/3000\n",
            "1/1 - 1s - loss: 0.1725 - val_loss: 0.1483 - 1s/epoch - 1s/step\n",
            "Epoch 1044/3000\n",
            "1/1 - 1s - loss: 0.1624 - val_loss: 0.1440 - 1s/epoch - 1s/step\n",
            "Epoch 1045/3000\n",
            "1/1 - 1s - loss: 0.1562 - val_loss: 0.1435 - 1s/epoch - 1s/step\n",
            "Epoch 1046/3000\n",
            "1/1 - 1s - loss: 0.1566 - val_loss: 0.1458 - 1s/epoch - 1s/step\n",
            "Epoch 1047/3000\n",
            "1/1 - 1s - loss: 0.1608 - val_loss: 0.1571 - 1s/epoch - 1s/step\n",
            "Epoch 1048/3000\n",
            "1/1 - 1s - loss: 0.1680 - val_loss: 0.1541 - 1s/epoch - 1s/step\n",
            "Epoch 1049/3000\n",
            "1/1 - 1s - loss: 0.1709 - val_loss: 0.1638 - 1s/epoch - 1s/step\n",
            "Epoch 1050/3000\n",
            "1/1 - 1s - loss: 0.1731 - val_loss: 0.1488 - 1s/epoch - 1s/step\n",
            "Epoch 1051/3000\n",
            "1/1 - 1s - loss: 0.1654 - val_loss: 0.1489 - 1s/epoch - 1s/step\n",
            "Epoch 1052/3000\n",
            "1/1 - 1s - loss: 0.1617 - val_loss: 0.1416 - 1s/epoch - 1s/step\n",
            "Epoch 1053/3000\n",
            "1/1 - 1s - loss: 0.1570 - val_loss: 0.1415 - 1s/epoch - 1s/step\n",
            "Epoch 1054/3000\n",
            "1/1 - 1s - loss: 0.1543 - val_loss: 0.1384 - 1s/epoch - 1s/step\n",
            "Epoch 1055/3000\n",
            "1/1 - 1s - loss: 0.1526 - val_loss: 0.1381 - 1s/epoch - 1s/step\n",
            "Epoch 1056/3000\n",
            "1/1 - 1s - loss: 0.1519 - val_loss: 0.1386 - 1s/epoch - 1s/step\n",
            "Epoch 1057/3000\n",
            "1/1 - 1s - loss: 0.1519 - val_loss: 0.1381 - 1s/epoch - 1s/step\n",
            "Epoch 1058/3000\n",
            "1/1 - 1s - loss: 0.1528 - val_loss: 0.1421 - 1s/epoch - 1s/step\n",
            "Epoch 1059/3000\n",
            "1/1 - 1s - loss: 0.1547 - val_loss: 0.1411 - 1s/epoch - 1s/step\n",
            "Epoch 1060/3000\n",
            "1/1 - 1s - loss: 0.1568 - val_loss: 0.1521 - 1s/epoch - 1s/step\n",
            "Epoch 1061/3000\n",
            "1/1 - 1s - loss: 0.1623 - val_loss: 0.1486 - 1s/epoch - 1s/step\n",
            "Epoch 1062/3000\n",
            "1/1 - 1s - loss: 0.1656 - val_loss: 0.1673 - 1s/epoch - 1s/step\n",
            "Epoch 1063/3000\n",
            "1/1 - 1s - loss: 0.1756 - val_loss: 0.1616 - 1s/epoch - 1s/step\n",
            "Epoch 1064/3000\n",
            "1/1 - 1s - loss: 0.1795 - val_loss: 0.2010 - 1s/epoch - 1s/step\n",
            "Epoch 1065/3000\n",
            "1/1 - 1s - loss: 0.2068 - val_loss: 0.1900 - 1s/epoch - 1s/step\n",
            "Epoch 1066/3000\n",
            "1/1 - 1s - loss: 0.2102 - val_loss: 0.2538 - 1s/epoch - 1s/step\n",
            "Epoch 1067/3000\n",
            "1/1 - 1s - loss: 0.2517 - val_loss: 0.1971 - 1s/epoch - 1s/step\n",
            "Epoch 1068/3000\n",
            "1/1 - 1s - loss: 0.2188 - val_loss: 0.1953 - 1s/epoch - 1s/step\n",
            "Epoch 1069/3000\n",
            "1/1 - 1s - loss: 0.1962 - val_loss: 0.1461 - 1s/epoch - 1s/step\n",
            "Epoch 1070/3000\n",
            "1/1 - 1s - loss: 0.1580 - val_loss: 0.1434 - 1s/epoch - 1s/step\n",
            "Epoch 1071/3000\n",
            "1/1 - 1s - loss: 0.1550 - val_loss: 0.1737 - 1s/epoch - 1s/step\n",
            "Epoch 1072/3000\n",
            "1/1 - 1s - loss: 0.1803 - val_loss: 0.1799 - 1s/epoch - 1s/step\n",
            "Epoch 1073/3000\n",
            "1/1 - 1s - loss: 0.1986 - val_loss: 0.2192 - 1s/epoch - 1s/step\n",
            "Epoch 1074/3000\n",
            "1/1 - 1s - loss: 0.2166 - val_loss: 0.1639 - 1s/epoch - 1s/step\n",
            "Epoch 1075/3000\n",
            "1/1 - 1s - loss: 0.1836 - val_loss: 0.1470 - 1s/epoch - 1s/step\n",
            "Epoch 1076/3000\n",
            "1/1 - 1s - loss: 0.1541 - val_loss: 0.1393 - 1s/epoch - 1s/step\n",
            "Epoch 1077/3000\n",
            "1/1 - 1s - loss: 0.1497 - val_loss: 0.1537 - 1s/epoch - 1s/step\n",
            "Epoch 1078/3000\n",
            "1/1 - 1s - loss: 0.1697 - val_loss: 0.2065 - 1s/epoch - 1s/step\n",
            "Epoch 1079/3000\n",
            "1/1 - 1s - loss: 0.2121 - val_loss: 0.2061 - 1s/epoch - 1s/step\n",
            "Epoch 1080/3000\n",
            "1/1 - 1s - loss: 0.2318 - val_loss: 0.3057 - 1s/epoch - 1s/step\n",
            "Epoch 1081/3000\n",
            "1/1 - 1s - loss: 0.2971 - val_loss: 0.2065 - 1s/epoch - 1s/step\n",
            "Epoch 1082/3000\n",
            "1/1 - 1s - loss: 0.2347 - val_loss: 0.1839 - 1s/epoch - 1s/step\n",
            "Epoch 1083/3000\n",
            "1/1 - 1s - loss: 0.1863 - val_loss: 0.1363 - 1s/epoch - 1s/step\n",
            "Epoch 1084/3000\n",
            "1/1 - 1s - loss: 0.1490 - val_loss: 0.1501 - 1s/epoch - 1s/step\n",
            "Epoch 1085/3000\n",
            "1/1 - 1s - loss: 0.1658 - val_loss: 0.2126 - 1s/epoch - 1s/step\n",
            "Epoch 1086/3000\n",
            "1/1 - 1s - loss: 0.2175 - val_loss: 0.2039 - 1s/epoch - 1s/step\n",
            "Epoch 1087/3000\n",
            "1/1 - 1s - loss: 0.2295 - val_loss: 0.2493 - 1s/epoch - 1s/step\n",
            "Epoch 1088/3000\n",
            "1/1 - 1s - loss: 0.2407 - val_loss: 0.1520 - 1s/epoch - 1s/step\n",
            "Epoch 1089/3000\n",
            "1/1 - 1s - loss: 0.1704 - val_loss: 0.1363 - 1s/epoch - 1s/step\n",
            "Epoch 1090/3000\n",
            "1/1 - 1s - loss: 0.1484 - val_loss: 0.1843 - 1s/epoch - 1s/step\n",
            "Epoch 1091/3000\n",
            "1/1 - 1s - loss: 0.1948 - val_loss: 0.2219 - 1s/epoch - 1s/step\n",
            "Epoch 1092/3000\n",
            "1/1 - 1s - loss: 0.2403 - val_loss: 0.4070 - 1s/epoch - 1s/step\n",
            "Epoch 1093/3000\n",
            "1/1 - 1s - loss: 0.3953 - val_loss: 0.2717 - 1s/epoch - 1s/step\n",
            "Epoch 1094/3000\n",
            "1/1 - 1s - loss: 0.3155 - val_loss: 0.2042 - 1s/epoch - 1s/step\n",
            "Epoch 1095/3000\n",
            "1/1 - 1s - loss: 0.1966 - val_loss: 0.1582 - 1s/epoch - 1s/step\n",
            "Epoch 1096/3000\n",
            "1/1 - 1s - loss: 0.1612 - val_loss: 0.2679 - 1s/epoch - 1s/step\n",
            "Epoch 1097/3000\n",
            "1/1 - 1s - loss: 0.2876 - val_loss: 0.6051 - 1s/epoch - 1s/step\n",
            "Epoch 1098/3000\n",
            "1/1 - 1s - loss: 0.6152 - val_loss: 0.3244 - 1s/epoch - 1s/step\n",
            "Epoch 1099/3000\n",
            "1/1 - 1s - loss: 0.3633 - val_loss: 0.2017 - 1s/epoch - 1s/step\n",
            "Epoch 1100/3000\n",
            "1/1 - 1s - loss: 0.1959 - val_loss: 0.2819 - 1s/epoch - 1s/step\n",
            "Epoch 1101/3000\n",
            "1/1 - 1s - loss: 0.2622 - val_loss: 0.2717 - 1s/epoch - 1s/step\n",
            "Epoch 1102/3000\n",
            "1/1 - 1s - loss: 0.2990 - val_loss: 0.2521 - 1s/epoch - 1s/step\n",
            "Epoch 1103/3000\n",
            "1/1 - 1s - loss: 0.2606 - val_loss: 0.1517 - 1s/epoch - 1s/step\n",
            "Epoch 1104/3000\n",
            "1/1 - 1s - loss: 0.1630 - val_loss: 0.1957 - 1s/epoch - 1s/step\n",
            "Epoch 1105/3000\n",
            "1/1 - 1s - loss: 0.2188 - val_loss: 0.3139 - 1s/epoch - 1s/step\n",
            "Epoch 1106/3000\n",
            "1/1 - 1s - loss: 0.2983 - val_loss: 0.1675 - 1s/epoch - 1s/step\n",
            "Epoch 1107/3000\n",
            "1/1 - 1s - loss: 0.1910 - val_loss: 0.1488 - 1s/epoch - 1s/step\n",
            "Epoch 1108/3000\n",
            "1/1 - 1s - loss: 0.1662 - val_loss: 0.2525 - 1s/epoch - 1s/step\n",
            "Epoch 1109/3000\n",
            "1/1 - 1s - loss: 0.2588 - val_loss: 0.2595 - 1s/epoch - 1s/step\n",
            "Epoch 1110/3000\n",
            "1/1 - 1s - loss: 0.2812 - val_loss: 0.4496 - 1s/epoch - 1s/step\n",
            "Epoch 1111/3000\n",
            "1/1 - 1s - loss: 0.4420 - val_loss: 0.2271 - 1s/epoch - 1s/step\n",
            "Epoch 1112/3000\n",
            "1/1 - 1s - loss: 0.2653 - val_loss: 0.1513 - 1s/epoch - 1s/step\n",
            "Epoch 1113/3000\n",
            "1/1 - 1s - loss: 0.1684 - val_loss: 0.2636 - 1s/epoch - 1s/step\n",
            "Epoch 1114/3000\n",
            "1/1 - 1s - loss: 0.2627 - val_loss: 0.2851 - 1s/epoch - 1s/step\n",
            "Epoch 1115/3000\n",
            "1/1 - 1s - loss: 0.3055 - val_loss: 0.4226 - 1s/epoch - 1s/step\n",
            "Epoch 1116/3000\n",
            "1/1 - 1s - loss: 0.4261 - val_loss: 0.1749 - 1s/epoch - 1s/step\n",
            "Epoch 1117/3000\n",
            "1/1 - 1s - loss: 0.1950 - val_loss: 0.1883 - 1s/epoch - 1s/step\n",
            "Epoch 1118/3000\n",
            "1/1 - 1s - loss: 0.2155 - val_loss: 0.3644 - 1s/epoch - 1s/step\n",
            "Epoch 1119/3000\n",
            "1/1 - 1s - loss: 0.3459 - val_loss: 0.1786 - 1s/epoch - 1s/step\n",
            "Epoch 1120/3000\n",
            "1/1 - 1s - loss: 0.1936 - val_loss: 0.1656 - 1s/epoch - 1s/step\n",
            "Epoch 1121/3000\n",
            "1/1 - 1s - loss: 0.1790 - val_loss: 0.2964 - 1s/epoch - 1s/step\n",
            "Epoch 1122/3000\n",
            "1/1 - 1s - loss: 0.3018 - val_loss: 0.1994 - 1s/epoch - 1s/step\n",
            "Epoch 1123/3000\n",
            "1/1 - 1s - loss: 0.2218 - val_loss: 0.1480 - 1s/epoch - 1s/step\n",
            "Epoch 1124/3000\n",
            "1/1 - 1s - loss: 0.1521 - val_loss: 0.1896 - 1s/epoch - 1s/step\n",
            "Epoch 1125/3000\n",
            "1/1 - 1s - loss: 0.1857 - val_loss: 0.1837 - 1s/epoch - 1s/step\n",
            "Epoch 1126/3000\n",
            "1/1 - 1s - loss: 0.2062 - val_loss: 0.1795 - 1s/epoch - 1s/step\n",
            "Epoch 1127/3000\n",
            "1/1 - 1s - loss: 0.1876 - val_loss: 0.1309 - 1s/epoch - 1s/step\n",
            "Epoch 1128/3000\n",
            "1/1 - 1s - loss: 0.1439 - val_loss: 0.1407 - 1s/epoch - 1s/step\n",
            "Epoch 1129/3000\n",
            "1/1 - 1s - loss: 0.1550 - val_loss: 0.1902 - 1s/epoch - 1s/step\n",
            "Epoch 1130/3000\n",
            "1/1 - 1s - loss: 0.1967 - val_loss: 0.1611 - 1s/epoch - 1s/step\n",
            "Epoch 1131/3000\n",
            "1/1 - 1s - loss: 0.1854 - val_loss: 0.1549 - 1s/epoch - 1s/step\n",
            "Epoch 1132/3000\n",
            "1/1 - 1s - loss: 0.1627 - val_loss: 0.1249 - 1s/epoch - 1s/step\n",
            "Epoch 1133/3000\n",
            "1/1 - 1s - loss: 0.1381 - val_loss: 0.1364 - 1s/epoch - 1s/step\n",
            "Epoch 1134/3000\n",
            "1/1 - 1s - loss: 0.1531 - val_loss: 0.1903 - 1s/epoch - 1s/step\n",
            "Epoch 1135/3000\n",
            "1/1 - 1s - loss: 0.2028 - val_loss: 0.1818 - 1s/epoch - 1s/step\n",
            "Epoch 1136/3000\n",
            "1/1 - 1s - loss: 0.2008 - val_loss: 0.2395 - 1s/epoch - 1s/step\n",
            "Epoch 1137/3000\n",
            "1/1 - 1s - loss: 0.2345 - val_loss: 0.1467 - 1s/epoch - 1s/step\n",
            "Epoch 1138/3000\n",
            "1/1 - 1s - loss: 0.1627 - val_loss: 0.1363 - 1s/epoch - 1s/step\n",
            "Epoch 1139/3000\n",
            "1/1 - 1s - loss: 0.1490 - val_loss: 0.1960 - 1s/epoch - 1s/step\n",
            "Epoch 1140/3000\n",
            "1/1 - 1s - loss: 0.2054 - val_loss: 0.1889 - 1s/epoch - 1s/step\n",
            "Epoch 1141/3000\n",
            "1/1 - 1s - loss: 0.2025 - val_loss: 0.1900 - 1s/epoch - 1s/step\n",
            "Epoch 1142/3000\n",
            "1/1 - 1s - loss: 0.1915 - val_loss: 0.1384 - 1s/epoch - 1s/step\n",
            "Epoch 1143/3000\n",
            "1/1 - 1s - loss: 0.1482 - val_loss: 0.1439 - 1s/epoch - 1s/step\n",
            "Epoch 1144/3000\n",
            "1/1 - 1s - loss: 0.1570 - val_loss: 0.1848 - 1s/epoch - 1s/step\n",
            "Epoch 1145/3000\n",
            "1/1 - 1s - loss: 0.1829 - val_loss: 0.1512 - 1s/epoch - 1s/step\n",
            "Epoch 1146/3000\n",
            "1/1 - 1s - loss: 0.1631 - val_loss: 0.1315 - 1s/epoch - 1s/step\n",
            "Epoch 1147/3000\n",
            "1/1 - 1s - loss: 0.1412 - val_loss: 0.1283 - 1s/epoch - 1s/step\n",
            "Epoch 1148/3000\n",
            "1/1 - 1s - loss: 0.1375 - val_loss: 0.1361 - 1s/epoch - 1s/step\n",
            "Epoch 1149/3000\n",
            "1/1 - 1s - loss: 0.1515 - val_loss: 0.1592 - 1s/epoch - 1s/step\n",
            "Epoch 1150/3000\n",
            "1/1 - 1s - loss: 0.1616 - val_loss: 0.1265 - 1s/epoch - 1s/step\n",
            "Epoch 1151/3000\n",
            "1/1 - 1s - loss: 0.1418 - val_loss: 0.1187 - 1s/epoch - 1s/step\n",
            "Epoch 1152/3000\n",
            "1/1 - 1s - loss: 0.1315 - val_loss: 0.1283 - 1s/epoch - 1s/step\n",
            "Epoch 1153/3000\n",
            "1/1 - 1s - loss: 0.1406 - val_loss: 0.1401 - 1s/epoch - 1s/step\n",
            "Epoch 1154/3000\n",
            "1/1 - 1s - loss: 0.1555 - val_loss: 0.1930 - 1s/epoch - 1s/step\n",
            "Epoch 1155/3000\n",
            "1/1 - 1s - loss: 0.1966 - val_loss: 0.1647 - 1s/epoch - 1s/step\n",
            "Epoch 1156/3000\n",
            "1/1 - 1s - loss: 0.1890 - val_loss: 0.1852 - 1s/epoch - 1s/step\n",
            "Epoch 1157/3000\n",
            "1/1 - 1s - loss: 0.1851 - val_loss: 0.1245 - 1s/epoch - 1s/step\n",
            "Epoch 1158/3000\n",
            "1/1 - 1s - loss: 0.1374 - val_loss: 0.1247 - 1s/epoch - 1s/step\n",
            "Epoch 1159/3000\n",
            "1/1 - 1s - loss: 0.1371 - val_loss: 0.1659 - 1s/epoch - 1s/step\n",
            "Epoch 1160/3000\n",
            "1/1 - 1s - loss: 0.1767 - val_loss: 0.1733 - 1s/epoch - 1s/step\n",
            "Epoch 1161/3000\n",
            "1/1 - 1s - loss: 0.1894 - val_loss: 0.2436 - 1s/epoch - 1s/step\n",
            "Epoch 1162/3000\n",
            "1/1 - 1s - loss: 0.2332 - val_loss: 0.1544 - 1s/epoch - 1s/step\n",
            "Epoch 1163/3000\n",
            "1/1 - 1s - loss: 0.1734 - val_loss: 0.1282 - 1s/epoch - 1s/step\n",
            "Epoch 1164/3000\n",
            "1/1 - 1s - loss: 0.1367 - val_loss: 0.1738 - 1s/epoch - 1s/step\n",
            "Epoch 1165/3000\n",
            "1/1 - 1s - loss: 0.1774 - val_loss: 0.1966 - 1s/epoch - 1s/step\n",
            "Epoch 1166/3000\n",
            "1/1 - 1s - loss: 0.2104 - val_loss: 0.2771 - 1s/epoch - 1s/step\n",
            "Epoch 1167/3000\n",
            "1/1 - 1s - loss: 0.2729 - val_loss: 0.1717 - 1s/epoch - 1s/step\n",
            "Epoch 1168/3000\n",
            "1/1 - 1s - loss: 0.1923 - val_loss: 0.1372 - 1s/epoch - 1s/step\n",
            "Epoch 1169/3000\n",
            "1/1 - 1s - loss: 0.1431 - val_loss: 0.1785 - 1s/epoch - 1s/step\n",
            "Epoch 1170/3000\n",
            "1/1 - 1s - loss: 0.1737 - val_loss: 0.1895 - 1s/epoch - 1s/step\n",
            "Epoch 1171/3000\n",
            "1/1 - 1s - loss: 0.2048 - val_loss: 0.2307 - 1s/epoch - 1s/step\n",
            "Epoch 1172/3000\n",
            "1/1 - 1s - loss: 0.2349 - val_loss: 0.1463 - 1s/epoch - 1s/step\n",
            "Epoch 1173/3000\n",
            "1/1 - 1s - loss: 0.1610 - val_loss: 0.1230 - 1s/epoch - 1s/step\n",
            "Epoch 1174/3000\n",
            "1/1 - 1s - loss: 0.1309 - val_loss: 0.1546 - 1s/epoch - 1s/step\n",
            "Epoch 1175/3000\n",
            "1/1 - 1s - loss: 0.1540 - val_loss: 0.1502 - 1s/epoch - 1s/step\n",
            "Epoch 1176/3000\n",
            "1/1 - 1s - loss: 0.1679 - val_loss: 0.1621 - 1s/epoch - 1s/step\n",
            "Epoch 1177/3000\n",
            "1/1 - 1s - loss: 0.1666 - val_loss: 0.1235 - 1s/epoch - 1s/step\n",
            "Epoch 1178/3000\n",
            "1/1 - 1s - loss: 0.1375 - val_loss: 0.1147 - 1s/epoch - 1s/step\n",
            "Epoch 1179/3000\n",
            "1/1 - 1s - loss: 0.1254 - val_loss: 0.1261 - 1s/epoch - 1s/step\n",
            "Epoch 1180/3000\n",
            "1/1 - 1s - loss: 0.1331 - val_loss: 0.1263 - 1s/epoch - 1s/step\n",
            "Epoch 1181/3000\n",
            "1/1 - 1s - loss: 0.1427 - val_loss: 0.1425 - 1s/epoch - 1s/step\n",
            "Epoch 1182/3000\n",
            "1/1 - 1s - loss: 0.1479 - val_loss: 0.1217 - 1s/epoch - 1s/step\n",
            "Epoch 1183/3000\n",
            "1/1 - 1s - loss: 0.1357 - val_loss: 0.1198 - 1s/epoch - 1s/step\n",
            "Epoch 1184/3000\n",
            "1/1 - 1s - loss: 0.1284 - val_loss: 0.1134 - 1s/epoch - 1s/step\n",
            "Epoch 1185/3000\n",
            "1/1 - 1s - loss: 0.1236 - val_loss: 0.1139 - 1s/epoch - 1s/step\n",
            "Epoch 1186/3000\n",
            "1/1 - 1s - loss: 0.1246 - val_loss: 0.1228 - 1s/epoch - 1s/step\n",
            "Epoch 1187/3000\n",
            "1/1 - 1s - loss: 0.1296 - val_loss: 0.1201 - 1s/epoch - 1s/step\n",
            "Epoch 1188/3000\n",
            "1/1 - 1s - loss: 0.1318 - val_loss: 0.1275 - 1s/epoch - 1s/step\n",
            "Epoch 1189/3000\n",
            "1/1 - 1s - loss: 0.1332 - val_loss: 0.1178 - 1s/epoch - 1s/step\n",
            "Epoch 1190/3000\n",
            "1/1 - 1s - loss: 0.1287 - val_loss: 0.1188 - 1s/epoch - 1s/step\n",
            "Epoch 1191/3000\n",
            "1/1 - 1s - loss: 0.1258 - val_loss: 0.1136 - 1s/epoch - 1s/step\n",
            "Epoch 1192/3000\n",
            "1/1 - 1s - loss: 0.1226 - val_loss: 0.1133 - 1s/epoch - 1s/step\n",
            "Epoch 1193/3000\n",
            "1/1 - 1s - loss: 0.1211 - val_loss: 0.1137 - 1s/epoch - 1s/step\n",
            "Epoch 1194/3000\n",
            "1/1 - 1s - loss: 0.1213 - val_loss: 0.1129 - 1s/epoch - 1s/step\n",
            "Epoch 1195/3000\n",
            "1/1 - 1s - loss: 0.1222 - val_loss: 0.1172 - 1s/epoch - 1s/step\n",
            "Epoch 1196/3000\n",
            "1/1 - 1s - loss: 0.1238 - val_loss: 0.1146 - 1s/epoch - 1s/step\n",
            "Epoch 1197/3000\n",
            "1/1 - 1s - loss: 0.1247 - val_loss: 0.1212 - 1s/epoch - 1s/step\n",
            "Epoch 1198/3000\n",
            "1/1 - 1s - loss: 0.1271 - val_loss: 0.1169 - 1s/epoch - 1s/step\n",
            "Epoch 1199/3000\n",
            "1/1 - 1s - loss: 0.1278 - val_loss: 0.1277 - 1s/epoch - 1s/step\n",
            "Epoch 1200/3000\n",
            "1/1 - 1s - loss: 0.1322 - val_loss: 0.1201 - 1s/epoch - 1s/step\n",
            "Epoch 1201/3000\n",
            "1/1 - 1s - loss: 0.1312 - val_loss: 0.1319 - 1s/epoch - 1s/step\n",
            "Epoch 1202/3000\n",
            "1/1 - 1s - loss: 0.1356 - val_loss: 0.1219 - 1s/epoch - 1s/step\n",
            "Epoch 1203/3000\n",
            "1/1 - 1s - loss: 0.1332 - val_loss: 0.1344 - 1s/epoch - 1s/step\n",
            "Epoch 1204/3000\n",
            "1/1 - 1s - loss: 0.1375 - val_loss: 0.1213 - 1s/epoch - 1s/step\n",
            "Epoch 1205/3000\n",
            "1/1 - 1s - loss: 0.1323 - val_loss: 0.1280 - 1s/epoch - 1s/step\n",
            "Epoch 1206/3000\n",
            "1/1 - 1s - loss: 0.1313 - val_loss: 0.1148 - 1s/epoch - 1s/step\n",
            "Epoch 1207/3000\n",
            "1/1 - 1s - loss: 0.1249 - val_loss: 0.1155 - 1s/epoch - 1s/step\n",
            "Epoch 1208/3000\n",
            "1/1 - 1s - loss: 0.1208 - val_loss: 0.1099 - 1s/epoch - 1s/step\n",
            "Epoch 1209/3000\n",
            "1/1 - 1s - loss: 0.1178 - val_loss: 0.1094 - 1s/epoch - 1s/step\n",
            "Epoch 1210/3000\n",
            "1/1 - 1s - loss: 0.1173 - val_loss: 0.1125 - 1s/epoch - 1s/step\n",
            "Epoch 1211/3000\n",
            "1/1 - 1s - loss: 0.1188 - val_loss: 0.1108 - 1s/epoch - 1s/step\n",
            "Epoch 1212/3000\n",
            "1/1 - 1s - loss: 0.1208 - val_loss: 0.1197 - 1s/epoch - 1s/step\n",
            "Epoch 1213/3000\n",
            "1/1 - 1s - loss: 0.1243 - val_loss: 0.1145 - 1s/epoch - 1s/step\n",
            "Epoch 1214/3000\n",
            "1/1 - 1s - loss: 0.1258 - val_loss: 0.1291 - 1s/epoch - 1s/step\n",
            "Epoch 1215/3000\n",
            "1/1 - 1s - loss: 0.1324 - val_loss: 0.1222 - 1s/epoch - 1s/step\n",
            "Epoch 1216/3000\n",
            "1/1 - 1s - loss: 0.1345 - val_loss: 0.1509 - 1s/epoch - 1s/step\n",
            "Epoch 1217/3000\n",
            "1/1 - 1s - loss: 0.1514 - val_loss: 0.1387 - 1s/epoch - 1s/step\n",
            "Epoch 1218/3000\n",
            "1/1 - 1s - loss: 0.1529 - val_loss: 0.1930 - 1s/epoch - 1s/step\n",
            "Epoch 1219/3000\n",
            "1/1 - 1s - loss: 0.1883 - val_loss: 0.1611 - 1s/epoch - 1s/step\n",
            "Epoch 1220/3000\n",
            "1/1 - 1s - loss: 0.1776 - val_loss: 0.2185 - 1s/epoch - 1s/step\n",
            "Epoch 1221/3000\n",
            "1/1 - 1s - loss: 0.2095 - val_loss: 0.1529 - 1s/epoch - 1s/step\n",
            "Epoch 1222/3000\n",
            "1/1 - 1s - loss: 0.1677 - val_loss: 0.1435 - 1s/epoch - 1s/step\n",
            "Epoch 1223/3000\n",
            "1/1 - 1s - loss: 0.1413 - val_loss: 0.1129 - 1s/epoch - 1s/step\n",
            "Epoch 1224/3000\n",
            "1/1 - 1s - loss: 0.1183 - val_loss: 0.1173 - 1s/epoch - 1s/step\n",
            "Epoch 1225/3000\n",
            "1/1 - 1s - loss: 0.1249 - val_loss: 0.1503 - 1s/epoch - 1s/step\n",
            "Epoch 1226/3000\n",
            "1/1 - 1s - loss: 0.1491 - val_loss: 0.1400 - 1s/epoch - 1s/step\n",
            "Epoch 1227/3000\n",
            "1/1 - 1s - loss: 0.1539 - val_loss: 0.1600 - 1s/epoch - 1s/step\n",
            "Epoch 1228/3000\n",
            "1/1 - 1s - loss: 0.1556 - val_loss: 0.1185 - 1s/epoch - 1s/step\n",
            "Epoch 1229/3000\n",
            "1/1 - 1s - loss: 0.1305 - val_loss: 0.1098 - 1s/epoch - 1s/step\n",
            "Epoch 1230/3000\n",
            "1/1 - 1s - loss: 0.1149 - val_loss: 0.1111 - 1s/epoch - 1s/step\n",
            "Epoch 1231/3000\n",
            "1/1 - 1s - loss: 0.1168 - val_loss: 0.1187 - 1s/epoch - 1s/step\n",
            "Epoch 1232/3000\n",
            "1/1 - 1s - loss: 0.1299 - val_loss: 0.1608 - 1s/epoch - 1s/step\n",
            "Epoch 1233/3000\n",
            "1/1 - 1s - loss: 0.1610 - val_loss: 0.1560 - 1s/epoch - 1s/step\n",
            "Epoch 1234/3000\n",
            "1/1 - 1s - loss: 0.1751 - val_loss: 0.2494 - 1s/epoch - 1s/step\n",
            "Epoch 1235/3000\n",
            "1/1 - 1s - loss: 0.2384 - val_loss: 0.1819 - 1s/epoch - 1s/step\n",
            "Epoch 1236/3000\n",
            "1/1 - 1s - loss: 0.2037 - val_loss: 0.2387 - 1s/epoch - 1s/step\n",
            "Epoch 1237/3000\n",
            "1/1 - 1s - loss: 0.2294 - val_loss: 0.1525 - 1s/epoch - 1s/step\n",
            "Epoch 1238/3000\n",
            "1/1 - 1s - loss: 0.1665 - val_loss: 0.1369 - 1s/epoch - 1s/step\n",
            "Epoch 1239/3000\n",
            "1/1 - 1s - loss: 0.1370 - val_loss: 0.1102 - 1s/epoch - 1s/step\n",
            "Epoch 1240/3000\n",
            "1/1 - 1s - loss: 0.1153 - val_loss: 0.1162 - 1s/epoch - 1s/step\n",
            "Epoch 1241/3000\n",
            "1/1 - 1s - loss: 0.1234 - val_loss: 0.1486 - 1s/epoch - 1s/step\n",
            "Epoch 1242/3000\n",
            "1/1 - 1s - loss: 0.1463 - val_loss: 0.1343 - 1s/epoch - 1s/step\n",
            "Epoch 1243/3000\n",
            "1/1 - 1s - loss: 0.1463 - val_loss: 0.1385 - 1s/epoch - 1s/step\n",
            "Epoch 1244/3000\n",
            "1/1 - 1s - loss: 0.1366 - val_loss: 0.1085 - 1s/epoch - 1s/step\n",
            "Epoch 1245/3000\n",
            "1/1 - 1s - loss: 0.1165 - val_loss: 0.1047 - 1s/epoch - 1s/step\n",
            "Epoch 1246/3000\n",
            "1/1 - 1s - loss: 0.1120 - val_loss: 0.1189 - 1s/epoch - 1s/step\n",
            "Epoch 1247/3000\n",
            "1/1 - 1s - loss: 0.1231 - val_loss: 0.1250 - 1s/epoch - 1s/step\n",
            "Epoch 1248/3000\n",
            "1/1 - 1s - loss: 0.1373 - val_loss: 0.1765 - 1s/epoch - 1s/step\n",
            "Epoch 1249/3000\n",
            "1/1 - 1s - loss: 0.1756 - val_loss: 0.1635 - 1s/epoch - 1s/step\n",
            "Epoch 1250/3000\n",
            "1/1 - 1s - loss: 0.1829 - val_loss: 0.2670 - 1s/epoch - 1s/step\n",
            "Epoch 1251/3000\n",
            "1/1 - 1s - loss: 0.2565 - val_loss: 0.1962 - 1s/epoch - 1s/step\n",
            "Epoch 1252/3000\n",
            "1/1 - 1s - loss: 0.2172 - val_loss: 0.2807 - 1s/epoch - 1s/step\n",
            "Epoch 1253/3000\n",
            "1/1 - 1s - loss: 0.2687 - val_loss: 0.1689 - 1s/epoch - 1s/step\n",
            "Epoch 1254/3000\n",
            "1/1 - 1s - loss: 0.1840 - val_loss: 0.1379 - 1s/epoch - 1s/step\n",
            "Epoch 1255/3000\n",
            "1/1 - 1s - loss: 0.1359 - val_loss: 0.1105 - 1s/epoch - 1s/step\n",
            "Epoch 1256/3000\n",
            "1/1 - 1s - loss: 0.1134 - val_loss: 0.1315 - 1s/epoch - 1s/step\n",
            "Epoch 1257/3000\n",
            "1/1 - 1s - loss: 0.1400 - val_loss: 0.1871 - 1s/epoch - 1s/step\n",
            "Epoch 1258/3000\n",
            "1/1 - 1s - loss: 0.1812 - val_loss: 0.1472 - 1s/epoch - 1s/step\n",
            "Epoch 1259/3000\n",
            "1/1 - 1s - loss: 0.1607 - val_loss: 0.1334 - 1s/epoch - 1s/step\n",
            "Epoch 1260/3000\n",
            "1/1 - 1s - loss: 0.1303 - val_loss: 0.1074 - 1s/epoch - 1s/step\n",
            "Epoch 1261/3000\n",
            "1/1 - 1s - loss: 0.1114 - val_loss: 0.1180 - 1s/epoch - 1s/step\n",
            "Epoch 1262/3000\n",
            "1/1 - 1s - loss: 0.1284 - val_loss: 0.1630 - 1s/epoch - 1s/step\n",
            "Epoch 1263/3000\n",
            "1/1 - 1s - loss: 0.1647 - val_loss: 0.1532 - 1s/epoch - 1s/step\n",
            "Epoch 1264/3000\n",
            "1/1 - 1s - loss: 0.1681 - val_loss: 0.2201 - 1s/epoch - 1s/step\n",
            "Epoch 1265/3000\n",
            "1/1 - 1s - loss: 0.2129 - val_loss: 0.1546 - 1s/epoch - 1s/step\n",
            "Epoch 1266/3000\n",
            "1/1 - 1s - loss: 0.1762 - val_loss: 0.1473 - 1s/epoch - 1s/step\n",
            "Epoch 1267/3000\n",
            "1/1 - 1s - loss: 0.1458 - val_loss: 0.1016 - 1s/epoch - 1s/step\n",
            "Epoch 1268/3000\n",
            "1/1 - 1s - loss: 0.1106 - val_loss: 0.1037 - 1s/epoch - 1s/step\n",
            "Epoch 1269/3000\n",
            "1/1 - 1s - loss: 0.1135 - val_loss: 0.1349 - 1s/epoch - 1s/step\n",
            "Epoch 1270/3000\n",
            "1/1 - 1s - loss: 0.1410 - val_loss: 0.1521 - 1s/epoch - 1s/step\n",
            "Epoch 1271/3000\n",
            "1/1 - 1s - loss: 0.1680 - val_loss: 0.2773 - 1s/epoch - 1s/step\n",
            "Epoch 1272/3000\n",
            "1/1 - 1s - loss: 0.2618 - val_loss: 0.1827 - 1s/epoch - 1s/step\n",
            "Epoch 1273/3000\n",
            "1/1 - 1s - loss: 0.2108 - val_loss: 0.1662 - 1s/epoch - 1s/step\n",
            "Epoch 1274/3000\n",
            "1/1 - 1s - loss: 0.1593 - val_loss: 0.1030 - 1s/epoch - 1s/step\n",
            "Epoch 1275/3000\n",
            "1/1 - 1s - loss: 0.1094 - val_loss: 0.1227 - 1s/epoch - 1s/step\n",
            "Epoch 1276/3000\n",
            "1/1 - 1s - loss: 0.1319 - val_loss: 0.2002 - 1s/epoch - 1s/step\n",
            "Epoch 1277/3000\n",
            "1/1 - 1s - loss: 0.2006 - val_loss: 0.1924 - 1s/epoch - 1s/step\n",
            "Epoch 1278/3000\n",
            "1/1 - 1s - loss: 0.2121 - val_loss: 0.2610 - 1s/epoch - 1s/step\n",
            "Epoch 1279/3000\n",
            "1/1 - 1s - loss: 0.2388 - val_loss: 0.1267 - 1s/epoch - 1s/step\n",
            "Epoch 1280/3000\n",
            "1/1 - 1s - loss: 0.1393 - val_loss: 0.1110 - 1s/epoch - 1s/step\n",
            "Epoch 1281/3000\n",
            "1/1 - 1s - loss: 0.1182 - val_loss: 0.1936 - 1s/epoch - 1s/step\n",
            "Epoch 1282/3000\n",
            "1/1 - 1s - loss: 0.2008 - val_loss: 0.2444 - 1s/epoch - 1s/step\n",
            "Epoch 1283/3000\n",
            "1/1 - 1s - loss: 0.2580 - val_loss: 0.7197 - 1s/epoch - 1s/step\n",
            "Epoch 1284/3000\n",
            "1/1 - 1s - loss: 0.6750 - val_loss: 0.3045 - 1s/epoch - 1s/step\n",
            "Epoch 1285/3000\n",
            "1/1 - 1s - loss: 0.3732 - val_loss: 0.1567 - 1s/epoch - 1s/step\n",
            "Epoch 1286/3000\n",
            "1/1 - 1s - loss: 0.1672 - val_loss: 0.3613 - 1s/epoch - 1s/step\n",
            "Epoch 1287/3000\n",
            "1/1 - 1s - loss: 0.3502 - val_loss: 0.3985 - 1s/epoch - 1s/step\n",
            "Epoch 1288/3000\n",
            "1/1 - 1s - loss: 0.4173 - val_loss: 0.8443 - 1s/epoch - 1s/step\n",
            "Epoch 1289/3000\n",
            "1/1 - 1s - loss: 0.8288 - val_loss: 0.2369 - 1s/epoch - 1s/step\n",
            "Epoch 1290/3000\n",
            "1/1 - 1s - loss: 0.2717 - val_loss: 0.3522 - 1s/epoch - 1s/step\n",
            "Epoch 1291/3000\n",
            "1/1 - 1s - loss: 0.4219 - val_loss: 0.7524 - 1s/epoch - 1s/step\n",
            "Epoch 1292/3000\n",
            "1/1 - 1s - loss: 0.6885 - val_loss: 0.1495 - 1s/epoch - 1s/step\n",
            "Epoch 1293/3000\n",
            "1/1 - 1s - loss: 0.1533 - val_loss: 0.6057 - 1s/epoch - 1s/step\n",
            "Epoch 1294/3000\n",
            "1/1 - 1s - loss: 0.6432 - val_loss: 1.6965 - 1s/epoch - 1s/step\n",
            "Epoch 1295/3000\n",
            "1/1 - 1s - loss: 1.6922 - val_loss: 0.2263 - 1s/epoch - 1s/step\n",
            "Epoch 1296/3000\n",
            "1/1 - 1s - loss: 0.2302 - val_loss: 1.3257 - 1s/epoch - 1s/step\n",
            "Epoch 1297/3000\n",
            "1/1 - 1s - loss: 1.5275 - val_loss: 2.6214 - 1s/epoch - 1s/step\n",
            "Epoch 1298/3000\n",
            "1/1 - 1s - loss: 2.5135 - val_loss: 0.6431 - 1s/epoch - 1s/step\n",
            "Epoch 1299/3000\n",
            "1/1 - 1s - loss: 0.5509 - val_loss: 4.0723 - 1s/epoch - 1s/step\n",
            "Epoch 1300/3000\n",
            "1/1 - 1s - loss: 4.2679 - val_loss: 13.4925 - 1s/epoch - 1s/step\n",
            "Epoch 1301/3000\n",
            "1/1 - 1s - loss: 13.9204 - val_loss: 9.3181 - 1s/epoch - 1s/step\n",
            "Epoch 1302/3000\n",
            "1/1 - 1s - loss: 9.0225 - val_loss: 7.5644 - 1s/epoch - 1s/step\n",
            "Epoch 1303/3000\n",
            "1/1 - 1s - loss: 8.8343 - val_loss: 5.3178 - 1s/epoch - 1s/step\n",
            "Epoch 1304/3000\n",
            "1/1 - 1s - loss: 5.7321 - val_loss: 6.0436 - 1s/epoch - 1s/step\n",
            "Epoch 1305/3000\n",
            "1/1 - 1s - loss: 6.1702 - val_loss: 4.4489 - 1s/epoch - 1s/step\n",
            "Epoch 1306/3000\n",
            "1/1 - 1s - loss: 5.4921 - val_loss: 5.7568 - 1s/epoch - 1s/step\n",
            "Epoch 1307/3000\n",
            "1/1 - 1s - loss: 6.2050 - val_loss: 4.1840 - 1s/epoch - 1s/step\n",
            "Epoch 1308/3000\n",
            "1/1 - 1s - loss: 4.4683 - val_loss: 4.0354 - 1s/epoch - 1s/step\n",
            "Epoch 1309/3000\n",
            "1/1 - 1s - loss: 4.5102 - val_loss: 3.7680 - 1s/epoch - 1s/step\n",
            "Epoch 1310/3000\n",
            "1/1 - 1s - loss: 3.8658 - val_loss: 2.9231 - 1s/epoch - 1s/step\n",
            "Epoch 1311/3000\n",
            "1/1 - 1s - loss: 2.7746 - val_loss: 4.9718 - 1s/epoch - 1s/step\n",
            "Epoch 1312/3000\n",
            "1/1 - 1s - loss: 4.9904 - val_loss: 2.1661 - 1s/epoch - 1s/step\n",
            "Epoch 1313/3000\n",
            "1/1 - 1s - loss: 1.9245 - val_loss: 3.8626 - 1s/epoch - 1s/step\n",
            "Epoch 1314/3000\n",
            "1/1 - 1s - loss: 3.8100 - val_loss: 1.1907 - 1s/epoch - 1s/step\n",
            "Epoch 1315/3000\n",
            "1/1 - 1s - loss: 1.1965 - val_loss: 3.3255 - 1s/epoch - 1s/step\n",
            "Epoch 1316/3000\n",
            "1/1 - 1s - loss: 3.3370 - val_loss: 1.6019 - 1s/epoch - 1s/step\n",
            "Epoch 1317/3000\n",
            "1/1 - 1s - loss: 1.8474 - val_loss: 2.2057 - 1s/epoch - 1s/step\n",
            "Epoch 1318/3000\n",
            "1/1 - 1s - loss: 2.4962 - val_loss: 0.9104 - 1s/epoch - 1s/step\n",
            "Epoch 1319/3000\n",
            "1/1 - 1s - loss: 0.9737 - val_loss: 2.3554 - 1s/epoch - 1s/step\n",
            "Epoch 1320/3000\n",
            "1/1 - 1s - loss: 2.4787 - val_loss: 0.6900 - 1s/epoch - 1s/step\n",
            "Epoch 1321/3000\n",
            "1/1 - 1s - loss: 0.8311 - val_loss: 2.0199 - 1s/epoch - 1s/step\n",
            "Epoch 1322/3000\n",
            "1/1 - 1s - loss: 2.0114 - val_loss: 1.2346 - 1s/epoch - 1s/step\n",
            "Epoch 1323/3000\n",
            "1/1 - 1s - loss: 1.2720 - val_loss: 0.7242 - 1s/epoch - 1s/step\n",
            "Epoch 1324/3000\n",
            "1/1 - 1s - loss: 0.8437 - val_loss: 1.3094 - 1s/epoch - 1s/step\n",
            "Epoch 1325/3000\n",
            "1/1 - 1s - loss: 1.2896 - val_loss: 0.8435 - 1s/epoch - 1s/step\n",
            "Epoch 1326/3000\n",
            "1/1 - 1s - loss: 0.8992 - val_loss: 1.1864 - 1s/epoch - 1s/step\n",
            "Epoch 1327/3000\n",
            "1/1 - 1s - loss: 1.2906 - val_loss: 0.6756 - 1s/epoch - 1s/step\n",
            "Epoch 1328/3000\n",
            "1/1 - 1s - loss: 0.6913 - val_loss: 1.0497 - 1s/epoch - 1s/step\n",
            "Epoch 1329/3000\n",
            "1/1 - 1s - loss: 1.0090 - val_loss: 0.7174 - 1s/epoch - 1s/step\n",
            "Epoch 1330/3000\n",
            "1/1 - 1s - loss: 0.7092 - val_loss: 1.0790 - 1s/epoch - 1s/step\n",
            "Epoch 1331/3000\n",
            "1/1 - 1s - loss: 1.0668 - val_loss: 0.4926 - 1s/epoch - 1s/step\n",
            "Epoch 1332/3000\n",
            "1/1 - 1s - loss: 0.5322 - val_loss: 1.0080 - 1s/epoch - 1s/step\n",
            "Epoch 1333/3000\n",
            "1/1 - 1s - loss: 1.0590 - val_loss: 0.3024 - 1s/epoch - 1s/step\n",
            "Epoch 1334/3000\n",
            "1/1 - 1s - loss: 0.3282 - val_loss: 0.7405 - 1s/epoch - 1s/step\n",
            "Epoch 1335/3000\n",
            "1/1 - 1s - loss: 0.8359 - val_loss: 0.3661 - 1s/epoch - 1s/step\n",
            "Epoch 1336/3000\n",
            "1/1 - 1s - loss: 0.4274 - val_loss: 0.7820 - 1s/epoch - 1s/step\n",
            "Epoch 1337/3000\n",
            "1/1 - 1s - loss: 0.7573 - val_loss: 0.3477 - 1s/epoch - 1s/step\n",
            "Epoch 1338/3000\n",
            "1/1 - 1s - loss: 0.4162 - val_loss: 0.5081 - 1s/epoch - 1s/step\n",
            "Epoch 1339/3000\n",
            "1/1 - 1s - loss: 0.5676 - val_loss: 0.3505 - 1s/epoch - 1s/step\n",
            "Epoch 1340/3000\n",
            "1/1 - 1s - loss: 0.3801 - val_loss: 0.5755 - 1s/epoch - 1s/step\n",
            "Epoch 1341/3000\n",
            "1/1 - 1s - loss: 0.6064 - val_loss: 0.2466 - 1s/epoch - 1s/step\n",
            "Epoch 1342/3000\n",
            "1/1 - 1s - loss: 0.2841 - val_loss: 0.3471 - 1s/epoch - 1s/step\n",
            "Epoch 1343/3000\n",
            "1/1 - 1s - loss: 0.4508 - val_loss: 0.2027 - 1s/epoch - 1s/step\n",
            "Epoch 1344/3000\n",
            "1/1 - 1s - loss: 0.3168 - val_loss: 0.4417 - 1s/epoch - 1s/step\n",
            "Epoch 1345/3000\n",
            "1/1 - 1s - loss: 0.4718 - val_loss: 0.1920 - 1s/epoch - 1s/step\n",
            "Epoch 1346/3000\n",
            "1/1 - 1s - loss: 0.2718 - val_loss: 0.2675 - 1s/epoch - 1s/step\n",
            "Epoch 1347/3000\n",
            "1/1 - 1s - loss: 0.3317 - val_loss: 0.2513 - 1s/epoch - 1s/step\n",
            "Epoch 1348/3000\n",
            "1/1 - 1s - loss: 0.2734 - val_loss: 0.3532 - 1s/epoch - 1s/step\n",
            "Epoch 1349/3000\n",
            "1/1 - 1s - loss: 0.3650 - val_loss: 0.2156 - 1s/epoch - 1s/step\n",
            "Epoch 1350/3000\n",
            "1/1 - 1s - loss: 0.2392 - val_loss: 0.2377 - 1s/epoch - 1s/step\n",
            "Epoch 1351/3000\n",
            "1/1 - 1s - loss: 0.2960 - val_loss: 0.1642 - 1s/epoch - 1s/step\n",
            "Epoch 1352/3000\n",
            "1/1 - 1s - loss: 0.2195 - val_loss: 0.2750 - 1s/epoch - 1s/step\n",
            "Epoch 1353/3000\n",
            "1/1 - 1s - loss: 0.3065 - val_loss: 0.1659 - 1s/epoch - 1s/step\n",
            "Epoch 1354/3000\n",
            "1/1 - 1s - loss: 0.2352 - val_loss: 0.1852 - 1s/epoch - 1s/step\n",
            "Epoch 1355/3000\n",
            "1/1 - 1s - loss: 0.2418 - val_loss: 0.1885 - 1s/epoch - 1s/step\n",
            "Epoch 1356/3000\n",
            "1/1 - 1s - loss: 0.2123 - val_loss: 0.2278 - 1s/epoch - 1s/step\n",
            "Epoch 1357/3000\n",
            "1/1 - 1s - loss: 0.2490 - val_loss: 0.1716 - 1s/epoch - 1s/step\n",
            "Epoch 1358/3000\n",
            "1/1 - 1s - loss: 0.2050 - val_loss: 0.1804 - 1s/epoch - 1s/step\n",
            "Epoch 1359/3000\n",
            "1/1 - 1s - loss: 0.2247 - val_loss: 0.1538 - 1s/epoch - 1s/step\n",
            "Epoch 1360/3000\n",
            "1/1 - 1s - loss: 0.1863 - val_loss: 0.1939 - 1s/epoch - 1s/step\n",
            "Epoch 1361/3000\n",
            "1/1 - 1s - loss: 0.2185 - val_loss: 0.1592 - 1s/epoch - 1s/step\n",
            "Epoch 1362/3000\n",
            "1/1 - 1s - loss: 0.2092 - val_loss: 0.1457 - 1s/epoch - 1s/step\n",
            "Epoch 1363/3000\n",
            "1/1 - 1s - loss: 0.1867 - val_loss: 0.1778 - 1s/epoch - 1s/step\n",
            "Epoch 1364/3000\n",
            "1/1 - 1s - loss: 0.2011 - val_loss: 0.1531 - 1s/epoch - 1s/step\n",
            "Epoch 1365/3000\n",
            "1/1 - 1s - loss: 0.1788 - val_loss: 0.1625 - 1s/epoch - 1s/step\n",
            "Epoch 1366/3000\n",
            "1/1 - 1s - loss: 0.1937 - val_loss: 0.1403 - 1s/epoch - 1s/step\n",
            "Epoch 1367/3000\n",
            "1/1 - 1s - loss: 0.1695 - val_loss: 0.1662 - 1s/epoch - 1s/step\n",
            "Epoch 1368/3000\n",
            "1/1 - 1s - loss: 0.1858 - val_loss: 0.1319 - 1s/epoch - 1s/step\n",
            "Epoch 1369/3000\n",
            "1/1 - 1s - loss: 0.1633 - val_loss: 0.1397 - 1s/epoch - 1s/step\n",
            "Epoch 1370/3000\n",
            "1/1 - 1s - loss: 0.1770 - val_loss: 0.1320 - 1s/epoch - 1s/step\n",
            "Epoch 1371/3000\n",
            "1/1 - 1s - loss: 0.1571 - val_loss: 0.1489 - 1s/epoch - 1s/step\n",
            "Epoch 1372/3000\n",
            "1/1 - 1s - loss: 0.1690 - val_loss: 0.1312 - 1s/epoch - 1s/step\n",
            "Epoch 1373/3000\n",
            "1/1 - 1s - loss: 0.1575 - val_loss: 0.1352 - 1s/epoch - 1s/step\n",
            "Epoch 1374/3000\n",
            "1/1 - 1s - loss: 0.1625 - val_loss: 0.1306 - 1s/epoch - 1s/step\n",
            "Epoch 1375/3000\n",
            "1/1 - 1s - loss: 0.1541 - val_loss: 0.1309 - 1s/epoch - 1s/step\n",
            "Epoch 1376/3000\n",
            "1/1 - 1s - loss: 0.1537 - val_loss: 0.1264 - 1s/epoch - 1s/step\n",
            "Epoch 1377/3000\n",
            "1/1 - 1s - loss: 0.1552 - val_loss: 0.1209 - 1s/epoch - 1s/step\n",
            "Epoch 1378/3000\n",
            "1/1 - 1s - loss: 0.1484 - val_loss: 0.1309 - 1s/epoch - 1s/step\n",
            "Epoch 1379/3000\n",
            "1/1 - 1s - loss: 0.1529 - val_loss: 0.1203 - 1s/epoch - 1s/step\n",
            "Epoch 1380/3000\n",
            "1/1 - 1s - loss: 0.1433 - val_loss: 0.1256 - 1s/epoch - 1s/step\n",
            "Epoch 1381/3000\n",
            "1/1 - 1s - loss: 0.1485 - val_loss: 0.1212 - 1s/epoch - 1s/step\n",
            "Epoch 1382/3000\n",
            "1/1 - 1s - loss: 0.1419 - val_loss: 0.1251 - 1s/epoch - 1s/step\n",
            "Epoch 1383/3000\n",
            "1/1 - 1s - loss: 0.1446 - val_loss: 0.1177 - 1s/epoch - 1s/step\n",
            "Epoch 1384/3000\n",
            "1/1 - 1s - loss: 0.1396 - val_loss: 0.1181 - 1s/epoch - 1s/step\n",
            "Epoch 1385/3000\n",
            "1/1 - 1s - loss: 0.1407 - val_loss: 0.1196 - 1s/epoch - 1s/step\n",
            "Epoch 1386/3000\n",
            "1/1 - 1s - loss: 0.1389 - val_loss: 0.1174 - 1s/epoch - 1s/step\n",
            "Epoch 1387/3000\n",
            "1/1 - 1s - loss: 0.1363 - val_loss: 0.1169 - 1s/epoch - 1s/step\n",
            "Epoch 1388/3000\n",
            "1/1 - 1s - loss: 0.1370 - val_loss: 0.1147 - 1s/epoch - 1s/step\n",
            "Epoch 1389/3000\n",
            "1/1 - 1s - loss: 0.1340 - val_loss: 0.1168 - 1s/epoch - 1s/step\n",
            "Epoch 1390/3000\n",
            "1/1 - 1s - loss: 0.1354 - val_loss: 0.1130 - 1s/epoch - 1s/step\n",
            "Epoch 1391/3000\n",
            "1/1 - 1s - loss: 0.1319 - val_loss: 0.1132 - 1s/epoch - 1s/step\n",
            "Epoch 1392/3000\n",
            "1/1 - 1s - loss: 0.1325 - val_loss: 0.1127 - 1s/epoch - 1s/step\n",
            "Epoch 1393/3000\n",
            "1/1 - 1s - loss: 0.1312 - val_loss: 0.1110 - 1s/epoch - 1s/step\n",
            "Epoch 1394/3000\n",
            "1/1 - 1s - loss: 0.1297 - val_loss: 0.1110 - 1s/epoch - 1s/step\n",
            "Epoch 1395/3000\n",
            "1/1 - 1s - loss: 0.1298 - val_loss: 0.1100 - 1s/epoch - 1s/step\n",
            "Epoch 1396/3000\n",
            "1/1 - 1s - loss: 0.1278 - val_loss: 0.1110 - 1s/epoch - 1s/step\n",
            "Epoch 1397/3000\n",
            "1/1 - 1s - loss: 0.1282 - val_loss: 0.1094 - 1s/epoch - 1s/step\n",
            "Epoch 1398/3000\n",
            "1/1 - 1s - loss: 0.1267 - val_loss: 0.1087 - 1s/epoch - 1s/step\n",
            "Epoch 1399/3000\n",
            "1/1 - 1s - loss: 0.1260 - val_loss: 0.1092 - 1s/epoch - 1s/step\n",
            "Epoch 1400/3000\n",
            "1/1 - 1s - loss: 0.1258 - val_loss: 0.1079 - 1s/epoch - 1s/step\n",
            "Epoch 1401/3000\n",
            "1/1 - 1s - loss: 0.1243 - val_loss: 0.1081 - 1s/epoch - 1s/step\n",
            "Epoch 1402/3000\n",
            "1/1 - 1s - loss: 0.1243 - val_loss: 0.1075 - 1s/epoch - 1s/step\n",
            "Epoch 1403/3000\n",
            "1/1 - 1s - loss: 0.1232 - val_loss: 0.1070 - 1s/epoch - 1s/step\n",
            "Epoch 1404/3000\n",
            "1/1 - 1s - loss: 0.1226 - val_loss: 0.1069 - 1s/epoch - 1s/step\n",
            "Epoch 1405/3000\n",
            "1/1 - 1s - loss: 0.1223 - val_loss: 0.1061 - 1s/epoch - 1s/step\n",
            "Epoch 1406/3000\n",
            "1/1 - 1s - loss: 0.1212 - val_loss: 0.1061 - 1s/epoch - 1s/step\n",
            "Epoch 1407/3000\n",
            "1/1 - 1s - loss: 0.1211 - val_loss: 0.1052 - 1s/epoch - 1s/step\n",
            "Epoch 1408/3000\n",
            "1/1 - 1s - loss: 0.1203 - val_loss: 0.1047 - 1s/epoch - 1s/step\n",
            "Epoch 1409/3000\n",
            "1/1 - 1s - loss: 0.1197 - val_loss: 0.1046 - 1s/epoch - 1s/step\n",
            "Epoch 1410/3000\n",
            "1/1 - 1s - loss: 0.1194 - val_loss: 0.1041 - 1s/epoch - 1s/step\n",
            "Epoch 1411/3000\n",
            "1/1 - 1s - loss: 0.1185 - val_loss: 0.1039 - 1s/epoch - 1s/step\n",
            "Epoch 1412/3000\n",
            "1/1 - 1s - loss: 0.1182 - val_loss: 0.1033 - 1s/epoch - 1s/step\n",
            "Epoch 1413/3000\n",
            "1/1 - 1s - loss: 0.1176 - val_loss: 0.1028 - 1s/epoch - 1s/step\n",
            "Epoch 1414/3000\n",
            "1/1 - 1s - loss: 0.1170 - val_loss: 0.1027 - 1s/epoch - 1s/step\n",
            "Epoch 1415/3000\n",
            "1/1 - 1s - loss: 0.1167 - val_loss: 0.1023 - 1s/epoch - 1s/step\n",
            "Epoch 1416/3000\n",
            "1/1 - 1s - loss: 0.1161 - val_loss: 0.1020 - 1s/epoch - 1s/step\n",
            "Epoch 1417/3000\n",
            "1/1 - 1s - loss: 0.1156 - val_loss: 0.1017 - 1s/epoch - 1s/step\n",
            "Epoch 1418/3000\n",
            "1/1 - 1s - loss: 0.1152 - val_loss: 0.1013 - 1s/epoch - 1s/step\n",
            "Epoch 1419/3000\n",
            "1/1 - 1s - loss: 0.1146 - val_loss: 0.1010 - 1s/epoch - 1s/step\n",
            "Epoch 1420/3000\n",
            "1/1 - 1s - loss: 0.1143 - val_loss: 0.1007 - 1s/epoch - 1s/step\n",
            "Epoch 1421/3000\n",
            "1/1 - 1s - loss: 0.1138 - val_loss: 0.1003 - 1s/epoch - 1s/step\n",
            "Epoch 1422/3000\n",
            "1/1 - 1s - loss: 0.1133 - val_loss: 0.0999 - 1s/epoch - 1s/step\n",
            "Epoch 1423/3000\n",
            "1/1 - 1s - loss: 0.1129 - val_loss: 0.0995 - 1s/epoch - 1s/step\n",
            "Epoch 1424/3000\n",
            "1/1 - 1s - loss: 0.1124 - val_loss: 0.0993 - 1s/epoch - 1s/step\n",
            "Epoch 1425/3000\n",
            "1/1 - 1s - loss: 0.1120 - val_loss: 0.0989 - 1s/epoch - 1s/step\n",
            "Epoch 1426/3000\n",
            "1/1 - 1s - loss: 0.1116 - val_loss: 0.0985 - 1s/epoch - 1s/step\n",
            "Epoch 1427/3000\n",
            "1/1 - 1s - loss: 0.1112 - val_loss: 0.0983 - 1s/epoch - 1s/step\n",
            "Epoch 1428/3000\n",
            "1/1 - 1s - loss: 0.1108 - val_loss: 0.0979 - 1s/epoch - 1s/step\n",
            "Epoch 1429/3000\n",
            "1/1 - 1s - loss: 0.1104 - val_loss: 0.0977 - 1s/epoch - 1s/step\n",
            "Epoch 1430/3000\n",
            "1/1 - 1s - loss: 0.1100 - val_loss: 0.0975 - 1s/epoch - 1s/step\n",
            "Epoch 1431/3000\n",
            "1/1 - 1s - loss: 0.1096 - val_loss: 0.0971 - 1s/epoch - 1s/step\n",
            "Epoch 1432/3000\n",
            "1/1 - 1s - loss: 0.1092 - val_loss: 0.0968 - 1s/epoch - 1s/step\n",
            "Epoch 1433/3000\n",
            "1/1 - 1s - loss: 0.1088 - val_loss: 0.0967 - 1s/epoch - 1s/step\n",
            "Epoch 1434/3000\n",
            "1/1 - 1s - loss: 0.1084 - val_loss: 0.0964 - 1s/epoch - 1s/step\n",
            "Epoch 1435/3000\n",
            "1/1 - 1s - loss: 0.1080 - val_loss: 0.0961 - 1s/epoch - 1s/step\n",
            "Epoch 1436/3000\n",
            "1/1 - 1s - loss: 0.1076 - val_loss: 0.0958 - 1s/epoch - 1s/step\n",
            "Epoch 1437/3000\n",
            "1/1 - 1s - loss: 0.1073 - val_loss: 0.0955 - 1s/epoch - 1s/step\n",
            "Epoch 1438/3000\n",
            "1/1 - 1s - loss: 0.1069 - val_loss: 0.0952 - 1s/epoch - 1s/step\n",
            "Epoch 1439/3000\n",
            "1/1 - 1s - loss: 0.1065 - val_loss: 0.0950 - 1s/epoch - 1s/step\n",
            "Epoch 1440/3000\n",
            "1/1 - 1s - loss: 0.1062 - val_loss: 0.0947 - 1s/epoch - 1s/step\n",
            "Epoch 1441/3000\n",
            "1/1 - 1s - loss: 0.1058 - val_loss: 0.0944 - 1s/epoch - 1s/step\n",
            "Epoch 1442/3000\n",
            "1/1 - 1s - loss: 0.1054 - val_loss: 0.0942 - 1s/epoch - 1s/step\n",
            "Epoch 1443/3000\n",
            "1/1 - 1s - loss: 0.1051 - val_loss: 0.0939 - 1s/epoch - 1s/step\n",
            "Epoch 1444/3000\n",
            "1/1 - 1s - loss: 0.1047 - val_loss: 0.0936 - 1s/epoch - 1s/step\n",
            "Epoch 1445/3000\n",
            "1/1 - 1s - loss: 0.1044 - val_loss: 0.0934 - 1s/epoch - 1s/step\n",
            "Epoch 1446/3000\n",
            "1/1 - 1s - loss: 0.1040 - val_loss: 0.0932 - 1s/epoch - 1s/step\n",
            "Epoch 1447/3000\n",
            "1/1 - 1s - loss: 0.1037 - val_loss: 0.0929 - 1s/epoch - 1s/step\n",
            "Epoch 1448/3000\n",
            "1/1 - 1s - loss: 0.1034 - val_loss: 0.0927 - 1s/epoch - 1s/step\n",
            "Epoch 1449/3000\n",
            "1/1 - 1s - loss: 0.1030 - val_loss: 0.0925 - 1s/epoch - 1s/step\n",
            "Epoch 1450/3000\n",
            "1/1 - 1s - loss: 0.1027 - val_loss: 0.0922 - 1s/epoch - 1s/step\n",
            "Epoch 1451/3000\n",
            "1/1 - 1s - loss: 0.1023 - val_loss: 0.0920 - 1s/epoch - 1s/step\n",
            "Epoch 1452/3000\n",
            "1/1 - 1s - loss: 0.1020 - val_loss: 0.0918 - 1s/epoch - 1s/step\n",
            "Epoch 1453/3000\n",
            "1/1 - 1s - loss: 0.1017 - val_loss: 0.0915 - 1s/epoch - 1s/step\n",
            "Epoch 1454/3000\n",
            "1/1 - 1s - loss: 0.1013 - val_loss: 0.0912 - 1s/epoch - 1s/step\n",
            "Epoch 1455/3000\n",
            "1/1 - 1s - loss: 0.1010 - val_loss: 0.0910 - 1s/epoch - 1s/step\n",
            "Epoch 1456/3000\n",
            "1/1 - 1s - loss: 0.1007 - val_loss: 0.0908 - 1s/epoch - 1s/step\n",
            "Epoch 1457/3000\n",
            "1/1 - 1s - loss: 0.1004 - val_loss: 0.0905 - 1s/epoch - 1s/step\n",
            "Epoch 1458/3000\n",
            "1/1 - 1s - loss: 0.1001 - val_loss: 0.0903 - 1s/epoch - 1s/step\n",
            "Epoch 1459/3000\n",
            "1/1 - 1s - loss: 0.0997 - val_loss: 0.0901 - 1s/epoch - 1s/step\n",
            "Epoch 1460/3000\n",
            "1/1 - 1s - loss: 0.0994 - val_loss: 0.0898 - 1s/epoch - 1s/step\n",
            "Epoch 1461/3000\n",
            "1/1 - 1s - loss: 0.0991 - val_loss: 0.0897 - 1s/epoch - 1s/step\n",
            "Epoch 1462/3000\n",
            "1/1 - 1s - loss: 0.0988 - val_loss: 0.0894 - 1s/epoch - 1s/step\n",
            "Epoch 1463/3000\n",
            "1/1 - 1s - loss: 0.0985 - val_loss: 0.0892 - 1s/epoch - 1s/step\n",
            "Epoch 1464/3000\n",
            "1/1 - 1s - loss: 0.0982 - val_loss: 0.0890 - 1s/epoch - 1s/step\n",
            "Epoch 1465/3000\n",
            "1/1 - 1s - loss: 0.0979 - val_loss: 0.0888 - 1s/epoch - 1s/step\n",
            "Epoch 1466/3000\n",
            "1/1 - 1s - loss: 0.0976 - val_loss: 0.0885 - 1s/epoch - 1s/step\n",
            "Epoch 1467/3000\n",
            "1/1 - 1s - loss: 0.0973 - val_loss: 0.0883 - 1s/epoch - 1s/step\n",
            "Epoch 1468/3000\n",
            "1/1 - 1s - loss: 0.0970 - val_loss: 0.0881 - 1s/epoch - 1s/step\n",
            "Epoch 1469/3000\n",
            "1/1 - 1s - loss: 0.0967 - val_loss: 0.0879 - 1s/epoch - 1s/step\n",
            "Epoch 1470/3000\n",
            "1/1 - 1s - loss: 0.0964 - val_loss: 0.0876 - 1s/epoch - 1s/step\n",
            "Epoch 1471/3000\n",
            "1/1 - 1s - loss: 0.0961 - val_loss: 0.0874 - 1s/epoch - 1s/step\n",
            "Epoch 1472/3000\n",
            "1/1 - 1s - loss: 0.0958 - val_loss: 0.0872 - 1s/epoch - 1s/step\n",
            "Epoch 1473/3000\n",
            "1/1 - 1s - loss: 0.0955 - val_loss: 0.0870 - 1s/epoch - 1s/step\n",
            "Epoch 1474/3000\n",
            "1/1 - 1s - loss: 0.0952 - val_loss: 0.0867 - 1s/epoch - 1s/step\n",
            "Epoch 1475/3000\n",
            "1/1 - 1s - loss: 0.0949 - val_loss: 0.0865 - 1s/epoch - 1s/step\n",
            "Epoch 1476/3000\n",
            "1/1 - 1s - loss: 0.0946 - val_loss: 0.0863 - 1s/epoch - 1s/step\n",
            "Epoch 1477/3000\n",
            "1/1 - 1s - loss: 0.0943 - val_loss: 0.0861 - 1s/epoch - 1s/step\n",
            "Epoch 1478/3000\n",
            "1/1 - 1s - loss: 0.0941 - val_loss: 0.0858 - 1s/epoch - 1s/step\n",
            "Epoch 1479/3000\n",
            "1/1 - 1s - loss: 0.0938 - val_loss: 0.0856 - 1s/epoch - 1s/step\n",
            "Epoch 1480/3000\n",
            "1/1 - 1s - loss: 0.0935 - val_loss: 0.0854 - 1s/epoch - 1s/step\n",
            "Epoch 1481/3000\n",
            "1/1 - 1s - loss: 0.0932 - val_loss: 0.0852 - 1s/epoch - 1s/step\n",
            "Epoch 1482/3000\n",
            "1/1 - 1s - loss: 0.0929 - val_loss: 0.0850 - 1s/epoch - 1s/step\n",
            "Epoch 1483/3000\n",
            "1/1 - 1s - loss: 0.0926 - val_loss: 0.0848 - 1s/epoch - 1s/step\n",
            "Epoch 1484/3000\n",
            "1/1 - 1s - loss: 0.0924 - val_loss: 0.0845 - 1s/epoch - 1s/step\n",
            "Epoch 1485/3000\n",
            "1/1 - 1s - loss: 0.0921 - val_loss: 0.0843 - 1s/epoch - 1s/step\n",
            "Epoch 1486/3000\n",
            "1/1 - 1s - loss: 0.0918 - val_loss: 0.0841 - 1s/epoch - 1s/step\n",
            "Epoch 1487/3000\n",
            "1/1 - 1s - loss: 0.0915 - val_loss: 0.0839 - 1s/epoch - 1s/step\n",
            "Epoch 1488/3000\n",
            "1/1 - 1s - loss: 0.0913 - val_loss: 0.0837 - 1s/epoch - 1s/step\n",
            "Epoch 1489/3000\n",
            "1/1 - 1s - loss: 0.0910 - val_loss: 0.0834 - 1s/epoch - 1s/step\n",
            "Epoch 1490/3000\n",
            "1/1 - 1s - loss: 0.0907 - val_loss: 0.0832 - 1s/epoch - 1s/step\n",
            "Epoch 1491/3000\n",
            "1/1 - 1s - loss: 0.0904 - val_loss: 0.0830 - 1s/epoch - 1s/step\n",
            "Epoch 1492/3000\n",
            "1/1 - 1s - loss: 0.0902 - val_loss: 0.0828 - 1s/epoch - 1s/step\n",
            "Epoch 1493/3000\n",
            "1/1 - 1s - loss: 0.0899 - val_loss: 0.0826 - 1s/epoch - 1s/step\n",
            "Epoch 1494/3000\n",
            "1/1 - 1s - loss: 0.0896 - val_loss: 0.0824 - 1s/epoch - 1s/step\n",
            "Epoch 1495/3000\n",
            "1/1 - 1s - loss: 0.0894 - val_loss: 0.0822 - 1s/epoch - 1s/step\n",
            "Epoch 1496/3000\n",
            "1/1 - 1s - loss: 0.0891 - val_loss: 0.0820 - 1s/epoch - 1s/step\n",
            "Epoch 1497/3000\n",
            "1/1 - 1s - loss: 0.0888 - val_loss: 0.0818 - 1s/epoch - 1s/step\n",
            "Epoch 1498/3000\n",
            "1/1 - 1s - loss: 0.0886 - val_loss: 0.0816 - 1s/epoch - 1s/step\n",
            "Epoch 1499/3000\n",
            "1/1 - 1s - loss: 0.0883 - val_loss: 0.0814 - 1s/epoch - 1s/step\n",
            "Epoch 1500/3000\n",
            "1/1 - 1s - loss: 0.0880 - val_loss: 0.0812 - 1s/epoch - 1s/step\n",
            "Epoch 1501/3000\n",
            "1/1 - 1s - loss: 0.0878 - val_loss: 0.0810 - 1s/epoch - 1s/step\n",
            "Epoch 1502/3000\n",
            "1/1 - 1s - loss: 0.0875 - val_loss: 0.0808 - 1s/epoch - 1s/step\n",
            "Epoch 1503/3000\n",
            "1/1 - 1s - loss: 0.0873 - val_loss: 0.0806 - 1s/epoch - 1s/step\n",
            "Epoch 1504/3000\n",
            "1/1 - 1s - loss: 0.0870 - val_loss: 0.0804 - 1s/epoch - 1s/step\n",
            "Epoch 1505/3000\n",
            "1/1 - 1s - loss: 0.0867 - val_loss: 0.0802 - 1s/epoch - 1s/step\n",
            "Epoch 1506/3000\n",
            "1/1 - 1s - loss: 0.0865 - val_loss: 0.0800 - 1s/epoch - 1s/step\n",
            "Epoch 1507/3000\n",
            "1/1 - 1s - loss: 0.0862 - val_loss: 0.0798 - 1s/epoch - 1s/step\n",
            "Epoch 1508/3000\n",
            "1/1 - 1s - loss: 0.0860 - val_loss: 0.0796 - 1s/epoch - 1s/step\n",
            "Epoch 1509/3000\n",
            "1/1 - 1s - loss: 0.0857 - val_loss: 0.0794 - 1s/epoch - 1s/step\n",
            "Epoch 1510/3000\n",
            "1/1 - 1s - loss: 0.0855 - val_loss: 0.0792 - 1s/epoch - 1s/step\n",
            "Epoch 1511/3000\n",
            "1/1 - 1s - loss: 0.0852 - val_loss: 0.0790 - 1s/epoch - 1s/step\n",
            "Epoch 1512/3000\n",
            "1/1 - 1s - loss: 0.0850 - val_loss: 0.0788 - 1s/epoch - 1s/step\n",
            "Epoch 1513/3000\n",
            "1/1 - 1s - loss: 0.0847 - val_loss: 0.0786 - 1s/epoch - 1s/step\n",
            "Epoch 1514/3000\n",
            "1/1 - 1s - loss: 0.0845 - val_loss: 0.0785 - 1s/epoch - 1s/step\n",
            "Epoch 1515/3000\n",
            "1/1 - 1s - loss: 0.0842 - val_loss: 0.0783 - 1s/epoch - 1s/step\n",
            "Epoch 1516/3000\n",
            "1/1 - 1s - loss: 0.0840 - val_loss: 0.0781 - 1s/epoch - 1s/step\n",
            "Epoch 1517/3000\n",
            "1/1 - 1s - loss: 0.0837 - val_loss: 0.0779 - 1s/epoch - 1s/step\n",
            "Epoch 1518/3000\n",
            "1/1 - 1s - loss: 0.0835 - val_loss: 0.0777 - 1s/epoch - 1s/step\n",
            "Epoch 1519/3000\n",
            "1/1 - 1s - loss: 0.0832 - val_loss: 0.0775 - 1s/epoch - 1s/step\n",
            "Epoch 1520/3000\n",
            "1/1 - 1s - loss: 0.0830 - val_loss: 0.0773 - 1s/epoch - 1s/step\n",
            "Epoch 1521/3000\n",
            "1/1 - 1s - loss: 0.0827 - val_loss: 0.0771 - 1s/epoch - 1s/step\n",
            "Epoch 1522/3000\n",
            "1/1 - 1s - loss: 0.0825 - val_loss: 0.0769 - 1s/epoch - 1s/step\n",
            "Epoch 1523/3000\n",
            "1/1 - 1s - loss: 0.0822 - val_loss: 0.0767 - 1s/epoch - 1s/step\n",
            "Epoch 1524/3000\n",
            "1/1 - 1s - loss: 0.0820 - val_loss: 0.0765 - 1s/epoch - 1s/step\n",
            "Epoch 1525/3000\n",
            "1/1 - 1s - loss: 0.0818 - val_loss: 0.0763 - 1s/epoch - 1s/step\n",
            "Epoch 1526/3000\n",
            "1/1 - 1s - loss: 0.0815 - val_loss: 0.0761 - 1s/epoch - 1s/step\n",
            "Epoch 1527/3000\n",
            "1/1 - 1s - loss: 0.0813 - val_loss: 0.0759 - 1s/epoch - 1s/step\n",
            "Epoch 1528/3000\n",
            "1/1 - 1s - loss: 0.0811 - val_loss: 0.0757 - 1s/epoch - 1s/step\n",
            "Epoch 1529/3000\n",
            "1/1 - 1s - loss: 0.0808 - val_loss: 0.0755 - 1s/epoch - 1s/step\n",
            "Epoch 1530/3000\n",
            "1/1 - 1s - loss: 0.0806 - val_loss: 0.0753 - 1s/epoch - 1s/step\n",
            "Epoch 1531/3000\n",
            "1/1 - 1s - loss: 0.0803 - val_loss: 0.0751 - 1s/epoch - 1s/step\n",
            "Epoch 1532/3000\n",
            "1/1 - 1s - loss: 0.0801 - val_loss: 0.0749 - 1s/epoch - 1s/step\n",
            "Epoch 1533/3000\n",
            "1/1 - 1s - loss: 0.0799 - val_loss: 0.0747 - 1s/epoch - 1s/step\n",
            "Epoch 1534/3000\n",
            "1/1 - 1s - loss: 0.0796 - val_loss: 0.0745 - 1s/epoch - 1s/step\n",
            "Epoch 1535/3000\n",
            "1/1 - 1s - loss: 0.0794 - val_loss: 0.0743 - 1s/epoch - 1s/step\n",
            "Epoch 1536/3000\n",
            "1/1 - 1s - loss: 0.0792 - val_loss: 0.0742 - 1s/epoch - 1s/step\n",
            "Epoch 1537/3000\n",
            "1/1 - 1s - loss: 0.0790 - val_loss: 0.0740 - 1s/epoch - 1s/step\n",
            "Epoch 1538/3000\n",
            "1/1 - 1s - loss: 0.0787 - val_loss: 0.0738 - 1s/epoch - 1s/step\n",
            "Epoch 1539/3000\n",
            "1/1 - 1s - loss: 0.0785 - val_loss: 0.0736 - 1s/epoch - 1s/step\n",
            "Epoch 1540/3000\n",
            "1/1 - 1s - loss: 0.0783 - val_loss: 0.0734 - 1s/epoch - 1s/step\n",
            "Epoch 1541/3000\n",
            "1/1 - 1s - loss: 0.0780 - val_loss: 0.0732 - 1s/epoch - 1s/step\n",
            "Epoch 1542/3000\n",
            "1/1 - 1s - loss: 0.0778 - val_loss: 0.0730 - 1s/epoch - 1s/step\n",
            "Epoch 1543/3000\n",
            "1/1 - 1s - loss: 0.0776 - val_loss: 0.0729 - 1s/epoch - 1s/step\n",
            "Epoch 1544/3000\n",
            "1/1 - 1s - loss: 0.0773 - val_loss: 0.0727 - 1s/epoch - 1s/step\n",
            "Epoch 1545/3000\n",
            "1/1 - 1s - loss: 0.0771 - val_loss: 0.0725 - 1s/epoch - 1s/step\n",
            "Epoch 1546/3000\n",
            "1/1 - 1s - loss: 0.0769 - val_loss: 0.0723 - 1s/epoch - 1s/step\n",
            "Epoch 1547/3000\n",
            "1/1 - 1s - loss: 0.0767 - val_loss: 0.0721 - 1s/epoch - 1s/step\n",
            "Epoch 1548/3000\n",
            "1/1 - 1s - loss: 0.0764 - val_loss: 0.0719 - 1s/epoch - 1s/step\n",
            "Epoch 1549/3000\n",
            "1/1 - 1s - loss: 0.0762 - val_loss: 0.0717 - 1s/epoch - 1s/step\n",
            "Epoch 1550/3000\n",
            "1/1 - 1s - loss: 0.0760 - val_loss: 0.0715 - 1s/epoch - 1s/step\n",
            "Epoch 1551/3000\n",
            "1/1 - 1s - loss: 0.0758 - val_loss: 0.0713 - 1s/epoch - 1s/step\n",
            "Epoch 1552/3000\n",
            "1/1 - 1s - loss: 0.0755 - val_loss: 0.0711 - 1s/epoch - 1s/step\n",
            "Epoch 1553/3000\n",
            "1/1 - 1s - loss: 0.0753 - val_loss: 0.0709 - 1s/epoch - 1s/step\n",
            "Epoch 1554/3000\n",
            "1/1 - 1s - loss: 0.0751 - val_loss: 0.0707 - 1s/epoch - 1s/step\n",
            "Epoch 1555/3000\n",
            "1/1 - 1s - loss: 0.0749 - val_loss: 0.0705 - 1s/epoch - 1s/step\n",
            "Epoch 1556/3000\n",
            "1/1 - 1s - loss: 0.0746 - val_loss: 0.0703 - 1s/epoch - 1s/step\n",
            "Epoch 1557/3000\n",
            "1/1 - 1s - loss: 0.0744 - val_loss: 0.0701 - 1s/epoch - 1s/step\n",
            "Epoch 1558/3000\n",
            "1/1 - 1s - loss: 0.0742 - val_loss: 0.0700 - 1s/epoch - 1s/step\n",
            "Epoch 1559/3000\n",
            "1/1 - 1s - loss: 0.0740 - val_loss: 0.0697 - 1s/epoch - 1s/step\n",
            "Epoch 1560/3000\n",
            "1/1 - 1s - loss: 0.0737 - val_loss: 0.0696 - 1s/epoch - 1s/step\n",
            "Epoch 1561/3000\n",
            "1/1 - 1s - loss: 0.0735 - val_loss: 0.0694 - 1s/epoch - 1s/step\n",
            "Epoch 1562/3000\n",
            "1/1 - 1s - loss: 0.0733 - val_loss: 0.0692 - 1s/epoch - 1s/step\n",
            "Epoch 1563/3000\n",
            "1/1 - 1s - loss: 0.0731 - val_loss: 0.0690 - 1s/epoch - 1s/step\n",
            "Epoch 1564/3000\n",
            "1/1 - 1s - loss: 0.0728 - val_loss: 0.0688 - 1s/epoch - 1s/step\n",
            "Epoch 1565/3000\n",
            "1/1 - 1s - loss: 0.0726 - val_loss: 0.0686 - 1s/epoch - 1s/step\n",
            "Epoch 1566/3000\n",
            "1/1 - 1s - loss: 0.0724 - val_loss: 0.0684 - 1s/epoch - 1s/step\n",
            "Epoch 1567/3000\n",
            "1/1 - 1s - loss: 0.0722 - val_loss: 0.0682 - 1s/epoch - 1s/step\n",
            "Epoch 1568/3000\n",
            "1/1 - 1s - loss: 0.0720 - val_loss: 0.0680 - 1s/epoch - 1s/step\n",
            "Epoch 1569/3000\n",
            "1/1 - 1s - loss: 0.0717 - val_loss: 0.0678 - 1s/epoch - 1s/step\n",
            "Epoch 1570/3000\n",
            "1/1 - 1s - loss: 0.0715 - val_loss: 0.0676 - 1s/epoch - 1s/step\n",
            "Epoch 1571/3000\n",
            "1/1 - 1s - loss: 0.0713 - val_loss: 0.0675 - 1s/epoch - 1s/step\n",
            "Epoch 1572/3000\n",
            "1/1 - 1s - loss: 0.0711 - val_loss: 0.0673 - 1s/epoch - 1s/step\n",
            "Epoch 1573/3000\n",
            "1/1 - 1s - loss: 0.0709 - val_loss: 0.0671 - 1s/epoch - 1s/step\n",
            "Epoch 1574/3000\n",
            "1/1 - 1s - loss: 0.0706 - val_loss: 0.0669 - 1s/epoch - 1s/step\n",
            "Epoch 1575/3000\n",
            "1/1 - 1s - loss: 0.0704 - val_loss: 0.0667 - 1s/epoch - 1s/step\n",
            "Epoch 1576/3000\n",
            "1/1 - 1s - loss: 0.0702 - val_loss: 0.0665 - 1s/epoch - 1s/step\n",
            "Epoch 1577/3000\n",
            "1/1 - 1s - loss: 0.0700 - val_loss: 0.0663 - 1s/epoch - 1s/step\n",
            "Epoch 1578/3000\n",
            "1/1 - 1s - loss: 0.0698 - val_loss: 0.0661 - 1s/epoch - 1s/step\n",
            "Epoch 1579/3000\n",
            "1/1 - 1s - loss: 0.0695 - val_loss: 0.0659 - 1s/epoch - 1s/step\n",
            "Epoch 1580/3000\n",
            "1/1 - 1s - loss: 0.0693 - val_loss: 0.0657 - 1s/epoch - 1s/step\n",
            "Epoch 1581/3000\n",
            "1/1 - 1s - loss: 0.0691 - val_loss: 0.0655 - 1s/epoch - 1s/step\n",
            "Epoch 1582/3000\n",
            "1/1 - 1s - loss: 0.0689 - val_loss: 0.0653 - 1s/epoch - 1s/step\n",
            "Epoch 1583/3000\n",
            "1/1 - 1s - loss: 0.0687 - val_loss: 0.0651 - 1s/epoch - 1s/step\n",
            "Epoch 1584/3000\n",
            "1/1 - 1s - loss: 0.0684 - val_loss: 0.0649 - 1s/epoch - 1s/step\n",
            "Epoch 1585/3000\n",
            "1/1 - 1s - loss: 0.0682 - val_loss: 0.0647 - 1s/epoch - 1s/step\n",
            "Epoch 1586/3000\n",
            "1/1 - 1s - loss: 0.0680 - val_loss: 0.0646 - 1s/epoch - 1s/step\n",
            "Epoch 1587/3000\n",
            "1/1 - 1s - loss: 0.0678 - val_loss: 0.0644 - 1s/epoch - 1s/step\n",
            "Epoch 1588/3000\n",
            "1/1 - 1s - loss: 0.0676 - val_loss: 0.0642 - 1s/epoch - 1s/step\n",
            "Epoch 1589/3000\n",
            "1/1 - 1s - loss: 0.0673 - val_loss: 0.0640 - 1s/epoch - 1s/step\n",
            "Epoch 1590/3000\n",
            "1/1 - 1s - loss: 0.0671 - val_loss: 0.0638 - 1s/epoch - 1s/step\n",
            "Epoch 1591/3000\n",
            "1/1 - 1s - loss: 0.0669 - val_loss: 0.0636 - 1s/epoch - 1s/step\n",
            "Epoch 1592/3000\n",
            "1/1 - 1s - loss: 0.0667 - val_loss: 0.0634 - 1s/epoch - 1s/step\n",
            "Epoch 1593/3000\n",
            "1/1 - 1s - loss: 0.0665 - val_loss: 0.0633 - 1s/epoch - 1s/step\n",
            "Epoch 1594/3000\n",
            "1/1 - 1s - loss: 0.0663 - val_loss: 0.0631 - 1s/epoch - 1s/step\n",
            "Epoch 1595/3000\n",
            "1/1 - 1s - loss: 0.0660 - val_loss: 0.0629 - 1s/epoch - 1s/step\n",
            "Epoch 1596/3000\n",
            "1/1 - 1s - loss: 0.0658 - val_loss: 0.0627 - 1s/epoch - 1s/step\n",
            "Epoch 1597/3000\n",
            "1/1 - 1s - loss: 0.0656 - val_loss: 0.0625 - 1s/epoch - 1s/step\n",
            "Epoch 1598/3000\n",
            "1/1 - 1s - loss: 0.0654 - val_loss: 0.0623 - 1s/epoch - 1s/step\n",
            "Epoch 1599/3000\n",
            "1/1 - 1s - loss: 0.0652 - val_loss: 0.0622 - 1s/epoch - 1s/step\n",
            "Epoch 1600/3000\n",
            "1/1 - 1s - loss: 0.0650 - val_loss: 0.0620 - 1s/epoch - 1s/step\n",
            "Epoch 1601/3000\n",
            "1/1 - 1s - loss: 0.0648 - val_loss: 0.0618 - 1s/epoch - 1s/step\n",
            "Epoch 1602/3000\n",
            "1/1 - 1s - loss: 0.0645 - val_loss: 0.0616 - 1s/epoch - 1s/step\n",
            "Epoch 1603/3000\n",
            "1/1 - 1s - loss: 0.0643 - val_loss: 0.0614 - 1s/epoch - 1s/step\n",
            "Epoch 1604/3000\n",
            "1/1 - 1s - loss: 0.0641 - val_loss: 0.0613 - 1s/epoch - 1s/step\n",
            "Epoch 1605/3000\n",
            "1/1 - 1s - loss: 0.0639 - val_loss: 0.0611 - 1s/epoch - 1s/step\n",
            "Epoch 1606/3000\n",
            "1/1 - 1s - loss: 0.0637 - val_loss: 0.0609 - 1s/epoch - 1s/step\n",
            "Epoch 1607/3000\n",
            "1/1 - 1s - loss: 0.0635 - val_loss: 0.0607 - 1s/epoch - 1s/step\n",
            "Epoch 1608/3000\n",
            "1/1 - 1s - loss: 0.0632 - val_loss: 0.0605 - 1s/epoch - 1s/step\n",
            "Epoch 1609/3000\n",
            "1/1 - 1s - loss: 0.0630 - val_loss: 0.0603 - 1s/epoch - 1s/step\n",
            "Epoch 1610/3000\n",
            "1/1 - 1s - loss: 0.0628 - val_loss: 0.0601 - 1s/epoch - 1s/step\n",
            "Epoch 1611/3000\n",
            "1/1 - 1s - loss: 0.0626 - val_loss: 0.0600 - 1s/epoch - 1s/step\n",
            "Epoch 1612/3000\n",
            "1/1 - 1s - loss: 0.0624 - val_loss: 0.0598 - 1s/epoch - 1s/step\n",
            "Epoch 1613/3000\n",
            "1/1 - 1s - loss: 0.0622 - val_loss: 0.0596 - 1s/epoch - 1s/step\n",
            "Epoch 1614/3000\n",
            "1/1 - 1s - loss: 0.0620 - val_loss: 0.0594 - 1s/epoch - 1s/step\n",
            "Epoch 1615/3000\n",
            "1/1 - 1s - loss: 0.0618 - val_loss: 0.0592 - 1s/epoch - 1s/step\n",
            "Epoch 1616/3000\n",
            "1/1 - 1s - loss: 0.0615 - val_loss: 0.0590 - 1s/epoch - 1s/step\n",
            "Epoch 1617/3000\n",
            "1/1 - 1s - loss: 0.0613 - val_loss: 0.0589 - 1s/epoch - 1s/step\n",
            "Epoch 1618/3000\n",
            "1/1 - 1s - loss: 0.0611 - val_loss: 0.0587 - 1s/epoch - 1s/step\n",
            "Epoch 1619/3000\n",
            "1/1 - 1s - loss: 0.0609 - val_loss: 0.0585 - 1s/epoch - 1s/step\n",
            "Epoch 1620/3000\n",
            "1/1 - 1s - loss: 0.0607 - val_loss: 0.0583 - 1s/epoch - 1s/step\n",
            "Epoch 1621/3000\n",
            "1/1 - 1s - loss: 0.0605 - val_loss: 0.0581 - 1s/epoch - 1s/step\n",
            "Epoch 1622/3000\n",
            "1/1 - 1s - loss: 0.0603 - val_loss: 0.0579 - 1s/epoch - 1s/step\n",
            "Epoch 1623/3000\n",
            "1/1 - 1s - loss: 0.0601 - val_loss: 0.0578 - 1s/epoch - 1s/step\n",
            "Epoch 1624/3000\n",
            "1/1 - 1s - loss: 0.0598 - val_loss: 0.0576 - 1s/epoch - 1s/step\n",
            "Epoch 1625/3000\n",
            "1/1 - 1s - loss: 0.0596 - val_loss: 0.0574 - 1s/epoch - 1s/step\n",
            "Epoch 1626/3000\n",
            "1/1 - 1s - loss: 0.0594 - val_loss: 0.0572 - 1s/epoch - 1s/step\n",
            "Epoch 1627/3000\n",
            "1/1 - 1s - loss: 0.0592 - val_loss: 0.0570 - 1s/epoch - 1s/step\n",
            "Epoch 1628/3000\n",
            "1/1 - 1s - loss: 0.0590 - val_loss: 0.0569 - 1s/epoch - 1s/step\n",
            "Epoch 1629/3000\n",
            "1/1 - 1s - loss: 0.0588 - val_loss: 0.0567 - 1s/epoch - 1s/step\n",
            "Epoch 1630/3000\n",
            "1/1 - 1s - loss: 0.0586 - val_loss: 0.0565 - 1s/epoch - 1s/step\n",
            "Epoch 1631/3000\n",
            "1/1 - 1s - loss: 0.0584 - val_loss: 0.0563 - 1s/epoch - 1s/step\n",
            "Epoch 1632/3000\n",
            "1/1 - 1s - loss: 0.0582 - val_loss: 0.0561 - 1s/epoch - 1s/step\n",
            "Epoch 1633/3000\n",
            "1/1 - 1s - loss: 0.0579 - val_loss: 0.0559 - 1s/epoch - 1s/step\n",
            "Epoch 1634/3000\n",
            "1/1 - 1s - loss: 0.0577 - val_loss: 0.0558 - 1s/epoch - 1s/step\n",
            "Epoch 1635/3000\n",
            "1/1 - 1s - loss: 0.0575 - val_loss: 0.0556 - 1s/epoch - 1s/step\n",
            "Epoch 1636/3000\n",
            "1/1 - 1s - loss: 0.0573 - val_loss: 0.0554 - 1s/epoch - 1s/step\n",
            "Epoch 1637/3000\n",
            "1/1 - 1s - loss: 0.0571 - val_loss: 0.0552 - 1s/epoch - 1s/step\n",
            "Epoch 1638/3000\n",
            "1/1 - 1s - loss: 0.0569 - val_loss: 0.0550 - 1s/epoch - 1s/step\n",
            "Epoch 1639/3000\n",
            "1/1 - 1s - loss: 0.0567 - val_loss: 0.0549 - 1s/epoch - 1s/step\n",
            "Epoch 1640/3000\n",
            "1/1 - 1s - loss: 0.0565 - val_loss: 0.0547 - 1s/epoch - 1s/step\n",
            "Epoch 1641/3000\n",
            "1/1 - 1s - loss: 0.0563 - val_loss: 0.0545 - 1s/epoch - 1s/step\n",
            "Epoch 1642/3000\n",
            "1/1 - 1s - loss: 0.0561 - val_loss: 0.0543 - 1s/epoch - 1s/step\n",
            "Epoch 1643/3000\n",
            "1/1 - 1s - loss: 0.0559 - val_loss: 0.0541 - 1s/epoch - 1s/step\n",
            "Epoch 1644/3000\n",
            "1/1 - 1s - loss: 0.0557 - val_loss: 0.0540 - 1s/epoch - 1s/step\n",
            "Epoch 1645/3000\n",
            "1/1 - 1s - loss: 0.0554 - val_loss: 0.0538 - 1s/epoch - 1s/step\n",
            "Epoch 1646/3000\n",
            "1/1 - 1s - loss: 0.0552 - val_loss: 0.0536 - 1s/epoch - 1s/step\n",
            "Epoch 1647/3000\n",
            "1/1 - 1s - loss: 0.0550 - val_loss: 0.0534 - 1s/epoch - 1s/step\n",
            "Epoch 1648/3000\n",
            "1/1 - 1s - loss: 0.0548 - val_loss: 0.0532 - 1s/epoch - 1s/step\n",
            "Epoch 1649/3000\n",
            "1/1 - 1s - loss: 0.0546 - val_loss: 0.0531 - 1s/epoch - 1s/step\n",
            "Epoch 1650/3000\n",
            "1/1 - 1s - loss: 0.0544 - val_loss: 0.0529 - 1s/epoch - 1s/step\n",
            "Epoch 1651/3000\n",
            "1/1 - 1s - loss: 0.0542 - val_loss: 0.0527 - 1s/epoch - 1s/step\n",
            "Epoch 1652/3000\n",
            "1/1 - 1s - loss: 0.0540 - val_loss: 0.0525 - 1s/epoch - 1s/step\n",
            "Epoch 1653/3000\n",
            "1/1 - 1s - loss: 0.0538 - val_loss: 0.0524 - 1s/epoch - 1s/step\n",
            "Epoch 1654/3000\n",
            "1/1 - 1s - loss: 0.0536 - val_loss: 0.0522 - 1s/epoch - 1s/step\n",
            "Epoch 1655/3000\n",
            "1/1 - 1s - loss: 0.0534 - val_loss: 0.0520 - 1s/epoch - 1s/step\n",
            "Epoch 1656/3000\n",
            "1/1 - 1s - loss: 0.0532 - val_loss: 0.0518 - 1s/epoch - 1s/step\n",
            "Epoch 1657/3000\n",
            "1/1 - 1s - loss: 0.0530 - val_loss: 0.0516 - 1s/epoch - 1s/step\n",
            "Epoch 1658/3000\n",
            "1/1 - 1s - loss: 0.0528 - val_loss: 0.0515 - 1s/epoch - 1s/step\n",
            "Epoch 1659/3000\n",
            "1/1 - 1s - loss: 0.0526 - val_loss: 0.0513 - 1s/epoch - 1s/step\n",
            "Epoch 1660/3000\n",
            "1/1 - 1s - loss: 0.0524 - val_loss: 0.0511 - 1s/epoch - 1s/step\n",
            "Epoch 1661/3000\n",
            "1/1 - 1s - loss: 0.0522 - val_loss: 0.0509 - 1s/epoch - 1s/step\n",
            "Epoch 1662/3000\n",
            "1/1 - 1s - loss: 0.0520 - val_loss: 0.0508 - 1s/epoch - 1s/step\n",
            "Epoch 1663/3000\n",
            "1/1 - 1s - loss: 0.0518 - val_loss: 0.0506 - 1s/epoch - 1s/step\n",
            "Epoch 1664/3000\n",
            "1/1 - 1s - loss: 0.0516 - val_loss: 0.0504 - 1s/epoch - 1s/step\n",
            "Epoch 1665/3000\n",
            "1/1 - 1s - loss: 0.0514 - val_loss: 0.0502 - 1s/epoch - 1s/step\n",
            "Epoch 1666/3000\n",
            "1/1 - 1s - loss: 0.0512 - val_loss: 0.0501 - 1s/epoch - 1s/step\n",
            "Epoch 1667/3000\n",
            "1/1 - 1s - loss: 0.0510 - val_loss: 0.0499 - 1s/epoch - 1s/step\n",
            "Epoch 1668/3000\n",
            "1/1 - 1s - loss: 0.0508 - val_loss: 0.0497 - 1s/epoch - 1s/step\n",
            "Epoch 1669/3000\n",
            "1/1 - 1s - loss: 0.0506 - val_loss: 0.0496 - 1s/epoch - 1s/step\n",
            "Epoch 1670/3000\n",
            "1/1 - 1s - loss: 0.0504 - val_loss: 0.0494 - 1s/epoch - 1s/step\n",
            "Epoch 1671/3000\n",
            "1/1 - 1s - loss: 0.0502 - val_loss: 0.0492 - 1s/epoch - 1s/step\n",
            "Epoch 1672/3000\n",
            "1/1 - 1s - loss: 0.0500 - val_loss: 0.0491 - 1s/epoch - 1s/step\n",
            "Epoch 1673/3000\n",
            "1/1 - 1s - loss: 0.0498 - val_loss: 0.0489 - 1s/epoch - 1s/step\n",
            "Epoch 1674/3000\n",
            "1/1 - 1s - loss: 0.0496 - val_loss: 0.0487 - 1s/epoch - 1s/step\n",
            "Epoch 1675/3000\n",
            "1/1 - 1s - loss: 0.0494 - val_loss: 0.0486 - 1s/epoch - 1s/step\n",
            "Epoch 1676/3000\n",
            "1/1 - 1s - loss: 0.0492 - val_loss: 0.0484 - 1s/epoch - 1s/step\n",
            "Epoch 1677/3000\n",
            "1/1 - 1s - loss: 0.0490 - val_loss: 0.0482 - 1s/epoch - 1s/step\n",
            "Epoch 1678/3000\n",
            "1/1 - 1s - loss: 0.0488 - val_loss: 0.0480 - 1s/epoch - 1s/step\n",
            "Epoch 1679/3000\n",
            "1/1 - 1s - loss: 0.0486 - val_loss: 0.0479 - 1s/epoch - 1s/step\n",
            "Epoch 1680/3000\n",
            "1/1 - 1s - loss: 0.0484 - val_loss: 0.0477 - 1s/epoch - 1s/step\n",
            "Epoch 1681/3000\n",
            "1/1 - 1s - loss: 0.0482 - val_loss: 0.0475 - 1s/epoch - 1s/step\n",
            "Epoch 1682/3000\n",
            "1/1 - 1s - loss: 0.0480 - val_loss: 0.0474 - 1s/epoch - 1s/step\n",
            "Epoch 1683/3000\n",
            "1/1 - 1s - loss: 0.0478 - val_loss: 0.0472 - 1s/epoch - 1s/step\n",
            "Epoch 1684/3000\n",
            "1/1 - 1s - loss: 0.0476 - val_loss: 0.0470 - 1s/epoch - 1s/step\n",
            "Epoch 1685/3000\n",
            "1/1 - 1s - loss: 0.0474 - val_loss: 0.0468 - 1s/epoch - 1s/step\n",
            "Epoch 1686/3000\n",
            "1/1 - 1s - loss: 0.0472 - val_loss: 0.0467 - 1s/epoch - 1s/step\n",
            "Epoch 1687/3000\n",
            "1/1 - 1s - loss: 0.0471 - val_loss: 0.0465 - 1s/epoch - 1s/step\n",
            "Epoch 1688/3000\n",
            "1/1 - 1s - loss: 0.0469 - val_loss: 0.0464 - 1s/epoch - 1s/step\n",
            "Epoch 1689/3000\n",
            "1/1 - 1s - loss: 0.0467 - val_loss: 0.0462 - 1s/epoch - 1s/step\n",
            "Epoch 1690/3000\n",
            "1/1 - 1s - loss: 0.0465 - val_loss: 0.0461 - 1s/epoch - 1s/step\n",
            "Epoch 1691/3000\n",
            "1/1 - 1s - loss: 0.0463 - val_loss: 0.0459 - 1s/epoch - 1s/step\n",
            "Epoch 1692/3000\n",
            "1/1 - 1s - loss: 0.0461 - val_loss: 0.0457 - 1s/epoch - 1s/step\n",
            "Epoch 1693/3000\n",
            "1/1 - 1s - loss: 0.0459 - val_loss: 0.0456 - 1s/epoch - 1s/step\n",
            "Epoch 1694/3000\n",
            "1/1 - 1s - loss: 0.0457 - val_loss: 0.0454 - 1s/epoch - 1s/step\n",
            "Epoch 1695/3000\n",
            "1/1 - 1s - loss: 0.0455 - val_loss: 0.0453 - 1s/epoch - 1s/step\n",
            "Epoch 1696/3000\n",
            "1/1 - 1s - loss: 0.0454 - val_loss: 0.0451 - 1s/epoch - 1s/step\n",
            "Epoch 1697/3000\n",
            "1/1 - 1s - loss: 0.0452 - val_loss: 0.0449 - 1s/epoch - 1s/step\n",
            "Epoch 1698/3000\n",
            "1/1 - 1s - loss: 0.0450 - val_loss: 0.0448 - 1s/epoch - 1s/step\n",
            "Epoch 1699/3000\n",
            "1/1 - 1s - loss: 0.0448 - val_loss: 0.0446 - 1s/epoch - 1s/step\n",
            "Epoch 1700/3000\n",
            "1/1 - 1s - loss: 0.0446 - val_loss: 0.0445 - 1s/epoch - 1s/step\n",
            "Epoch 1701/3000\n",
            "1/1 - 1s - loss: 0.0444 - val_loss: 0.0443 - 1s/epoch - 1s/step\n",
            "Epoch 1702/3000\n",
            "1/1 - 1s - loss: 0.0443 - val_loss: 0.0442 - 1s/epoch - 1s/step\n",
            "Epoch 1703/3000\n",
            "1/1 - 1s - loss: 0.0441 - val_loss: 0.0440 - 1s/epoch - 1s/step\n",
            "Epoch 1704/3000\n",
            "1/1 - 1s - loss: 0.0439 - val_loss: 0.0438 - 1s/epoch - 1s/step\n",
            "Epoch 1705/3000\n",
            "1/1 - 1s - loss: 0.0437 - val_loss: 0.0437 - 1s/epoch - 1s/step\n",
            "Epoch 1706/3000\n",
            "1/1 - 1s - loss: 0.0435 - val_loss: 0.0435 - 1s/epoch - 1s/step\n",
            "Epoch 1707/3000\n",
            "1/1 - 1s - loss: 0.0434 - val_loss: 0.0434 - 1s/epoch - 1s/step\n",
            "Epoch 1708/3000\n",
            "1/1 - 1s - loss: 0.0432 - val_loss: 0.0432 - 1s/epoch - 1s/step\n",
            "Epoch 1709/3000\n",
            "1/1 - 1s - loss: 0.0430 - val_loss: 0.0431 - 1s/epoch - 1s/step\n",
            "Epoch 1710/3000\n",
            "1/1 - 1s - loss: 0.0428 - val_loss: 0.0429 - 1s/epoch - 1s/step\n",
            "Epoch 1711/3000\n",
            "1/1 - 1s - loss: 0.0426 - val_loss: 0.0428 - 1s/epoch - 1s/step\n",
            "Epoch 1712/3000\n",
            "1/1 - 1s - loss: 0.0425 - val_loss: 0.0426 - 1s/epoch - 1s/step\n",
            "Epoch 1713/3000\n",
            "1/1 - 1s - loss: 0.0423 - val_loss: 0.0425 - 1s/epoch - 1s/step\n",
            "Epoch 1714/3000\n",
            "1/1 - 1s - loss: 0.0421 - val_loss: 0.0423 - 1s/epoch - 1s/step\n",
            "Epoch 1715/3000\n",
            "1/1 - 1s - loss: 0.0419 - val_loss: 0.0422 - 1s/epoch - 1s/step\n",
            "Epoch 1716/3000\n",
            "1/1 - 1s - loss: 0.0418 - val_loss: 0.0420 - 1s/epoch - 1s/step\n",
            "Epoch 1717/3000\n",
            "1/1 - 1s - loss: 0.0416 - val_loss: 0.0419 - 1s/epoch - 1s/step\n",
            "Epoch 1718/3000\n",
            "1/1 - 1s - loss: 0.0414 - val_loss: 0.0417 - 1s/epoch - 1s/step\n",
            "Epoch 1719/3000\n",
            "1/1 - 1s - loss: 0.0413 - val_loss: 0.0416 - 1s/epoch - 1s/step\n",
            "Epoch 1720/3000\n",
            "1/1 - 1s - loss: 0.0411 - val_loss: 0.0414 - 1s/epoch - 1s/step\n",
            "Epoch 1721/3000\n",
            "1/1 - 1s - loss: 0.0409 - val_loss: 0.0413 - 1s/epoch - 1s/step\n",
            "Epoch 1722/3000\n",
            "1/1 - 1s - loss: 0.0408 - val_loss: 0.0412 - 1s/epoch - 1s/step\n",
            "Epoch 1723/3000\n",
            "1/1 - 1s - loss: 0.0406 - val_loss: 0.0410 - 1s/epoch - 1s/step\n",
            "Epoch 1724/3000\n",
            "1/1 - 1s - loss: 0.0404 - val_loss: 0.0409 - 1s/epoch - 1s/step\n",
            "Epoch 1725/3000\n",
            "1/1 - 1s - loss: 0.0403 - val_loss: 0.0407 - 1s/epoch - 1s/step\n",
            "Epoch 1726/3000\n",
            "1/1 - 1s - loss: 0.0401 - val_loss: 0.0406 - 1s/epoch - 1s/step\n",
            "Epoch 1727/3000\n",
            "1/1 - 1s - loss: 0.0399 - val_loss: 0.0404 - 1s/epoch - 1s/step\n",
            "Epoch 1728/3000\n",
            "1/1 - 1s - loss: 0.0398 - val_loss: 0.0403 - 1s/epoch - 1s/step\n",
            "Epoch 1729/3000\n",
            "1/1 - 1s - loss: 0.0396 - val_loss: 0.0402 - 1s/epoch - 1s/step\n",
            "Epoch 1730/3000\n",
            "1/1 - 1s - loss: 0.0394 - val_loss: 0.0400 - 1s/epoch - 1s/step\n",
            "Epoch 1731/3000\n",
            "1/1 - 1s - loss: 0.0393 - val_loss: 0.0399 - 1s/epoch - 1s/step\n",
            "Epoch 1732/3000\n",
            "1/1 - 1s - loss: 0.0391 - val_loss: 0.0398 - 1s/epoch - 1s/step\n",
            "Epoch 1733/3000\n",
            "1/1 - 1s - loss: 0.0390 - val_loss: 0.0396 - 1s/epoch - 1s/step\n",
            "Epoch 1734/3000\n",
            "1/1 - 1s - loss: 0.0388 - val_loss: 0.0395 - 1s/epoch - 1s/step\n",
            "Epoch 1735/3000\n",
            "1/1 - 1s - loss: 0.0386 - val_loss: 0.0393 - 1s/epoch - 1s/step\n",
            "Epoch 1736/3000\n",
            "1/1 - 1s - loss: 0.0385 - val_loss: 0.0392 - 1s/epoch - 1s/step\n",
            "Epoch 1737/3000\n",
            "1/1 - 1s - loss: 0.0383 - val_loss: 0.0391 - 1s/epoch - 1s/step\n",
            "Epoch 1738/3000\n",
            "1/1 - 1s - loss: 0.0382 - val_loss: 0.0390 - 1s/epoch - 1s/step\n",
            "Epoch 1739/3000\n",
            "1/1 - 1s - loss: 0.0380 - val_loss: 0.0388 - 1s/epoch - 1s/step\n",
            "Epoch 1740/3000\n",
            "1/1 - 1s - loss: 0.0379 - val_loss: 0.0387 - 1s/epoch - 1s/step\n",
            "Epoch 1741/3000\n",
            "1/1 - 1s - loss: 0.0377 - val_loss: 0.0385 - 1s/epoch - 1s/step\n",
            "Epoch 1742/3000\n",
            "1/1 - 1s - loss: 0.0376 - val_loss: 0.0384 - 1s/epoch - 1s/step\n",
            "Epoch 1743/3000\n",
            "1/1 - 1s - loss: 0.0374 - val_loss: 0.0383 - 1s/epoch - 1s/step\n",
            "Epoch 1744/3000\n",
            "1/1 - 1s - loss: 0.0373 - val_loss: 0.0382 - 1s/epoch - 1s/step\n",
            "Epoch 1745/3000\n",
            "1/1 - 1s - loss: 0.0371 - val_loss: 0.0380 - 1s/epoch - 1s/step\n",
            "Epoch 1746/3000\n",
            "1/1 - 1s - loss: 0.0370 - val_loss: 0.0379 - 1s/epoch - 1s/step\n",
            "Epoch 1747/3000\n",
            "1/1 - 1s - loss: 0.0368 - val_loss: 0.0378 - 1s/epoch - 1s/step\n",
            "Epoch 1748/3000\n",
            "1/1 - 1s - loss: 0.0367 - val_loss: 0.0377 - 1s/epoch - 1s/step\n",
            "Epoch 1749/3000\n",
            "1/1 - 1s - loss: 0.0365 - val_loss: 0.0375 - 1s/epoch - 1s/step\n",
            "Epoch 1750/3000\n",
            "1/1 - 1s - loss: 0.0364 - val_loss: 0.0374 - 1s/epoch - 1s/step\n",
            "Epoch 1751/3000\n",
            "1/1 - 1s - loss: 0.0362 - val_loss: 0.0373 - 1s/epoch - 1s/step\n",
            "Epoch 1752/3000\n",
            "1/1 - 1s - loss: 0.0361 - val_loss: 0.0372 - 1s/epoch - 1s/step\n",
            "Epoch 1753/3000\n",
            "1/1 - 1s - loss: 0.0360 - val_loss: 0.0370 - 1s/epoch - 1s/step\n",
            "Epoch 1754/3000\n",
            "1/1 - 1s - loss: 0.0358 - val_loss: 0.0370 - 1s/epoch - 1s/step\n",
            "Epoch 1755/3000\n",
            "1/1 - 1s - loss: 0.0357 - val_loss: 0.0368 - 1s/epoch - 1s/step\n",
            "Epoch 1756/3000\n",
            "1/1 - 1s - loss: 0.0355 - val_loss: 0.0368 - 1s/epoch - 1s/step\n",
            "Epoch 1757/3000\n",
            "1/1 - 1s - loss: 0.0354 - val_loss: 0.0366 - 1s/epoch - 1s/step\n",
            "Epoch 1758/3000\n",
            "1/1 - 1s - loss: 0.0353 - val_loss: 0.0365 - 1s/epoch - 1s/step\n",
            "Epoch 1759/3000\n",
            "1/1 - 1s - loss: 0.0351 - val_loss: 0.0364 - 1s/epoch - 1s/step\n",
            "Epoch 1760/3000\n",
            "1/1 - 1s - loss: 0.0350 - val_loss: 0.0363 - 1s/epoch - 1s/step\n",
            "Epoch 1761/3000\n",
            "1/1 - 1s - loss: 0.0349 - val_loss: 0.0362 - 1s/epoch - 1s/step\n",
            "Epoch 1762/3000\n",
            "1/1 - 1s - loss: 0.0347 - val_loss: 0.0360 - 1s/epoch - 1s/step\n",
            "Epoch 1763/3000\n",
            "1/1 - 1s - loss: 0.0346 - val_loss: 0.0359 - 1s/epoch - 1s/step\n",
            "Epoch 1764/3000\n",
            "1/1 - 1s - loss: 0.0345 - val_loss: 0.0358 - 1s/epoch - 1s/step\n",
            "Epoch 1765/3000\n",
            "1/1 - 1s - loss: 0.0343 - val_loss: 0.0357 - 1s/epoch - 1s/step\n",
            "Epoch 1766/3000\n",
            "1/1 - 1s - loss: 0.0342 - val_loss: 0.0356 - 1s/epoch - 1s/step\n",
            "Epoch 1767/3000\n",
            "1/1 - 1s - loss: 0.0341 - val_loss: 0.0355 - 1s/epoch - 1s/step\n",
            "Epoch 1768/3000\n",
            "1/1 - 1s - loss: 0.0339 - val_loss: 0.0353 - 1s/epoch - 1s/step\n",
            "Epoch 1769/3000\n",
            "1/1 - 1s - loss: 0.0338 - val_loss: 0.0353 - 1s/epoch - 1s/step\n",
            "Epoch 1770/3000\n",
            "1/1 - 1s - loss: 0.0337 - val_loss: 0.0351 - 1s/epoch - 1s/step\n",
            "Epoch 1771/3000\n",
            "1/1 - 1s - loss: 0.0336 - val_loss: 0.0351 - 1s/epoch - 1s/step\n",
            "Epoch 1772/3000\n",
            "1/1 - 1s - loss: 0.0334 - val_loss: 0.0349 - 1s/epoch - 1s/step\n",
            "Epoch 1773/3000\n",
            "1/1 - 1s - loss: 0.0333 - val_loss: 0.0349 - 1s/epoch - 1s/step\n",
            "Epoch 1774/3000\n",
            "1/1 - 1s - loss: 0.0332 - val_loss: 0.0347 - 1s/epoch - 1s/step\n",
            "Epoch 1775/3000\n",
            "1/1 - 1s - loss: 0.0331 - val_loss: 0.0347 - 1s/epoch - 1s/step\n",
            "Epoch 1776/3000\n",
            "1/1 - 1s - loss: 0.0330 - val_loss: 0.0345 - 1s/epoch - 1s/step\n",
            "Epoch 1777/3000\n",
            "1/1 - 1s - loss: 0.0329 - val_loss: 0.0345 - 1s/epoch - 1s/step\n",
            "Epoch 1778/3000\n",
            "1/1 - 1s - loss: 0.0327 - val_loss: 0.0343 - 1s/epoch - 1s/step\n",
            "Epoch 1779/3000\n",
            "1/1 - 1s - loss: 0.0326 - val_loss: 0.0343 - 1s/epoch - 1s/step\n",
            "Epoch 1780/3000\n",
            "1/1 - 1s - loss: 0.0325 - val_loss: 0.0341 - 1s/epoch - 1s/step\n",
            "Epoch 1781/3000\n",
            "1/1 - 1s - loss: 0.0324 - val_loss: 0.0341 - 1s/epoch - 1s/step\n",
            "Epoch 1782/3000\n",
            "1/1 - 1s - loss: 0.0323 - val_loss: 0.0339 - 1s/epoch - 1s/step\n",
            "Epoch 1783/3000\n",
            "1/1 - 1s - loss: 0.0322 - val_loss: 0.0338 - 1s/epoch - 1s/step\n",
            "Epoch 1784/3000\n",
            "1/1 - 1s - loss: 0.0320 - val_loss: 0.0337 - 1s/epoch - 1s/step\n",
            "Epoch 1785/3000\n",
            "1/1 - 1s - loss: 0.0319 - val_loss: 0.0336 - 1s/epoch - 1s/step\n",
            "Epoch 1786/3000\n",
            "1/1 - 1s - loss: 0.0318 - val_loss: 0.0335 - 1s/epoch - 1s/step\n",
            "Epoch 1787/3000\n",
            "1/1 - 1s - loss: 0.0317 - val_loss: 0.0334 - 1s/epoch - 1s/step\n",
            "Epoch 1788/3000\n",
            "1/1 - 1s - loss: 0.0316 - val_loss: 0.0333 - 1s/epoch - 1s/step\n",
            "Epoch 1789/3000\n",
            "1/1 - 1s - loss: 0.0315 - val_loss: 0.0332 - 1s/epoch - 1s/step\n",
            "Epoch 1790/3000\n",
            "1/1 - 1s - loss: 0.0314 - val_loss: 0.0332 - 1s/epoch - 1s/step\n",
            "Epoch 1791/3000\n",
            "1/1 - 1s - loss: 0.0313 - val_loss: 0.0331 - 1s/epoch - 1s/step\n",
            "Epoch 1792/3000\n",
            "1/1 - 1s - loss: 0.0312 - val_loss: 0.0330 - 1s/epoch - 1s/step\n",
            "Epoch 1793/3000\n",
            "1/1 - 1s - loss: 0.0311 - val_loss: 0.0329 - 1s/epoch - 1s/step\n",
            "Epoch 1794/3000\n",
            "1/1 - 1s - loss: 0.0310 - val_loss: 0.0328 - 1s/epoch - 1s/step\n",
            "Epoch 1795/3000\n",
            "1/1 - 1s - loss: 0.0309 - val_loss: 0.0327 - 1s/epoch - 1s/step\n",
            "Epoch 1796/3000\n",
            "1/1 - 1s - loss: 0.0308 - val_loss: 0.0326 - 1s/epoch - 1s/step\n",
            "Epoch 1797/3000\n",
            "1/1 - 1s - loss: 0.0307 - val_loss: 0.0326 - 1s/epoch - 1s/step\n",
            "Epoch 1798/3000\n",
            "1/1 - 1s - loss: 0.0306 - val_loss: 0.0324 - 1s/epoch - 1s/step\n",
            "Epoch 1799/3000\n",
            "1/1 - 1s - loss: 0.0305 - val_loss: 0.0324 - 1s/epoch - 1s/step\n",
            "Epoch 1800/3000\n",
            "1/1 - 1s - loss: 0.0304 - val_loss: 0.0323 - 1s/epoch - 1s/step\n",
            "Epoch 1801/3000\n",
            "1/1 - 1s - loss: 0.0303 - val_loss: 0.0322 - 1s/epoch - 1s/step\n",
            "Epoch 1802/3000\n",
            "1/1 - 1s - loss: 0.0302 - val_loss: 0.0321 - 1s/epoch - 1s/step\n",
            "Epoch 1803/3000\n",
            "1/1 - 1s - loss: 0.0301 - val_loss: 0.0320 - 1s/epoch - 1s/step\n",
            "Epoch 1804/3000\n",
            "1/1 - 1s - loss: 0.0300 - val_loss: 0.0320 - 1s/epoch - 1s/step\n",
            "Epoch 1805/3000\n",
            "1/1 - 1s - loss: 0.0299 - val_loss: 0.0319 - 1s/epoch - 1s/step\n",
            "Epoch 1806/3000\n",
            "1/1 - 1s - loss: 0.0298 - val_loss: 0.0318 - 1s/epoch - 1s/step\n",
            "Epoch 1807/3000\n",
            "1/1 - 1s - loss: 0.0298 - val_loss: 0.0317 - 1s/epoch - 1s/step\n",
            "Epoch 1808/3000\n",
            "1/1 - 1s - loss: 0.0297 - val_loss: 0.0317 - 1s/epoch - 1s/step\n",
            "Epoch 1809/3000\n",
            "1/1 - 1s - loss: 0.0296 - val_loss: 0.0315 - 1s/epoch - 1s/step\n",
            "Epoch 1810/3000\n",
            "1/1 - 1s - loss: 0.0295 - val_loss: 0.0315 - 1s/epoch - 1s/step\n",
            "Epoch 1811/3000\n",
            "1/1 - 1s - loss: 0.0294 - val_loss: 0.0314 - 1s/epoch - 1s/step\n",
            "Epoch 1812/3000\n",
            "1/1 - 1s - loss: 0.0293 - val_loss: 0.0314 - 1s/epoch - 1s/step\n",
            "Epoch 1813/3000\n",
            "1/1 - 1s - loss: 0.0292 - val_loss: 0.0312 - 1s/epoch - 1s/step\n",
            "Epoch 1814/3000\n",
            "1/1 - 1s - loss: 0.0292 - val_loss: 0.0313 - 1s/epoch - 1s/step\n",
            "Epoch 1815/3000\n",
            "1/1 - 1s - loss: 0.0291 - val_loss: 0.0311 - 1s/epoch - 1s/step\n",
            "Epoch 1816/3000\n",
            "1/1 - 1s - loss: 0.0290 - val_loss: 0.0312 - 1s/epoch - 1s/step\n",
            "Epoch 1817/3000\n",
            "1/1 - 1s - loss: 0.0290 - val_loss: 0.0309 - 1s/epoch - 1s/step\n",
            "Epoch 1818/3000\n",
            "1/1 - 1s - loss: 0.0289 - val_loss: 0.0311 - 1s/epoch - 1s/step\n",
            "Epoch 1819/3000\n",
            "1/1 - 1s - loss: 0.0288 - val_loss: 0.0308 - 1s/epoch - 1s/step\n",
            "Epoch 1820/3000\n",
            "1/1 - 1s - loss: 0.0288 - val_loss: 0.0311 - 1s/epoch - 1s/step\n",
            "Epoch 1821/3000\n",
            "1/1 - 1s - loss: 0.0287 - val_loss: 0.0306 - 1s/epoch - 1s/step\n",
            "Epoch 1822/3000\n",
            "1/1 - 1s - loss: 0.0287 - val_loss: 0.0310 - 1s/epoch - 1s/step\n",
            "Epoch 1823/3000\n",
            "1/1 - 1s - loss: 0.0286 - val_loss: 0.0305 - 1s/epoch - 1s/step\n",
            "Epoch 1824/3000\n",
            "1/1 - 1s - loss: 0.0286 - val_loss: 0.0311 - 1s/epoch - 1s/step\n",
            "Epoch 1825/3000\n",
            "1/1 - 1s - loss: 0.0286 - val_loss: 0.0305 - 1s/epoch - 1s/step\n",
            "Epoch 1826/3000\n",
            "1/1 - 1s - loss: 0.0286 - val_loss: 0.0312 - 1s/epoch - 1s/step\n",
            "Epoch 1827/3000\n",
            "1/1 - 1s - loss: 0.0286 - val_loss: 0.0305 - 1s/epoch - 1s/step\n",
            "Epoch 1828/3000\n",
            "1/1 - 1s - loss: 0.0287 - val_loss: 0.0314 - 1s/epoch - 1s/step\n",
            "Epoch 1829/3000\n",
            "1/1 - 1s - loss: 0.0288 - val_loss: 0.0307 - 1s/epoch - 1s/step\n",
            "Epoch 1830/3000\n",
            "1/1 - 1s - loss: 0.0289 - val_loss: 0.0320 - 1s/epoch - 1s/step\n",
            "Epoch 1831/3000\n",
            "1/1 - 1s - loss: 0.0292 - val_loss: 0.0311 - 1s/epoch - 1s/step\n",
            "Epoch 1832/3000\n",
            "1/1 - 1s - loss: 0.0295 - val_loss: 0.0333 - 1s/epoch - 1s/step\n",
            "Epoch 1833/3000\n",
            "1/1 - 1s - loss: 0.0303 - val_loss: 0.0322 - 1s/epoch - 1s/step\n",
            "Epoch 1834/3000\n",
            "1/1 - 1s - loss: 0.0308 - val_loss: 0.0359 - 1s/epoch - 1s/step\n",
            "Epoch 1835/3000\n",
            "1/1 - 1s - loss: 0.0325 - val_loss: 0.0340 - 1s/epoch - 1s/step\n",
            "Epoch 1836/3000\n",
            "1/1 - 1s - loss: 0.0329 - val_loss: 0.0399 - 1s/epoch - 1s/step\n",
            "Epoch 1837/3000\n",
            "1/1 - 1s - loss: 0.0360 - val_loss: 0.0361 - 1s/epoch - 1s/step\n",
            "Epoch 1838/3000\n",
            "1/1 - 1s - loss: 0.0352 - val_loss: 0.0424 - 1s/epoch - 1s/step\n",
            "Epoch 1839/3000\n",
            "1/1 - 1s - loss: 0.0381 - val_loss: 0.0360 - 1s/epoch - 1s/step\n",
            "Epoch 1840/3000\n",
            "1/1 - 1s - loss: 0.0349 - val_loss: 0.0386 - 1s/epoch - 1s/step\n",
            "Epoch 1841/3000\n",
            "1/1 - 1s - loss: 0.0344 - val_loss: 0.0325 - 1s/epoch - 1s/step\n",
            "Epoch 1842/3000\n",
            "1/1 - 1s - loss: 0.0306 - val_loss: 0.0318 - 1s/epoch - 1s/step\n",
            "Epoch 1843/3000\n",
            "1/1 - 1s - loss: 0.0285 - val_loss: 0.0299 - 1s/epoch - 1s/step\n",
            "Epoch 1844/3000\n",
            "1/1 - 1s - loss: 0.0273 - val_loss: 0.0298 - 1s/epoch - 1s/step\n",
            "Epoch 1845/3000\n",
            "1/1 - 1s - loss: 0.0274 - val_loss: 0.0315 - 1s/epoch - 1s/step\n",
            "Epoch 1846/3000\n",
            "1/1 - 1s - loss: 0.0285 - val_loss: 0.0311 - 1s/epoch - 1s/step\n",
            "Epoch 1847/3000\n",
            "1/1 - 1s - loss: 0.0297 - val_loss: 0.0348 - 1s/epoch - 1s/step\n",
            "Epoch 1848/3000\n",
            "1/1 - 1s - loss: 0.0316 - val_loss: 0.0327 - 1s/epoch - 1s/step\n",
            "Epoch 1849/3000\n",
            "1/1 - 1s - loss: 0.0318 - val_loss: 0.0378 - 1s/epoch - 1s/step\n",
            "Epoch 1850/3000\n",
            "1/1 - 1s - loss: 0.0344 - val_loss: 0.0347 - 1s/epoch - 1s/step\n",
            "Epoch 1851/3000\n",
            "1/1 - 1s - loss: 0.0341 - val_loss: 0.0427 - 1s/epoch - 1s/step\n",
            "Epoch 1852/3000\n",
            "1/1 - 1s - loss: 0.0388 - val_loss: 0.0382 - 1s/epoch - 1s/step\n",
            "Epoch 1853/3000\n",
            "1/1 - 1s - loss: 0.0378 - val_loss: 0.0500 - 1s/epoch - 1s/step\n",
            "Epoch 1854/3000\n",
            "1/1 - 1s - loss: 0.0452 - val_loss: 0.0412 - 1s/epoch - 1s/step\n",
            "Epoch 1855/3000\n",
            "1/1 - 1s - loss: 0.0408 - val_loss: 0.0497 - 1s/epoch - 1s/step\n",
            "Epoch 1856/3000\n",
            "1/1 - 1s - loss: 0.0446 - val_loss: 0.0378 - 1s/epoch - 1s/step\n",
            "Epoch 1857/3000\n",
            "1/1 - 1s - loss: 0.0365 - val_loss: 0.0368 - 1s/epoch - 1s/step\n",
            "Epoch 1858/3000\n",
            "1/1 - 1s - loss: 0.0325 - val_loss: 0.0303 - 1s/epoch - 1s/step\n",
            "Epoch 1859/3000\n",
            "1/1 - 1s - loss: 0.0277 - val_loss: 0.0297 - 1s/epoch - 1s/step\n",
            "Epoch 1860/3000\n",
            "1/1 - 1s - loss: 0.0270 - val_loss: 0.0329 - 1s/epoch - 1s/step\n",
            "Epoch 1861/3000\n",
            "1/1 - 1s - loss: 0.0294 - val_loss: 0.0330 - 1s/epoch - 1s/step\n",
            "Epoch 1862/3000\n",
            "1/1 - 1s - loss: 0.0317 - val_loss: 0.0387 - 1s/epoch - 1s/step\n",
            "Epoch 1863/3000\n",
            "1/1 - 1s - loss: 0.0348 - val_loss: 0.0330 - 1s/epoch - 1s/step\n",
            "Epoch 1864/3000\n",
            "1/1 - 1s - loss: 0.0324 - val_loss: 0.0342 - 1s/epoch - 1s/step\n",
            "Epoch 1865/3000\n",
            "1/1 - 1s - loss: 0.0311 - val_loss: 0.0295 - 1s/epoch - 1s/step\n",
            "Epoch 1866/3000\n",
            "1/1 - 1s - loss: 0.0281 - val_loss: 0.0290 - 1s/epoch - 1s/step\n",
            "Epoch 1867/3000\n",
            "1/1 - 1s - loss: 0.0267 - val_loss: 0.0278 - 1s/epoch - 1s/step\n",
            "Epoch 1868/3000\n",
            "1/1 - 1s - loss: 0.0260 - val_loss: 0.0277 - 1s/epoch - 1s/step\n",
            "Epoch 1869/3000\n",
            "1/1 - 1s - loss: 0.0258 - val_loss: 0.0280 - 1s/epoch - 1s/step\n",
            "Epoch 1870/3000\n",
            "1/1 - 1s - loss: 0.0259 - val_loss: 0.0278 - 1s/epoch - 1s/step\n",
            "Epoch 1871/3000\n",
            "1/1 - 1s - loss: 0.0262 - val_loss: 0.0292 - 1s/epoch - 1s/step\n",
            "Epoch 1872/3000\n",
            "1/1 - 1s - loss: 0.0269 - val_loss: 0.0295 - 1s/epoch - 1s/step\n",
            "Epoch 1873/3000\n",
            "1/1 - 1s - loss: 0.0283 - val_loss: 0.0360 - 1s/epoch - 1s/step\n",
            "Epoch 1874/3000\n",
            "1/1 - 1s - loss: 0.0332 - val_loss: 0.0402 - 1s/epoch - 1s/step\n",
            "Epoch 1875/3000\n",
            "1/1 - 1s - loss: 0.0402 - val_loss: 0.0833 - 1s/epoch - 1s/step\n",
            "Epoch 1876/3000\n",
            "1/1 - 1s - loss: 0.0772 - val_loss: 0.0840 - 1s/epoch - 1s/step\n",
            "Epoch 1877/3000\n",
            "1/1 - 1s - loss: 0.0885 - val_loss: 0.2492 - 1s/epoch - 1s/step\n",
            "Epoch 1878/3000\n",
            "1/1 - 1s - loss: 0.2275 - val_loss: 0.1191 - 1s/epoch - 1s/step\n",
            "Epoch 1879/3000\n",
            "1/1 - 1s - loss: 0.1310 - val_loss: 0.0979 - 1s/epoch - 1s/step\n",
            "Epoch 1880/3000\n",
            "1/1 - 1s - loss: 0.0836 - val_loss: 0.0368 - 1s/epoch - 1s/step\n",
            "Epoch 1881/3000\n",
            "1/1 - 1s - loss: 0.0312 - val_loss: 0.0807 - 1s/epoch - 1s/step\n",
            "Epoch 1882/3000\n",
            "1/1 - 1s - loss: 0.0777 - val_loss: 0.1709 - 1s/epoch - 1s/step\n",
            "Epoch 1883/3000\n",
            "1/1 - 1s - loss: 0.1635 - val_loss: 0.0917 - 1s/epoch - 1s/step\n",
            "Epoch 1884/3000\n",
            "1/1 - 1s - loss: 0.0943 - val_loss: 0.0502 - 1s/epoch - 1s/step\n",
            "Epoch 1885/3000\n",
            "1/1 - 1s - loss: 0.0417 - val_loss: 0.0726 - 1s/epoch - 1s/step\n",
            "Epoch 1886/3000\n",
            "1/1 - 1s - loss: 0.0597 - val_loss: 0.0852 - 1s/epoch - 1s/step\n",
            "Epoch 1887/3000\n",
            "1/1 - 1s - loss: 0.0878 - val_loss: 0.0934 - 1s/epoch - 1s/step\n",
            "Epoch 1888/3000\n",
            "1/1 - 1s - loss: 0.0888 - val_loss: 0.0402 - 1s/epoch - 1s/step\n",
            "Epoch 1889/3000\n",
            "1/1 - 1s - loss: 0.0391 - val_loss: 0.0355 - 1s/epoch - 1s/step\n",
            "Epoch 1890/3000\n",
            "1/1 - 1s - loss: 0.0351 - val_loss: 0.0741 - 1s/epoch - 1s/step\n",
            "Epoch 1891/3000\n",
            "1/1 - 1s - loss: 0.0673 - val_loss: 0.0573 - 1s/epoch - 1s/step\n",
            "Epoch 1892/3000\n",
            "1/1 - 1s - loss: 0.0623 - val_loss: 0.0554 - 1s/epoch - 1s/step\n",
            "Epoch 1893/3000\n",
            "1/1 - 1s - loss: 0.0517 - val_loss: 0.0295 - 1s/epoch - 1s/step\n",
            "Epoch 1894/3000\n",
            "1/1 - 1s - loss: 0.0292 - val_loss: 0.0293 - 1s/epoch - 1s/step\n",
            "Epoch 1895/3000\n",
            "1/1 - 1s - loss: 0.0287 - val_loss: 0.0480 - 1s/epoch - 1s/step\n",
            "Epoch 1896/3000\n",
            "1/1 - 1s - loss: 0.0468 - val_loss: 0.0680 - 1s/epoch - 1s/step\n",
            "Epoch 1897/3000\n",
            "1/1 - 1s - loss: 0.0707 - val_loss: 0.2322 - 1s/epoch - 1s/step\n",
            "Epoch 1898/3000\n",
            "1/1 - 1s - loss: 0.2163 - val_loss: 0.1321 - 1s/epoch - 1s/step\n",
            "Epoch 1899/3000\n",
            "1/1 - 1s - loss: 0.1525 - val_loss: 0.1859 - 1s/epoch - 1s/step\n",
            "Epoch 1900/3000\n",
            "1/1 - 1s - loss: 0.1664 - val_loss: 0.0449 - 1s/epoch - 1s/step\n",
            "Epoch 1901/3000\n",
            "1/1 - 1s - loss: 0.0429 - val_loss: 0.0689 - 1s/epoch - 1s/step\n",
            "Epoch 1902/3000\n",
            "1/1 - 1s - loss: 0.0646 - val_loss: 0.2081 - 1s/epoch - 1s/step\n",
            "Epoch 1903/3000\n",
            "1/1 - 1s - loss: 0.2118 - val_loss: 0.1516 - 1s/epoch - 1s/step\n",
            "Epoch 1904/3000\n",
            "1/1 - 1s - loss: 0.1544 - val_loss: 0.1474 - 1s/epoch - 1s/step\n",
            "Epoch 1905/3000\n",
            "1/1 - 1s - loss: 0.1227 - val_loss: 0.0614 - 1s/epoch - 1s/step\n",
            "Epoch 1906/3000\n",
            "1/1 - 1s - loss: 0.0555 - val_loss: 0.1017 - 1s/epoch - 1s/step\n",
            "Epoch 1907/3000\n",
            "1/1 - 1s - loss: 0.1084 - val_loss: 0.1730 - 1s/epoch - 1s/step\n",
            "Epoch 1908/3000\n",
            "1/1 - 1s - loss: 0.1708 - val_loss: 0.0772 - 1s/epoch - 1s/step\n",
            "Epoch 1909/3000\n",
            "1/1 - 1s - loss: 0.0770 - val_loss: 0.0412 - 1s/epoch - 1s/step\n",
            "Epoch 1910/3000\n",
            "1/1 - 1s - loss: 0.0400 - val_loss: 0.0998 - 1s/epoch - 1s/step\n",
            "Epoch 1911/3000\n",
            "1/1 - 1s - loss: 0.0868 - val_loss: 0.0749 - 1s/epoch - 1s/step\n",
            "Epoch 1912/3000\n",
            "1/1 - 1s - loss: 0.0840 - val_loss: 0.0440 - 1s/epoch - 1s/step\n",
            "Epoch 1913/3000\n",
            "1/1 - 1s - loss: 0.0398 - val_loss: 0.0375 - 1s/epoch - 1s/step\n",
            "Epoch 1914/3000\n",
            "1/1 - 1s - loss: 0.0367 - val_loss: 0.0872 - 1s/epoch - 1s/step\n",
            "Epoch 1915/3000\n",
            "1/1 - 1s - loss: 0.0869 - val_loss: 0.2868 - 1s/epoch - 1s/step\n",
            "Epoch 1916/3000\n",
            "1/1 - 1s - loss: 0.2779 - val_loss: 0.1479 - 1s/epoch - 1s/step\n",
            "Epoch 1917/3000\n",
            "1/1 - 1s - loss: 0.1712 - val_loss: 0.1162 - 1s/epoch - 1s/step\n",
            "Epoch 1918/3000\n",
            "1/1 - 1s - loss: 0.1021 - val_loss: 0.0480 - 1s/epoch - 1s/step\n",
            "Epoch 1919/3000\n",
            "1/1 - 1s - loss: 0.0428 - val_loss: 0.1637 - 1s/epoch - 1s/step\n",
            "Epoch 1920/3000\n",
            "1/1 - 1s - loss: 0.1616 - val_loss: 0.7010 - 1s/epoch - 1s/step\n",
            "Epoch 1921/3000\n",
            "1/1 - 1s - loss: 0.6982 - val_loss: 0.1739 - 1s/epoch - 1s/step\n",
            "Epoch 1922/3000\n",
            "1/1 - 1s - loss: 0.1962 - val_loss: 0.1151 - 1s/epoch - 1s/step\n",
            "Epoch 1923/3000\n",
            "1/1 - 1s - loss: 0.1314 - val_loss: 0.4243 - 1s/epoch - 1s/step\n",
            "Epoch 1924/3000\n",
            "1/1 - 1s - loss: 0.3940 - val_loss: 0.1307 - 1s/epoch - 1s/step\n",
            "Epoch 1925/3000\n",
            "1/1 - 1s - loss: 0.1293 - val_loss: 0.1453 - 1s/epoch - 1s/step\n",
            "Epoch 1926/3000\n",
            "1/1 - 1s - loss: 0.1427 - val_loss: 0.3316 - 1s/epoch - 1s/step\n",
            "Epoch 1927/3000\n",
            "1/1 - 1s - loss: 0.3221 - val_loss: 0.1402 - 1s/epoch - 1s/step\n",
            "Epoch 1928/3000\n",
            "1/1 - 1s - loss: 0.1452 - val_loss: 0.1467 - 1s/epoch - 1s/step\n",
            "Epoch 1929/3000\n",
            "1/1 - 1s - loss: 0.1557 - val_loss: 0.2389 - 1s/epoch - 1s/step\n",
            "Epoch 1930/3000\n",
            "1/1 - 1s - loss: 0.2132 - val_loss: 0.1307 - 1s/epoch - 1s/step\n",
            "Epoch 1931/3000\n",
            "1/1 - 1s - loss: 0.1321 - val_loss: 0.1533 - 1s/epoch - 1s/step\n",
            "Epoch 1932/3000\n",
            "1/1 - 1s - loss: 0.1547 - val_loss: 0.1866 - 1s/epoch - 1s/step\n",
            "Epoch 1933/3000\n",
            "1/1 - 1s - loss: 0.1844 - val_loss: 0.1571 - 1s/epoch - 1s/step\n",
            "Epoch 1934/3000\n",
            "1/1 - 1s - loss: 0.1615 - val_loss: 0.1157 - 1s/epoch - 1s/step\n",
            "Epoch 1935/3000\n",
            "1/1 - 1s - loss: 0.1179 - val_loss: 0.0715 - 1s/epoch - 1s/step\n",
            "Epoch 1936/3000\n",
            "1/1 - 1s - loss: 0.0680 - val_loss: 0.1511 - 1s/epoch - 1s/step\n",
            "Epoch 1937/3000\n",
            "1/1 - 1s - loss: 0.1552 - val_loss: 0.1500 - 1s/epoch - 1s/step\n",
            "Epoch 1938/3000\n",
            "1/1 - 1s - loss: 0.1492 - val_loss: 0.0432 - 1s/epoch - 1s/step\n",
            "Epoch 1939/3000\n",
            "1/1 - 1s - loss: 0.0450 - val_loss: 0.0998 - 1s/epoch - 1s/step\n",
            "Epoch 1940/3000\n",
            "1/1 - 1s - loss: 0.0987 - val_loss: 0.0687 - 1s/epoch - 1s/step\n",
            "Epoch 1941/3000\n",
            "1/1 - 1s - loss: 0.0680 - val_loss: 0.0508 - 1s/epoch - 1s/step\n",
            "Epoch 1942/3000\n",
            "1/1 - 1s - loss: 0.0524 - val_loss: 0.1370 - 1s/epoch - 1s/step\n",
            "Epoch 1943/3000\n",
            "1/1 - 1s - loss: 0.1341 - val_loss: 0.0558 - 1s/epoch - 1s/step\n",
            "Epoch 1944/3000\n",
            "1/1 - 1s - loss: 0.0575 - val_loss: 0.0453 - 1s/epoch - 1s/step\n",
            "Epoch 1945/3000\n",
            "1/1 - 1s - loss: 0.0439 - val_loss: 0.0734 - 1s/epoch - 1s/step\n",
            "Epoch 1946/3000\n",
            "1/1 - 1s - loss: 0.0708 - val_loss: 0.0395 - 1s/epoch - 1s/step\n",
            "Epoch 1947/3000\n",
            "1/1 - 1s - loss: 0.0387 - val_loss: 0.0634 - 1s/epoch - 1s/step\n",
            "Epoch 1948/3000\n",
            "1/1 - 1s - loss: 0.0622 - val_loss: 0.0615 - 1s/epoch - 1s/step\n",
            "Epoch 1949/3000\n",
            "1/1 - 1s - loss: 0.0607 - val_loss: 0.0287 - 1s/epoch - 1s/step\n",
            "Epoch 1950/3000\n",
            "1/1 - 1s - loss: 0.0275 - val_loss: 0.0479 - 1s/epoch - 1s/step\n",
            "Epoch 1951/3000\n",
            "1/1 - 1s - loss: 0.0470 - val_loss: 0.0467 - 1s/epoch - 1s/step\n",
            "Epoch 1952/3000\n",
            "1/1 - 1s - loss: 0.0468 - val_loss: 0.0409 - 1s/epoch - 1s/step\n",
            "Epoch 1953/3000\n",
            "1/1 - 1s - loss: 0.0405 - val_loss: 0.0460 - 1s/epoch - 1s/step\n",
            "Epoch 1954/3000\n",
            "1/1 - 1s - loss: 0.0466 - val_loss: 0.0320 - 1s/epoch - 1s/step\n",
            "Epoch 1955/3000\n",
            "1/1 - 1s - loss: 0.0310 - val_loss: 0.0303 - 1s/epoch - 1s/step\n",
            "Epoch 1956/3000\n",
            "1/1 - 1s - loss: 0.0294 - val_loss: 0.0390 - 1s/epoch - 1s/step\n",
            "Epoch 1957/3000\n",
            "1/1 - 1s - loss: 0.0392 - val_loss: 0.0351 - 1s/epoch - 1s/step\n",
            "Epoch 1958/3000\n",
            "1/1 - 1s - loss: 0.0340 - val_loss: 0.0399 - 1s/epoch - 1s/step\n",
            "Epoch 1959/3000\n",
            "1/1 - 1s - loss: 0.0397 - val_loss: 0.0479 - 1s/epoch - 1s/step\n",
            "Epoch 1960/3000\n",
            "1/1 - 1s - loss: 0.0457 - val_loss: 0.0345 - 1s/epoch - 1s/step\n",
            "Epoch 1961/3000\n",
            "1/1 - 1s - loss: 0.0350 - val_loss: 0.0438 - 1s/epoch - 1s/step\n",
            "Epoch 1962/3000\n",
            "1/1 - 1s - loss: 0.0405 - val_loss: 0.0313 - 1s/epoch - 1s/step\n",
            "Epoch 1963/3000\n",
            "1/1 - 1s - loss: 0.0303 - val_loss: 0.0272 - 1s/epoch - 1s/step\n",
            "Epoch 1964/3000\n",
            "1/1 - 1s - loss: 0.0253 - val_loss: 0.0328 - 1s/epoch - 1s/step\n",
            "Epoch 1965/3000\n",
            "1/1 - 1s - loss: 0.0306 - val_loss: 0.0300 - 1s/epoch - 1s/step\n",
            "Epoch 1966/3000\n",
            "1/1 - 1s - loss: 0.0289 - val_loss: 0.0375 - 1s/epoch - 1s/step\n",
            "Epoch 1967/3000\n",
            "1/1 - 1s - loss: 0.0345 - val_loss: 0.0360 - 1s/epoch - 1s/step\n",
            "Epoch 1968/3000\n",
            "1/1 - 1s - loss: 0.0364 - val_loss: 0.0349 - 1s/epoch - 1s/step\n",
            "Epoch 1969/3000\n",
            "1/1 - 1s - loss: 0.0320 - val_loss: 0.0287 - 1s/epoch - 1s/step\n",
            "Epoch 1970/3000\n",
            "1/1 - 1s - loss: 0.0282 - val_loss: 0.0284 - 1s/epoch - 1s/step\n",
            "Epoch 1971/3000\n",
            "1/1 - 1s - loss: 0.0267 - val_loss: 0.0259 - 1s/epoch - 1s/step\n",
            "Epoch 1972/3000\n",
            "1/1 - 1s - loss: 0.0244 - val_loss: 0.0280 - 1s/epoch - 1s/step\n",
            "Epoch 1973/3000\n",
            "1/1 - 1s - loss: 0.0275 - val_loss: 0.0321 - 1s/epoch - 1s/step\n",
            "Epoch 1974/3000\n",
            "1/1 - 1s - loss: 0.0295 - val_loss: 0.0279 - 1s/epoch - 1s/step\n",
            "Epoch 1975/3000\n",
            "1/1 - 1s - loss: 0.0281 - val_loss: 0.0308 - 1s/epoch - 1s/step\n",
            "Epoch 1976/3000\n",
            "1/1 - 1s - loss: 0.0287 - val_loss: 0.0266 - 1s/epoch - 1s/step\n",
            "Epoch 1977/3000\n",
            "1/1 - 1s - loss: 0.0258 - val_loss: 0.0261 - 1s/epoch - 1s/step\n",
            "Epoch 1978/3000\n",
            "1/1 - 1s - loss: 0.0245 - val_loss: 0.0259 - 1s/epoch - 1s/step\n",
            "Epoch 1979/3000\n",
            "1/1 - 1s - loss: 0.0248 - val_loss: 0.0250 - 1s/epoch - 1s/step\n",
            "Epoch 1980/3000\n",
            "1/1 - 1s - loss: 0.0238 - val_loss: 0.0261 - 1s/epoch - 1s/step\n",
            "Epoch 1981/3000\n",
            "1/1 - 1s - loss: 0.0243 - val_loss: 0.0260 - 1s/epoch - 1s/step\n",
            "Epoch 1982/3000\n",
            "1/1 - 1s - loss: 0.0251 - val_loss: 0.0272 - 1s/epoch - 1s/step\n",
            "Epoch 1983/3000\n",
            "1/1 - 1s - loss: 0.0251 - val_loss: 0.0270 - 1s/epoch - 1s/step\n",
            "Epoch 1984/3000\n",
            "1/1 - 1s - loss: 0.0261 - val_loss: 0.0310 - 1s/epoch - 1s/step\n",
            "Epoch 1985/3000\n",
            "1/1 - 1s - loss: 0.0283 - val_loss: 0.0293 - 1s/epoch - 1s/step\n",
            "Epoch 1986/3000\n",
            "1/1 - 1s - loss: 0.0291 - val_loss: 0.0386 - 1s/epoch - 1s/step\n",
            "Epoch 1987/3000\n",
            "1/1 - 1s - loss: 0.0349 - val_loss: 0.0340 - 1s/epoch - 1s/step\n",
            "Epoch 1988/3000\n",
            "1/1 - 1s - loss: 0.0343 - val_loss: 0.0460 - 1s/epoch - 1s/step\n",
            "Epoch 1989/3000\n",
            "1/1 - 1s - loss: 0.0416 - val_loss: 0.0365 - 1s/epoch - 1s/step\n",
            "Epoch 1990/3000\n",
            "1/1 - 1s - loss: 0.0365 - val_loss: 0.0418 - 1s/epoch - 1s/step\n",
            "Epoch 1991/3000\n",
            "1/1 - 1s - loss: 0.0374 - val_loss: 0.0298 - 1s/epoch - 1s/step\n",
            "Epoch 1992/3000\n",
            "1/1 - 1s - loss: 0.0287 - val_loss: 0.0273 - 1s/epoch - 1s/step\n",
            "Epoch 1993/3000\n",
            "1/1 - 1s - loss: 0.0245 - val_loss: 0.0264 - 1s/epoch - 1s/step\n",
            "Epoch 1994/3000\n",
            "1/1 - 1s - loss: 0.0241 - val_loss: 0.0281 - 1s/epoch - 1s/step\n",
            "Epoch 1995/3000\n",
            "1/1 - 1s - loss: 0.0271 - val_loss: 0.0360 - 1s/epoch - 1s/step\n",
            "Epoch 1996/3000\n",
            "1/1 - 1s - loss: 0.0327 - val_loss: 0.0316 - 1s/epoch - 1s/step\n",
            "Epoch 1997/3000\n",
            "1/1 - 1s - loss: 0.0323 - val_loss: 0.0367 - 1s/epoch - 1s/step\n",
            "Epoch 1998/3000\n",
            "1/1 - 1s - loss: 0.0332 - val_loss: 0.0276 - 1s/epoch - 1s/step\n",
            "Epoch 1999/3000\n",
            "1/1 - 1s - loss: 0.0275 - val_loss: 0.0263 - 1s/epoch - 1s/step\n",
            "Epoch 2000/3000\n",
            "1/1 - 1s - loss: 0.0243 - val_loss: 0.0243 - 1s/epoch - 1s/step\n",
            "Epoch 2001/3000\n",
            "1/1 - 1s - loss: 0.0230 - val_loss: 0.0244 - 1s/epoch - 1s/step\n",
            "Epoch 2002/3000\n",
            "1/1 - 1s - loss: 0.0232 - val_loss: 0.0266 - 1s/epoch - 1s/step\n",
            "Epoch 2003/3000\n",
            "1/1 - 1s - loss: 0.0245 - val_loss: 0.0268 - 1s/epoch - 1s/step\n",
            "Epoch 2004/3000\n",
            "1/1 - 1s - loss: 0.0267 - val_loss: 0.0347 - 1s/epoch - 1s/step\n",
            "Epoch 2005/3000\n",
            "1/1 - 1s - loss: 0.0318 - val_loss: 0.0341 - 1s/epoch - 1s/step\n",
            "Epoch 2006/3000\n",
            "1/1 - 1s - loss: 0.0347 - val_loss: 0.0605 - 1s/epoch - 1s/step\n",
            "Epoch 2007/3000\n",
            "1/1 - 1s - loss: 0.0560 - val_loss: 0.0558 - 1s/epoch - 1s/step\n",
            "Epoch 2008/3000\n",
            "1/1 - 1s - loss: 0.0587 - val_loss: 0.1268 - 1s/epoch - 1s/step\n",
            "Epoch 2009/3000\n",
            "1/1 - 1s - loss: 0.1157 - val_loss: 0.0670 - 1s/epoch - 1s/step\n",
            "Epoch 2010/3000\n",
            "1/1 - 1s - loss: 0.0734 - val_loss: 0.0568 - 1s/epoch - 1s/step\n",
            "Epoch 2011/3000\n",
            "1/1 - 1s - loss: 0.0495 - val_loss: 0.0284 - 1s/epoch - 1s/step\n",
            "Epoch 2012/3000\n",
            "1/1 - 1s - loss: 0.0253 - val_loss: 0.0444 - 1s/epoch - 1s/step\n",
            "Epoch 2013/3000\n",
            "1/1 - 1s - loss: 0.0427 - val_loss: 0.0897 - 1s/epoch - 1s/step\n",
            "Epoch 2014/3000\n",
            "1/1 - 1s - loss: 0.0857 - val_loss: 0.0649 - 1s/epoch - 1s/step\n",
            "Epoch 2015/3000\n",
            "1/1 - 1s - loss: 0.0689 - val_loss: 0.0561 - 1s/epoch - 1s/step\n",
            "Epoch 2016/3000\n",
            "1/1 - 1s - loss: 0.0480 - val_loss: 0.0309 - 1s/epoch - 1s/step\n",
            "Epoch 2017/3000\n",
            "1/1 - 1s - loss: 0.0280 - val_loss: 0.0474 - 1s/epoch - 1s/step\n",
            "Epoch 2018/3000\n",
            "1/1 - 1s - loss: 0.0485 - val_loss: 0.0940 - 1s/epoch - 1s/step\n",
            "Epoch 2019/3000\n",
            "1/1 - 1s - loss: 0.0933 - val_loss: 0.0701 - 1s/epoch - 1s/step\n",
            "Epoch 2020/3000\n",
            "1/1 - 1s - loss: 0.0728 - val_loss: 0.1111 - 1s/epoch - 1s/step\n",
            "Epoch 2021/3000\n",
            "1/1 - 1s - loss: 0.0987 - val_loss: 0.0440 - 1s/epoch - 1s/step\n",
            "Epoch 2022/3000\n",
            "1/1 - 1s - loss: 0.0513 - val_loss: 0.0303 - 1s/epoch - 1s/step\n",
            "Epoch 2023/3000\n",
            "1/1 - 1s - loss: 0.0306 - val_loss: 0.0668 - 1s/epoch - 1s/step\n",
            "Epoch 2024/3000\n",
            "1/1 - 1s - loss: 0.0684 - val_loss: 0.1071 - 1s/epoch - 1s/step\n",
            "Epoch 2025/3000\n",
            "1/1 - 1s - loss: 0.1065 - val_loss: 0.4033 - 1s/epoch - 1s/step\n",
            "Epoch 2026/3000\n",
            "1/1 - 1s - loss: 0.3760 - val_loss: 0.1683 - 1s/epoch - 1s/step\n",
            "Epoch 2027/3000\n",
            "1/1 - 1s - loss: 0.2147 - val_loss: 0.0589 - 1s/epoch - 1s/step\n",
            "Epoch 2028/3000\n",
            "1/1 - 1s - loss: 0.0604 - val_loss: 0.1568 - 1s/epoch - 1s/step\n",
            "Epoch 2029/3000\n",
            "1/1 - 1s - loss: 0.1534 - val_loss: 0.2873 - 1s/epoch - 1s/step\n",
            "Epoch 2030/3000\n",
            "1/1 - 1s - loss: 0.2842 - val_loss: 1.1586 - 1s/epoch - 1s/step\n",
            "Epoch 2031/3000\n",
            "1/1 - 1s - loss: 1.1292 - val_loss: 0.3109 - 1s/epoch - 1s/step\n",
            "Epoch 2032/3000\n",
            "1/1 - 1s - loss: 0.3878 - val_loss: 0.3623 - 1s/epoch - 1s/step\n",
            "Epoch 2033/3000\n",
            "1/1 - 1s - loss: 0.4453 - val_loss: 0.8609 - 1s/epoch - 1s/step\n",
            "Epoch 2034/3000\n",
            "1/1 - 1s - loss: 0.8547 - val_loss: 0.2444 - 1s/epoch - 1s/step\n",
            "Epoch 2035/3000\n",
            "1/1 - 1s - loss: 0.2525 - val_loss: 0.6686 - 1s/epoch - 1s/step\n",
            "Epoch 2036/3000\n",
            "1/1 - 1s - loss: 0.6689 - val_loss: 2.4021 - 1s/epoch - 1s/step\n",
            "Epoch 2037/3000\n",
            "1/1 - 1s - loss: 2.4192 - val_loss: 0.7771 - 1s/epoch - 1s/step\n",
            "Epoch 2038/3000\n",
            "1/1 - 1s - loss: 0.7922 - val_loss: 1.4930 - 1s/epoch - 1s/step\n",
            "Epoch 2039/3000\n",
            "1/1 - 1s - loss: 1.8150 - val_loss: 1.6856 - 1s/epoch - 1s/step\n",
            "Epoch 2040/3000\n",
            "1/1 - 1s - loss: 1.6414 - val_loss: 1.1003 - 1s/epoch - 1s/step\n",
            "Epoch 2041/3000\n",
            "1/1 - 1s - loss: 1.1296 - val_loss: 2.8384 - 1s/epoch - 1s/step\n",
            "Epoch 2042/3000\n",
            "1/1 - 1s - loss: 2.8292 - val_loss: 13.6834 - 1s/epoch - 1s/step\n",
            "Epoch 2043/3000\n",
            "1/1 - 1s - loss: 14.2743 - val_loss: 6.8337 - 1s/epoch - 1s/step\n",
            "Epoch 2044/3000\n",
            "1/1 - 1s - loss: 6.6008 - val_loss: 9.9116 - 1s/epoch - 1s/step\n",
            "Epoch 2045/3000\n",
            "1/1 - 1s - loss: 11.8546 - val_loss: 7.8105 - 1s/epoch - 1s/step\n",
            "Epoch 2046/3000\n",
            "1/1 - 1s - loss: 7.3429 - val_loss: 3.4535 - 1s/epoch - 1s/step\n",
            "Epoch 2047/3000\n",
            "1/1 - 1s - loss: 3.7097 - val_loss: 6.6332 - 1s/epoch - 1s/step\n",
            "Epoch 2048/3000\n",
            "1/1 - 1s - loss: 7.1131 - val_loss: 4.5506 - 1s/epoch - 1s/step\n",
            "Epoch 2049/3000\n",
            "1/1 - 1s - loss: 5.1201 - val_loss: 6.2690 - 1s/epoch - 1s/step\n",
            "Epoch 2050/3000\n",
            "1/1 - 1s - loss: 7.6229 - val_loss: 2.8322 - 1s/epoch - 1s/step\n",
            "Epoch 2051/3000\n",
            "1/1 - 1s - loss: 3.0291 - val_loss: 5.3097 - 1s/epoch - 1s/step\n",
            "Epoch 2052/3000\n",
            "1/1 - 1s - loss: 5.5728 - val_loss: 3.5444 - 1s/epoch - 1s/step\n",
            "Epoch 2053/3000\n",
            "1/1 - 1s - loss: 3.4581 - val_loss: 3.9367 - 1s/epoch - 1s/step\n",
            "Epoch 2054/3000\n",
            "1/1 - 1s - loss: 3.8673 - val_loss: 3.9552 - 1s/epoch - 1s/step\n",
            "Epoch 2055/3000\n",
            "1/1 - 1s - loss: 3.9298 - val_loss: 1.8048 - 1s/epoch - 1s/step\n",
            "Epoch 2056/3000\n",
            "1/1 - 1s - loss: 1.7968 - val_loss: 3.1506 - 1s/epoch - 1s/step\n",
            "Epoch 2057/3000\n",
            "1/1 - 1s - loss: 3.2744 - val_loss: 2.1419 - 1s/epoch - 1s/step\n",
            "Epoch 2058/3000\n",
            "1/1 - 1s - loss: 2.4783 - val_loss: 1.8401 - 1s/epoch - 1s/step\n",
            "Epoch 2059/3000\n",
            "1/1 - 1s - loss: 2.2472 - val_loss: 2.2302 - 1s/epoch - 1s/step\n",
            "Epoch 2060/3000\n",
            "1/1 - 1s - loss: 2.2351 - val_loss: 0.6286 - 1s/epoch - 1s/step\n",
            "Epoch 2061/3000\n",
            "1/1 - 1s - loss: 0.7537 - val_loss: 2.0027 - 1s/epoch - 1s/step\n",
            "Epoch 2062/3000\n",
            "1/1 - 1s - loss: 2.1003 - val_loss: 1.0318 - 1s/epoch - 1s/step\n",
            "Epoch 2063/3000\n",
            "1/1 - 1s - loss: 1.1217 - val_loss: 0.9387 - 1s/epoch - 1s/step\n",
            "Epoch 2064/3000\n",
            "1/1 - 1s - loss: 1.0829 - val_loss: 1.0441 - 1s/epoch - 1s/step\n",
            "Epoch 2065/3000\n",
            "1/1 - 1s - loss: 1.0837 - val_loss: 0.6690 - 1s/epoch - 1s/step\n",
            "Epoch 2066/3000\n",
            "1/1 - 1s - loss: 0.7939 - val_loss: 1.2717 - 1s/epoch - 1s/step\n",
            "Epoch 2067/3000\n",
            "1/1 - 1s - loss: 1.3805 - val_loss: 0.8698 - 1s/epoch - 1s/step\n",
            "Epoch 2068/3000\n",
            "1/1 - 1s - loss: 0.8707 - val_loss: 0.7575 - 1s/epoch - 1s/step\n",
            "Epoch 2069/3000\n",
            "1/1 - 1s - loss: 0.8412 - val_loss: 0.7954 - 1s/epoch - 1s/step\n",
            "Epoch 2070/3000\n",
            "1/1 - 1s - loss: 0.8839 - val_loss: 0.5326 - 1s/epoch - 1s/step\n",
            "Epoch 2071/3000\n",
            "1/1 - 1s - loss: 0.7079 - val_loss: 0.6840 - 1s/epoch - 1s/step\n",
            "Epoch 2072/3000\n",
            "1/1 - 1s - loss: 0.8029 - val_loss: 0.4153 - 1s/epoch - 1s/step\n",
            "Epoch 2073/3000\n",
            "1/1 - 1s - loss: 0.5031 - val_loss: 0.4775 - 1s/epoch - 1s/step\n",
            "Epoch 2074/3000\n",
            "1/1 - 1s - loss: 0.5462 - val_loss: 0.9345 - 1s/epoch - 1s/step\n",
            "Epoch 2075/3000\n",
            "1/1 - 1s - loss: 0.9116 - val_loss: 0.6070 - 1s/epoch - 1s/step\n",
            "Epoch 2076/3000\n",
            "1/1 - 1s - loss: 0.7056 - val_loss: 0.7550 - 1s/epoch - 1s/step\n",
            "Epoch 2077/3000\n",
            "1/1 - 1s - loss: 0.7664 - val_loss: 0.7155 - 1s/epoch - 1s/step\n",
            "Epoch 2078/3000\n",
            "1/1 - 1s - loss: 0.7575 - val_loss: 0.6540 - 1s/epoch - 1s/step\n",
            "Epoch 2079/3000\n",
            "1/1 - 1s - loss: 0.6761 - val_loss: 0.5794 - 1s/epoch - 1s/step\n",
            "Epoch 2080/3000\n",
            "1/1 - 1s - loss: 0.6172 - val_loss: 0.2164 - 1s/epoch - 1s/step\n",
            "Epoch 2081/3000\n",
            "1/1 - 1s - loss: 0.3297 - val_loss: 0.7023 - 1s/epoch - 1s/step\n",
            "Epoch 2082/3000\n",
            "1/1 - 1s - loss: 0.7904 - val_loss: 0.2292 - 1s/epoch - 1s/step\n",
            "Epoch 2083/3000\n",
            "1/1 - 1s - loss: 0.3717 - val_loss: 0.3751 - 1s/epoch - 1s/step\n",
            "Epoch 2084/3000\n",
            "1/1 - 1s - loss: 0.4899 - val_loss: 0.3101 - 1s/epoch - 1s/step\n",
            "Epoch 2085/3000\n",
            "1/1 - 1s - loss: 0.3448 - val_loss: 0.3866 - 1s/epoch - 1s/step\n",
            "Epoch 2086/3000\n",
            "1/1 - 1s - loss: 0.4173 - val_loss: 0.3351 - 1s/epoch - 1s/step\n",
            "Epoch 2087/3000\n",
            "1/1 - 1s - loss: 0.3416 - val_loss: 0.3512 - 1s/epoch - 1s/step\n",
            "Epoch 2088/3000\n",
            "1/1 - 1s - loss: 0.3798 - val_loss: 0.1185 - 1s/epoch - 1s/step\n",
            "Epoch 2089/3000\n",
            "1/1 - 1s - loss: 0.1691 - val_loss: 0.3926 - 1s/epoch - 1s/step\n",
            "Epoch 2090/3000\n",
            "1/1 - 1s - loss: 0.4289 - val_loss: 0.2847 - 1s/epoch - 1s/step\n",
            "Epoch 2091/3000\n",
            "1/1 - 1s - loss: 0.3624 - val_loss: 0.2091 - 1s/epoch - 1s/step\n",
            "Epoch 2092/3000\n",
            "1/1 - 1s - loss: 0.2497 - val_loss: 0.3483 - 1s/epoch - 1s/step\n",
            "Epoch 2093/3000\n",
            "1/1 - 1s - loss: 0.3778 - val_loss: 0.1212 - 1s/epoch - 1s/step\n",
            "Epoch 2094/3000\n",
            "1/1 - 1s - loss: 0.1559 - val_loss: 0.3295 - 1s/epoch - 1s/step\n",
            "Epoch 2095/3000\n",
            "1/1 - 1s - loss: 0.3498 - val_loss: 0.1034 - 1s/epoch - 1s/step\n",
            "Epoch 2096/3000\n",
            "1/1 - 1s - loss: 0.1247 - val_loss: 0.3110 - 1s/epoch - 1s/step\n",
            "Epoch 2097/3000\n",
            "1/1 - 1s - loss: 0.3111 - val_loss: 0.2187 - 1s/epoch - 1s/step\n",
            "Epoch 2098/3000\n",
            "1/1 - 1s - loss: 0.2449 - val_loss: 0.1705 - 1s/epoch - 1s/step\n",
            "Epoch 2099/3000\n",
            "1/1 - 1s - loss: 0.1929 - val_loss: 0.2422 - 1s/epoch - 1s/step\n",
            "Epoch 2100/3000\n",
            "1/1 - 1s - loss: 0.2670 - val_loss: 0.0982 - 1s/epoch - 1s/step\n",
            "Epoch 2101/3000\n",
            "1/1 - 1s - loss: 0.1239 - val_loss: 0.2024 - 1s/epoch - 1s/step\n",
            "Epoch 2102/3000\n",
            "1/1 - 1s - loss: 0.2103 - val_loss: 0.1112 - 1s/epoch - 1s/step\n",
            "Epoch 2103/3000\n",
            "1/1 - 1s - loss: 0.1218 - val_loss: 0.1770 - 1s/epoch - 1s/step\n",
            "Epoch 2104/3000\n",
            "1/1 - 1s - loss: 0.1808 - val_loss: 0.1236 - 1s/epoch - 1s/step\n",
            "Epoch 2105/3000\n",
            "1/1 - 1s - loss: 0.1368 - val_loss: 0.1275 - 1s/epoch - 1s/step\n",
            "Epoch 2106/3000\n",
            "1/1 - 1s - loss: 0.1418 - val_loss: 0.1270 - 1s/epoch - 1s/step\n",
            "Epoch 2107/3000\n",
            "1/1 - 1s - loss: 0.1347 - val_loss: 0.0972 - 1s/epoch - 1s/step\n",
            "Epoch 2108/3000\n",
            "1/1 - 1s - loss: 0.1083 - val_loss: 0.1199 - 1s/epoch - 1s/step\n",
            "Epoch 2109/3000\n",
            "1/1 - 1s - loss: 0.1299 - val_loss: 0.0791 - 1s/epoch - 1s/step\n",
            "Epoch 2110/3000\n",
            "1/1 - 1s - loss: 0.0950 - val_loss: 0.1148 - 1s/epoch - 1s/step\n",
            "Epoch 2111/3000\n",
            "1/1 - 1s - loss: 0.1319 - val_loss: 0.0739 - 1s/epoch - 1s/step\n",
            "Epoch 2112/3000\n",
            "1/1 - 1s - loss: 0.0892 - val_loss: 0.0957 - 1s/epoch - 1s/step\n",
            "Epoch 2113/3000\n",
            "1/1 - 1s - loss: 0.1116 - val_loss: 0.0792 - 1s/epoch - 1s/step\n",
            "Epoch 2114/3000\n",
            "1/1 - 1s - loss: 0.0910 - val_loss: 0.0721 - 1s/epoch - 1s/step\n",
            "Epoch 2115/3000\n",
            "1/1 - 1s - loss: 0.0838 - val_loss: 0.0872 - 1s/epoch - 1s/step\n",
            "Epoch 2116/3000\n",
            "1/1 - 1s - loss: 0.0970 - val_loss: 0.0640 - 1s/epoch - 1s/step\n",
            "Epoch 2117/3000\n",
            "1/1 - 1s - loss: 0.0731 - val_loss: 0.0866 - 1s/epoch - 1s/step\n",
            "Epoch 2118/3000\n",
            "1/1 - 1s - loss: 0.0952 - val_loss: 0.0639 - 1s/epoch - 1s/step\n",
            "Epoch 2119/3000\n",
            "1/1 - 1s - loss: 0.0729 - val_loss: 0.0692 - 1s/epoch - 1s/step\n",
            "Epoch 2120/3000\n",
            "1/1 - 1s - loss: 0.0786 - val_loss: 0.0750 - 1s/epoch - 1s/step\n",
            "Epoch 2121/3000\n",
            "1/1 - 1s - loss: 0.0830 - val_loss: 0.0583 - 1s/epoch - 1s/step\n",
            "Epoch 2122/3000\n",
            "1/1 - 1s - loss: 0.0668 - val_loss: 0.0671 - 1s/epoch - 1s/step\n",
            "Epoch 2123/3000\n",
            "1/1 - 1s - loss: 0.0751 - val_loss: 0.0591 - 1s/epoch - 1s/step\n",
            "Epoch 2124/3000\n",
            "1/1 - 1s - loss: 0.0681 - val_loss: 0.0574 - 1s/epoch - 1s/step\n",
            "Epoch 2125/3000\n",
            "1/1 - 1s - loss: 0.0654 - val_loss: 0.0621 - 1s/epoch - 1s/step\n",
            "Epoch 2126/3000\n",
            "1/1 - 1s - loss: 0.0689 - val_loss: 0.0560 - 1s/epoch - 1s/step\n",
            "Epoch 2127/3000\n",
            "1/1 - 1s - loss: 0.0618 - val_loss: 0.0594 - 1s/epoch - 1s/step\n",
            "Epoch 2128/3000\n",
            "1/1 - 1s - loss: 0.0649 - val_loss: 0.0576 - 1s/epoch - 1s/step\n",
            "Epoch 2129/3000\n",
            "1/1 - 1s - loss: 0.0634 - val_loss: 0.0532 - 1s/epoch - 1s/step\n",
            "Epoch 2130/3000\n",
            "1/1 - 1s - loss: 0.0593 - val_loss: 0.0558 - 1s/epoch - 1s/step\n",
            "Epoch 2131/3000\n",
            "1/1 - 1s - loss: 0.0626 - val_loss: 0.0539 - 1s/epoch - 1s/step\n",
            "Epoch 2132/3000\n",
            "1/1 - 1s - loss: 0.0594 - val_loss: 0.0522 - 1s/epoch - 1s/step\n",
            "Epoch 2133/3000\n",
            "1/1 - 1s - loss: 0.0577 - val_loss: 0.0543 - 1s/epoch - 1s/step\n",
            "Epoch 2134/3000\n",
            "1/1 - 1s - loss: 0.0601 - val_loss: 0.0511 - 1s/epoch - 1s/step\n",
            "Epoch 2135/3000\n",
            "1/1 - 1s - loss: 0.0564 - val_loss: 0.0506 - 1s/epoch - 1s/step\n",
            "Epoch 2136/3000\n",
            "1/1 - 1s - loss: 0.0554 - val_loss: 0.0520 - 1s/epoch - 1s/step\n",
            "Epoch 2137/3000\n",
            "1/1 - 1s - loss: 0.0568 - val_loss: 0.0493 - 1s/epoch - 1s/step\n",
            "Epoch 2138/3000\n",
            "1/1 - 1s - loss: 0.0534 - val_loss: 0.0506 - 1s/epoch - 1s/step\n",
            "Epoch 2139/3000\n",
            "1/1 - 1s - loss: 0.0543 - val_loss: 0.0494 - 1s/epoch - 1s/step\n",
            "Epoch 2140/3000\n",
            "1/1 - 1s - loss: 0.0535 - val_loss: 0.0477 - 1s/epoch - 1s/step\n",
            "Epoch 2141/3000\n",
            "1/1 - 1s - loss: 0.0513 - val_loss: 0.0492 - 1s/epoch - 1s/step\n",
            "Epoch 2142/3000\n",
            "1/1 - 1s - loss: 0.0525 - val_loss: 0.0470 - 1s/epoch - 1s/step\n",
            "Epoch 2143/3000\n",
            "1/1 - 1s - loss: 0.0506 - val_loss: 0.0466 - 1s/epoch - 1s/step\n",
            "Epoch 2144/3000\n",
            "1/1 - 1s - loss: 0.0504 - val_loss: 0.0474 - 1s/epoch - 1s/step\n",
            "Epoch 2145/3000\n",
            "1/1 - 1s - loss: 0.0506 - val_loss: 0.0457 - 1s/epoch - 1s/step\n",
            "Epoch 2146/3000\n",
            "1/1 - 1s - loss: 0.0489 - val_loss: 0.0463 - 1s/epoch - 1s/step\n",
            "Epoch 2147/3000\n",
            "1/1 - 1s - loss: 0.0494 - val_loss: 0.0462 - 1s/epoch - 1s/step\n",
            "Epoch 2148/3000\n",
            "1/1 - 1s - loss: 0.0488 - val_loss: 0.0451 - 1s/epoch - 1s/step\n",
            "Epoch 2149/3000\n",
            "1/1 - 1s - loss: 0.0478 - val_loss: 0.0451 - 1s/epoch - 1s/step\n",
            "Epoch 2150/3000\n",
            "1/1 - 1s - loss: 0.0481 - val_loss: 0.0449 - 1s/epoch - 1s/step\n",
            "Epoch 2151/3000\n",
            "1/1 - 1s - loss: 0.0475 - val_loss: 0.0439 - 1s/epoch - 1s/step\n",
            "Epoch 2152/3000\n",
            "1/1 - 1s - loss: 0.0467 - val_loss: 0.0436 - 1s/epoch - 1s/step\n",
            "Epoch 2153/3000\n",
            "1/1 - 1s - loss: 0.0469 - val_loss: 0.0435 - 1s/epoch - 1s/step\n",
            "Epoch 2154/3000\n",
            "1/1 - 1s - loss: 0.0463 - val_loss: 0.0425 - 1s/epoch - 1s/step\n",
            "Epoch 2155/3000\n",
            "1/1 - 1s - loss: 0.0455 - val_loss: 0.0425 - 1s/epoch - 1s/step\n",
            "Epoch 2156/3000\n",
            "1/1 - 1s - loss: 0.0458 - val_loss: 0.0425 - 1s/epoch - 1s/step\n",
            "Epoch 2157/3000\n",
            "1/1 - 1s - loss: 0.0453 - val_loss: 0.0416 - 1s/epoch - 1s/step\n",
            "Epoch 2158/3000\n",
            "1/1 - 1s - loss: 0.0445 - val_loss: 0.0416 - 1s/epoch - 1s/step\n",
            "Epoch 2159/3000\n",
            "1/1 - 1s - loss: 0.0447 - val_loss: 0.0417 - 1s/epoch - 1s/step\n",
            "Epoch 2160/3000\n",
            "1/1 - 1s - loss: 0.0442 - val_loss: 0.0412 - 1s/epoch - 1s/step\n",
            "Epoch 2161/3000\n",
            "1/1 - 1s - loss: 0.0437 - val_loss: 0.0411 - 1s/epoch - 1s/step\n",
            "Epoch 2162/3000\n",
            "1/1 - 1s - loss: 0.0438 - val_loss: 0.0410 - 1s/epoch - 1s/step\n",
            "Epoch 2163/3000\n",
            "1/1 - 1s - loss: 0.0433 - val_loss: 0.0404 - 1s/epoch - 1s/step\n",
            "Epoch 2164/3000\n",
            "1/1 - 1s - loss: 0.0428 - val_loss: 0.0402 - 1s/epoch - 1s/step\n",
            "Epoch 2165/3000\n",
            "1/1 - 1s - loss: 0.0429 - val_loss: 0.0403 - 1s/epoch - 1s/step\n",
            "Epoch 2166/3000\n",
            "1/1 - 1s - loss: 0.0425 - val_loss: 0.0398 - 1s/epoch - 1s/step\n",
            "Epoch 2167/3000\n",
            "1/1 - 1s - loss: 0.0420 - val_loss: 0.0396 - 1s/epoch - 1s/step\n",
            "Epoch 2168/3000\n",
            "1/1 - 1s - loss: 0.0421 - val_loss: 0.0396 - 1s/epoch - 1s/step\n",
            "Epoch 2169/3000\n",
            "1/1 - 1s - loss: 0.0417 - val_loss: 0.0392 - 1s/epoch - 1s/step\n",
            "Epoch 2170/3000\n",
            "1/1 - 1s - loss: 0.0413 - val_loss: 0.0390 - 1s/epoch - 1s/step\n",
            "Epoch 2171/3000\n",
            "1/1 - 1s - loss: 0.0413 - val_loss: 0.0390 - 1s/epoch - 1s/step\n",
            "Epoch 2172/3000\n",
            "1/1 - 1s - loss: 0.0410 - val_loss: 0.0385 - 1s/epoch - 1s/step\n",
            "Epoch 2173/3000\n",
            "1/1 - 1s - loss: 0.0406 - val_loss: 0.0383 - 1s/epoch - 1s/step\n",
            "Epoch 2174/3000\n",
            "1/1 - 1s - loss: 0.0406 - val_loss: 0.0384 - 1s/epoch - 1s/step\n",
            "Epoch 2175/3000\n",
            "1/1 - 1s - loss: 0.0403 - val_loss: 0.0379 - 1s/epoch - 1s/step\n",
            "Epoch 2176/3000\n",
            "1/1 - 1s - loss: 0.0400 - val_loss: 0.0376 - 1s/epoch - 1s/step\n",
            "Epoch 2177/3000\n",
            "1/1 - 1s - loss: 0.0399 - val_loss: 0.0378 - 1s/epoch - 1s/step\n",
            "Epoch 2178/3000\n",
            "1/1 - 1s - loss: 0.0397 - val_loss: 0.0373 - 1s/epoch - 1s/step\n",
            "Epoch 2179/3000\n",
            "1/1 - 1s - loss: 0.0394 - val_loss: 0.0372 - 1s/epoch - 1s/step\n",
            "Epoch 2180/3000\n",
            "1/1 - 1s - loss: 0.0392 - val_loss: 0.0373 - 1s/epoch - 1s/step\n",
            "Epoch 2181/3000\n",
            "1/1 - 1s - loss: 0.0391 - val_loss: 0.0368 - 1s/epoch - 1s/step\n",
            "Epoch 2182/3000\n",
            "1/1 - 1s - loss: 0.0388 - val_loss: 0.0367 - 1s/epoch - 1s/step\n",
            "Epoch 2183/3000\n",
            "1/1 - 1s - loss: 0.0387 - val_loss: 0.0368 - 1s/epoch - 1s/step\n",
            "Epoch 2184/3000\n",
            "1/1 - 1s - loss: 0.0385 - val_loss: 0.0364 - 1s/epoch - 1s/step\n",
            "Epoch 2185/3000\n",
            "1/1 - 1s - loss: 0.0383 - val_loss: 0.0362 - 1s/epoch - 1s/step\n",
            "Epoch 2186/3000\n",
            "1/1 - 1s - loss: 0.0381 - val_loss: 0.0363 - 1s/epoch - 1s/step\n",
            "Epoch 2187/3000\n",
            "1/1 - 1s - loss: 0.0380 - val_loss: 0.0359 - 1s/epoch - 1s/step\n",
            "Epoch 2188/3000\n",
            "1/1 - 1s - loss: 0.0378 - val_loss: 0.0359 - 1s/epoch - 1s/step\n",
            "Epoch 2189/3000\n",
            "1/1 - 1s - loss: 0.0376 - val_loss: 0.0359 - 1s/epoch - 1s/step\n",
            "Epoch 2190/3000\n",
            "1/1 - 1s - loss: 0.0374 - val_loss: 0.0356 - 1s/epoch - 1s/step\n",
            "Epoch 2191/3000\n",
            "1/1 - 1s - loss: 0.0373 - val_loss: 0.0354 - 1s/epoch - 1s/step\n",
            "Epoch 2192/3000\n",
            "1/1 - 1s - loss: 0.0371 - val_loss: 0.0354 - 1s/epoch - 1s/step\n",
            "Epoch 2193/3000\n",
            "1/1 - 1s - loss: 0.0370 - val_loss: 0.0351 - 1s/epoch - 1s/step\n",
            "Epoch 2194/3000\n",
            "1/1 - 1s - loss: 0.0368 - val_loss: 0.0350 - 1s/epoch - 1s/step\n",
            "Epoch 2195/3000\n",
            "1/1 - 1s - loss: 0.0366 - val_loss: 0.0349 - 1s/epoch - 1s/step\n",
            "Epoch 2196/3000\n",
            "1/1 - 1s - loss: 0.0365 - val_loss: 0.0347 - 1s/epoch - 1s/step\n",
            "Epoch 2197/3000\n",
            "1/1 - 1s - loss: 0.0364 - val_loss: 0.0346 - 1s/epoch - 1s/step\n",
            "Epoch 2198/3000\n",
            "1/1 - 1s - loss: 0.0362 - val_loss: 0.0345 - 1s/epoch - 1s/step\n",
            "Epoch 2199/3000\n",
            "1/1 - 1s - loss: 0.0361 - val_loss: 0.0343 - 1s/epoch - 1s/step\n",
            "Epoch 2200/3000\n",
            "1/1 - 1s - loss: 0.0359 - val_loss: 0.0343 - 1s/epoch - 1s/step\n",
            "Epoch 2201/3000\n",
            "1/1 - 1s - loss: 0.0358 - val_loss: 0.0341 - 1s/epoch - 1s/step\n",
            "Epoch 2202/3000\n",
            "1/1 - 1s - loss: 0.0357 - val_loss: 0.0340 - 1s/epoch - 1s/step\n",
            "Epoch 2203/3000\n",
            "1/1 - 1s - loss: 0.0355 - val_loss: 0.0340 - 1s/epoch - 1s/step\n",
            "Epoch 2204/3000\n",
            "1/1 - 1s - loss: 0.0354 - val_loss: 0.0338 - 1s/epoch - 1s/step\n",
            "Epoch 2205/3000\n",
            "1/1 - 1s - loss: 0.0353 - val_loss: 0.0337 - 1s/epoch - 1s/step\n",
            "Epoch 2206/3000\n",
            "1/1 - 1s - loss: 0.0351 - val_loss: 0.0336 - 1s/epoch - 1s/step\n",
            "Epoch 2207/3000\n",
            "1/1 - 1s - loss: 0.0350 - val_loss: 0.0335 - 1s/epoch - 1s/step\n",
            "Epoch 2208/3000\n",
            "1/1 - 1s - loss: 0.0349 - val_loss: 0.0334 - 1s/epoch - 1s/step\n",
            "Epoch 2209/3000\n",
            "1/1 - 1s - loss: 0.0348 - val_loss: 0.0333 - 1s/epoch - 1s/step\n",
            "Epoch 2210/3000\n",
            "1/1 - 1s - loss: 0.0346 - val_loss: 0.0332 - 1s/epoch - 1s/step\n",
            "Epoch 2211/3000\n",
            "1/1 - 1s - loss: 0.0345 - val_loss: 0.0331 - 1s/epoch - 1s/step\n",
            "Epoch 2212/3000\n",
            "1/1 - 1s - loss: 0.0344 - val_loss: 0.0330 - 1s/epoch - 1s/step\n",
            "Epoch 2213/3000\n",
            "1/1 - 1s - loss: 0.0343 - val_loss: 0.0329 - 1s/epoch - 1s/step\n",
            "Epoch 2214/3000\n",
            "1/1 - 1s - loss: 0.0342 - val_loss: 0.0329 - 1s/epoch - 1s/step\n",
            "Epoch 2215/3000\n",
            "1/1 - 1s - loss: 0.0341 - val_loss: 0.0327 - 1s/epoch - 1s/step\n",
            "Epoch 2216/3000\n",
            "1/1 - 1s - loss: 0.0339 - val_loss: 0.0327 - 1s/epoch - 1s/step\n",
            "Epoch 2217/3000\n",
            "1/1 - 1s - loss: 0.0338 - val_loss: 0.0326 - 1s/epoch - 1s/step\n",
            "Epoch 2218/3000\n",
            "1/1 - 1s - loss: 0.0337 - val_loss: 0.0324 - 1s/epoch - 1s/step\n",
            "Epoch 2219/3000\n",
            "1/1 - 1s - loss: 0.0336 - val_loss: 0.0324 - 1s/epoch - 1s/step\n",
            "Epoch 2220/3000\n",
            "1/1 - 1s - loss: 0.0335 - val_loss: 0.0323 - 1s/epoch - 1s/step\n",
            "Epoch 2221/3000\n",
            "1/1 - 1s - loss: 0.0334 - val_loss: 0.0322 - 1s/epoch - 1s/step\n",
            "Epoch 2222/3000\n",
            "1/1 - 1s - loss: 0.0333 - val_loss: 0.0321 - 1s/epoch - 1s/step\n",
            "Epoch 2223/3000\n",
            "1/1 - 1s - loss: 0.0332 - val_loss: 0.0320 - 1s/epoch - 1s/step\n",
            "Epoch 2224/3000\n",
            "1/1 - 1s - loss: 0.0331 - val_loss: 0.0320 - 1s/epoch - 1s/step\n",
            "Epoch 2225/3000\n",
            "1/1 - 1s - loss: 0.0330 - val_loss: 0.0319 - 1s/epoch - 1s/step\n",
            "Epoch 2226/3000\n",
            "1/1 - 1s - loss: 0.0329 - val_loss: 0.0318 - 1s/epoch - 1s/step\n",
            "Epoch 2227/3000\n",
            "1/1 - 1s - loss: 0.0328 - val_loss: 0.0317 - 1s/epoch - 1s/step\n",
            "Epoch 2228/3000\n",
            "1/1 - 1s - loss: 0.0327 - val_loss: 0.0317 - 1s/epoch - 1s/step\n",
            "Epoch 2229/3000\n",
            "1/1 - 1s - loss: 0.0326 - val_loss: 0.0316 - 1s/epoch - 1s/step\n",
            "Epoch 2230/3000\n",
            "1/1 - 1s - loss: 0.0325 - val_loss: 0.0315 - 1s/epoch - 1s/step\n",
            "Epoch 2231/3000\n",
            "1/1 - 1s - loss: 0.0324 - val_loss: 0.0314 - 1s/epoch - 1s/step\n",
            "Epoch 2232/3000\n",
            "1/1 - 1s - loss: 0.0323 - val_loss: 0.0314 - 1s/epoch - 1s/step\n",
            "Epoch 2233/3000\n",
            "1/1 - 1s - loss: 0.0322 - val_loss: 0.0313 - 1s/epoch - 1s/step\n",
            "Epoch 2234/3000\n",
            "1/1 - 1s - loss: 0.0321 - val_loss: 0.0312 - 1s/epoch - 1s/step\n",
            "Epoch 2235/3000\n",
            "1/1 - 1s - loss: 0.0320 - val_loss: 0.0311 - 1s/epoch - 1s/step\n",
            "Epoch 2236/3000\n",
            "1/1 - 1s - loss: 0.0319 - val_loss: 0.0311 - 1s/epoch - 1s/step\n",
            "Epoch 2237/3000\n",
            "1/1 - 1s - loss: 0.0318 - val_loss: 0.0310 - 1s/epoch - 1s/step\n",
            "Epoch 2238/3000\n",
            "1/1 - 1s - loss: 0.0317 - val_loss: 0.0309 - 1s/epoch - 1s/step\n",
            "Epoch 2239/3000\n",
            "1/1 - 1s - loss: 0.0317 - val_loss: 0.0309 - 1s/epoch - 1s/step\n",
            "Epoch 2240/3000\n",
            "1/1 - 1s - loss: 0.0316 - val_loss: 0.0308 - 1s/epoch - 1s/step\n",
            "Epoch 2241/3000\n",
            "1/1 - 1s - loss: 0.0315 - val_loss: 0.0307 - 1s/epoch - 1s/step\n",
            "Epoch 2242/3000\n",
            "1/1 - 1s - loss: 0.0314 - val_loss: 0.0307 - 1s/epoch - 1s/step\n",
            "Epoch 2243/3000\n",
            "1/1 - 1s - loss: 0.0313 - val_loss: 0.0306 - 1s/epoch - 1s/step\n",
            "Epoch 2244/3000\n",
            "1/1 - 1s - loss: 0.0312 - val_loss: 0.0305 - 1s/epoch - 1s/step\n",
            "Epoch 2245/3000\n",
            "1/1 - 1s - loss: 0.0311 - val_loss: 0.0305 - 1s/epoch - 1s/step\n",
            "Epoch 2246/3000\n",
            "1/1 - 1s - loss: 0.0311 - val_loss: 0.0304 - 1s/epoch - 1s/step\n",
            "Epoch 2247/3000\n",
            "1/1 - 1s - loss: 0.0310 - val_loss: 0.0303 - 1s/epoch - 1s/step\n",
            "Epoch 2248/3000\n",
            "1/1 - 1s - loss: 0.0309 - val_loss: 0.0303 - 1s/epoch - 1s/step\n",
            "Epoch 2249/3000\n",
            "1/1 - 1s - loss: 0.0308 - val_loss: 0.0302 - 1s/epoch - 1s/step\n",
            "Epoch 2250/3000\n",
            "1/1 - 1s - loss: 0.0307 - val_loss: 0.0302 - 1s/epoch - 1s/step\n",
            "Epoch 2251/3000\n",
            "1/1 - 1s - loss: 0.0307 - val_loss: 0.0301 - 1s/epoch - 1s/step\n",
            "Epoch 2252/3000\n",
            "1/1 - 1s - loss: 0.0306 - val_loss: 0.0301 - 1s/epoch - 1s/step\n",
            "Epoch 2253/3000\n",
            "1/1 - 1s - loss: 0.0305 - val_loss: 0.0300 - 1s/epoch - 1s/step\n",
            "Epoch 2254/3000\n",
            "1/1 - 1s - loss: 0.0304 - val_loss: 0.0299 - 1s/epoch - 1s/step\n",
            "Epoch 2255/3000\n",
            "1/1 - 1s - loss: 0.0304 - val_loss: 0.0299 - 1s/epoch - 1s/step\n",
            "Epoch 2256/3000\n",
            "1/1 - 1s - loss: 0.0303 - val_loss: 0.0298 - 1s/epoch - 1s/step\n",
            "Epoch 2257/3000\n",
            "1/1 - 1s - loss: 0.0302 - val_loss: 0.0298 - 1s/epoch - 1s/step\n",
            "Epoch 2258/3000\n",
            "1/1 - 1s - loss: 0.0301 - val_loss: 0.0297 - 1s/epoch - 1s/step\n",
            "Epoch 2259/3000\n",
            "1/1 - 1s - loss: 0.0301 - val_loss: 0.0297 - 1s/epoch - 1s/step\n",
            "Epoch 2260/3000\n",
            "1/1 - 1s - loss: 0.0300 - val_loss: 0.0296 - 1s/epoch - 1s/step\n",
            "Epoch 2261/3000\n",
            "1/1 - 1s - loss: 0.0299 - val_loss: 0.0295 - 1s/epoch - 1s/step\n",
            "Epoch 2262/3000\n",
            "1/1 - 1s - loss: 0.0298 - val_loss: 0.0295 - 1s/epoch - 1s/step\n",
            "Epoch 2263/3000\n",
            "1/1 - 1s - loss: 0.0298 - val_loss: 0.0294 - 1s/epoch - 1s/step\n",
            "Epoch 2264/3000\n",
            "1/1 - 1s - loss: 0.0297 - val_loss: 0.0294 - 1s/epoch - 1s/step\n",
            "Epoch 2265/3000\n",
            "1/1 - 1s - loss: 0.0296 - val_loss: 0.0293 - 1s/epoch - 1s/step\n",
            "Epoch 2266/3000\n",
            "1/1 - 1s - loss: 0.0295 - val_loss: 0.0293 - 1s/epoch - 1s/step\n",
            "Epoch 2267/3000\n",
            "1/1 - 1s - loss: 0.0295 - val_loss: 0.0292 - 1s/epoch - 1s/step\n",
            "Epoch 2268/3000\n",
            "1/1 - 1s - loss: 0.0294 - val_loss: 0.0292 - 1s/epoch - 1s/step\n",
            "Epoch 2269/3000\n",
            "1/1 - 1s - loss: 0.0293 - val_loss: 0.0291 - 1s/epoch - 1s/step\n",
            "Epoch 2270/3000\n",
            "1/1 - 1s - loss: 0.0293 - val_loss: 0.0291 - 1s/epoch - 1s/step\n",
            "Epoch 2271/3000\n",
            "1/1 - 1s - loss: 0.0292 - val_loss: 0.0291 - 1s/epoch - 1s/step\n",
            "Epoch 2272/3000\n",
            "1/1 - 1s - loss: 0.0291 - val_loss: 0.0290 - 1s/epoch - 1s/step\n",
            "Epoch 2273/3000\n",
            "1/1 - 1s - loss: 0.0291 - val_loss: 0.0290 - 1s/epoch - 1s/step\n",
            "Epoch 2274/3000\n",
            "1/1 - 1s - loss: 0.0290 - val_loss: 0.0289 - 1s/epoch - 1s/step\n",
            "Epoch 2275/3000\n",
            "1/1 - 1s - loss: 0.0289 - val_loss: 0.0289 - 1s/epoch - 1s/step\n",
            "Epoch 2276/3000\n",
            "1/1 - 1s - loss: 0.0289 - val_loss: 0.0288 - 1s/epoch - 1s/step\n",
            "Epoch 2277/3000\n",
            "1/1 - 1s - loss: 0.0288 - val_loss: 0.0288 - 1s/epoch - 1s/step\n",
            "Epoch 2278/3000\n",
            "1/1 - 1s - loss: 0.0287 - val_loss: 0.0287 - 1s/epoch - 1s/step\n",
            "Epoch 2279/3000\n",
            "1/1 - 1s - loss: 0.0287 - val_loss: 0.0287 - 1s/epoch - 1s/step\n",
            "Epoch 2280/3000\n",
            "1/1 - 1s - loss: 0.0286 - val_loss: 0.0287 - 1s/epoch - 1s/step\n",
            "Epoch 2281/3000\n",
            "1/1 - 1s - loss: 0.0286 - val_loss: 0.0286 - 1s/epoch - 1s/step\n",
            "Epoch 2282/3000\n",
            "1/1 - 1s - loss: 0.0285 - val_loss: 0.0286 - 1s/epoch - 1s/step\n",
            "Epoch 2283/3000\n",
            "1/1 - 1s - loss: 0.0284 - val_loss: 0.0285 - 1s/epoch - 1s/step\n",
            "Epoch 2284/3000\n",
            "1/1 - 1s - loss: 0.0284 - val_loss: 0.0285 - 1s/epoch - 1s/step\n",
            "Epoch 2285/3000\n",
            "1/1 - 1s - loss: 0.0283 - val_loss: 0.0285 - 1s/epoch - 1s/step\n",
            "Epoch 2286/3000\n",
            "1/1 - 1s - loss: 0.0282 - val_loss: 0.0284 - 1s/epoch - 1s/step\n",
            "Epoch 2287/3000\n",
            "1/1 - 1s - loss: 0.0282 - val_loss: 0.0284 - 1s/epoch - 1s/step\n",
            "Epoch 2288/3000\n",
            "1/1 - 1s - loss: 0.0281 - val_loss: 0.0283 - 1s/epoch - 1s/step\n",
            "Epoch 2289/3000\n",
            "1/1 - 1s - loss: 0.0281 - val_loss: 0.0283 - 1s/epoch - 1s/step\n",
            "Epoch 2290/3000\n",
            "1/1 - 1s - loss: 0.0280 - val_loss: 0.0282 - 1s/epoch - 1s/step\n",
            "Epoch 2291/3000\n",
            "1/1 - 1s - loss: 0.0279 - val_loss: 0.0282 - 1s/epoch - 1s/step\n",
            "Epoch 2292/3000\n",
            "1/1 - 1s - loss: 0.0279 - val_loss: 0.0282 - 1s/epoch - 1s/step\n",
            "Epoch 2293/3000\n",
            "1/1 - 1s - loss: 0.0278 - val_loss: 0.0281 - 1s/epoch - 1s/step\n",
            "Epoch 2294/3000\n",
            "1/1 - 1s - loss: 0.0278 - val_loss: 0.0281 - 1s/epoch - 1s/step\n",
            "Epoch 2295/3000\n",
            "1/1 - 1s - loss: 0.0277 - val_loss: 0.0280 - 1s/epoch - 1s/step\n",
            "Epoch 2296/3000\n",
            "1/1 - 1s - loss: 0.0277 - val_loss: 0.0280 - 1s/epoch - 1s/step\n",
            "Epoch 2297/3000\n",
            "1/1 - 1s - loss: 0.0276 - val_loss: 0.0279 - 1s/epoch - 1s/step\n",
            "Epoch 2298/3000\n",
            "1/1 - 1s - loss: 0.0275 - val_loss: 0.0279 - 1s/epoch - 1s/step\n",
            "Epoch 2299/3000\n",
            "1/1 - 1s - loss: 0.0275 - val_loss: 0.0279 - 1s/epoch - 1s/step\n",
            "Epoch 2300/3000\n",
            "1/1 - 1s - loss: 0.0274 - val_loss: 0.0278 - 1s/epoch - 1s/step\n",
            "Epoch 2301/3000\n",
            "1/1 - 1s - loss: 0.0274 - val_loss: 0.0278 - 1s/epoch - 1s/step\n",
            "Epoch 2302/3000\n",
            "1/1 - 1s - loss: 0.0273 - val_loss: 0.0278 - 1s/epoch - 1s/step\n",
            "Epoch 2303/3000\n",
            "1/1 - 1s - loss: 0.0273 - val_loss: 0.0277 - 1s/epoch - 1s/step\n",
            "Epoch 2304/3000\n",
            "1/1 - 1s - loss: 0.0272 - val_loss: 0.0277 - 1s/epoch - 1s/step\n",
            "Epoch 2305/3000\n",
            "1/1 - 1s - loss: 0.0272 - val_loss: 0.0276 - 1s/epoch - 1s/step\n",
            "Epoch 2306/3000\n",
            "1/1 - 1s - loss: 0.0271 - val_loss: 0.0276 - 1s/epoch - 1s/step\n",
            "Epoch 2307/3000\n",
            "1/1 - 1s - loss: 0.0271 - val_loss: 0.0276 - 1s/epoch - 1s/step\n",
            "Epoch 2308/3000\n",
            "1/1 - 1s - loss: 0.0270 - val_loss: 0.0275 - 1s/epoch - 1s/step\n",
            "Epoch 2309/3000\n",
            "1/1 - 1s - loss: 0.0270 - val_loss: 0.0275 - 1s/epoch - 1s/step\n",
            "Epoch 2310/3000\n",
            "1/1 - 1s - loss: 0.0269 - val_loss: 0.0275 - 1s/epoch - 1s/step\n",
            "Epoch 2311/3000\n",
            "1/1 - 1s - loss: 0.0269 - val_loss: 0.0274 - 1s/epoch - 1s/step\n",
            "Epoch 2312/3000\n",
            "1/1 - 1s - loss: 0.0268 - val_loss: 0.0274 - 1s/epoch - 1s/step\n",
            "Epoch 2313/3000\n",
            "1/1 - 1s - loss: 0.0268 - val_loss: 0.0273 - 1s/epoch - 1s/step\n",
            "Epoch 2314/3000\n",
            "1/1 - 1s - loss: 0.0267 - val_loss: 0.0273 - 1s/epoch - 1s/step\n",
            "Epoch 2315/3000\n",
            "1/1 - 1s - loss: 0.0267 - val_loss: 0.0273 - 1s/epoch - 1s/step\n",
            "Epoch 2316/3000\n",
            "1/1 - 1s - loss: 0.0266 - val_loss: 0.0272 - 1s/epoch - 1s/step\n",
            "Epoch 2317/3000\n",
            "1/1 - 1s - loss: 0.0266 - val_loss: 0.0272 - 1s/epoch - 1s/step\n",
            "Epoch 2318/3000\n",
            "1/1 - 1s - loss: 0.0265 - val_loss: 0.0271 - 1s/epoch - 1s/step\n",
            "Epoch 2319/3000\n",
            "1/1 - 1s - loss: 0.0265 - val_loss: 0.0271 - 1s/epoch - 1s/step\n",
            "Epoch 2320/3000\n",
            "1/1 - 1s - loss: 0.0264 - val_loss: 0.0271 - 1s/epoch - 1s/step\n",
            "Epoch 2321/3000\n",
            "1/1 - 1s - loss: 0.0264 - val_loss: 0.0270 - 1s/epoch - 1s/step\n",
            "Epoch 2322/3000\n",
            "1/1 - 1s - loss: 0.0263 - val_loss: 0.0270 - 1s/epoch - 1s/step\n",
            "Epoch 2323/3000\n",
            "1/1 - 1s - loss: 0.0263 - val_loss: 0.0270 - 1s/epoch - 1s/step\n",
            "Epoch 2324/3000\n",
            "1/1 - 1s - loss: 0.0262 - val_loss: 0.0269 - 1s/epoch - 1s/step\n",
            "Epoch 2325/3000\n",
            "1/1 - 1s - loss: 0.0262 - val_loss: 0.0269 - 1s/epoch - 1s/step\n",
            "Epoch 2326/3000\n",
            "1/1 - 1s - loss: 0.0262 - val_loss: 0.0269 - 1s/epoch - 1s/step\n",
            "Epoch 2327/3000\n",
            "1/1 - 1s - loss: 0.0261 - val_loss: 0.0268 - 1s/epoch - 1s/step\n",
            "Epoch 2328/3000\n",
            "1/1 - 1s - loss: 0.0261 - val_loss: 0.0268 - 1s/epoch - 1s/step\n",
            "Epoch 2329/3000\n",
            "1/1 - 1s - loss: 0.0260 - val_loss: 0.0267 - 1s/epoch - 1s/step\n",
            "Epoch 2330/3000\n",
            "1/1 - 1s - loss: 0.0260 - val_loss: 0.0267 - 1s/epoch - 1s/step\n",
            "Epoch 2331/3000\n",
            "1/1 - 1s - loss: 0.0259 - val_loss: 0.0267 - 1s/epoch - 1s/step\n",
            "Epoch 2332/3000\n",
            "1/1 - 1s - loss: 0.0259 - val_loss: 0.0266 - 1s/epoch - 1s/step\n",
            "Epoch 2333/3000\n",
            "1/1 - 1s - loss: 0.0258 - val_loss: 0.0266 - 1s/epoch - 1s/step\n",
            "Epoch 2334/3000\n",
            "1/1 - 1s - loss: 0.0258 - val_loss: 0.0266 - 1s/epoch - 1s/step\n",
            "Epoch 2335/3000\n",
            "1/1 - 1s - loss: 0.0258 - val_loss: 0.0265 - 1s/epoch - 1s/step\n",
            "Epoch 2336/3000\n",
            "1/1 - 1s - loss: 0.0257 - val_loss: 0.0265 - 1s/epoch - 1s/step\n",
            "Epoch 2337/3000\n",
            "1/1 - 1s - loss: 0.0257 - val_loss: 0.0265 - 1s/epoch - 1s/step\n",
            "Epoch 2338/3000\n",
            "1/1 - 1s - loss: 0.0256 - val_loss: 0.0264 - 1s/epoch - 1s/step\n",
            "Epoch 2339/3000\n",
            "1/1 - 1s - loss: 0.0256 - val_loss: 0.0264 - 1s/epoch - 1s/step\n",
            "Epoch 2340/3000\n",
            "1/1 - 1s - loss: 0.0256 - val_loss: 0.0264 - 1s/epoch - 1s/step\n",
            "Epoch 2341/3000\n",
            "1/1 - 1s - loss: 0.0255 - val_loss: 0.0263 - 1s/epoch - 1s/step\n",
            "Epoch 2342/3000\n",
            "1/1 - 1s - loss: 0.0255 - val_loss: 0.0263 - 1s/epoch - 1s/step\n",
            "Epoch 2343/3000\n",
            "1/1 - 1s - loss: 0.0254 - val_loss: 0.0263 - 1s/epoch - 1s/step\n",
            "Epoch 2344/3000\n",
            "1/1 - 1s - loss: 0.0254 - val_loss: 0.0262 - 1s/epoch - 1s/step\n",
            "Epoch 2345/3000\n",
            "1/1 - 1s - loss: 0.0253 - val_loss: 0.0262 - 1s/epoch - 1s/step\n",
            "Epoch 2346/3000\n",
            "1/1 - 1s - loss: 0.0253 - val_loss: 0.0262 - 1s/epoch - 1s/step\n",
            "Epoch 2347/3000\n",
            "1/1 - 1s - loss: 0.0253 - val_loss: 0.0261 - 1s/epoch - 1s/step\n",
            "Epoch 2348/3000\n",
            "1/1 - 1s - loss: 0.0252 - val_loss: 0.0261 - 1s/epoch - 1s/step\n",
            "Epoch 2349/3000\n",
            "1/1 - 1s - loss: 0.0252 - val_loss: 0.0261 - 1s/epoch - 1s/step\n",
            "Epoch 2350/3000\n",
            "1/1 - 1s - loss: 0.0252 - val_loss: 0.0260 - 1s/epoch - 1s/step\n",
            "Epoch 2351/3000\n",
            "1/1 - 1s - loss: 0.0251 - val_loss: 0.0260 - 1s/epoch - 1s/step\n",
            "Epoch 2352/3000\n",
            "1/1 - 1s - loss: 0.0251 - val_loss: 0.0260 - 1s/epoch - 1s/step\n",
            "Epoch 2353/3000\n",
            "1/1 - 1s - loss: 0.0250 - val_loss: 0.0259 - 1s/epoch - 1s/step\n",
            "Epoch 2354/3000\n",
            "1/1 - 1s - loss: 0.0250 - val_loss: 0.0259 - 1s/epoch - 1s/step\n",
            "Epoch 2355/3000\n",
            "1/1 - 1s - loss: 0.0250 - val_loss: 0.0259 - 1s/epoch - 1s/step\n",
            "Epoch 2356/3000\n",
            "1/1 - 1s - loss: 0.0249 - val_loss: 0.0259 - 1s/epoch - 1s/step\n",
            "Epoch 2357/3000\n",
            "1/1 - 1s - loss: 0.0249 - val_loss: 0.0258 - 1s/epoch - 1s/step\n",
            "Epoch 2358/3000\n",
            "1/1 - 1s - loss: 0.0248 - val_loss: 0.0258 - 1s/epoch - 1s/step\n",
            "Epoch 2359/3000\n",
            "1/1 - 1s - loss: 0.0248 - val_loss: 0.0258 - 1s/epoch - 1s/step\n",
            "Epoch 2360/3000\n",
            "1/1 - 1s - loss: 0.0248 - val_loss: 0.0257 - 1s/epoch - 1s/step\n",
            "Epoch 2361/3000\n",
            "1/1 - 1s - loss: 0.0247 - val_loss: 0.0257 - 1s/epoch - 1s/step\n",
            "Epoch 2362/3000\n",
            "1/1 - 1s - loss: 0.0247 - val_loss: 0.0257 - 1s/epoch - 1s/step\n",
            "Epoch 2363/3000\n",
            "1/1 - 1s - loss: 0.0247 - val_loss: 0.0256 - 1s/epoch - 1s/step\n",
            "Epoch 2364/3000\n",
            "1/1 - 1s - loss: 0.0246 - val_loss: 0.0256 - 1s/epoch - 1s/step\n",
            "Epoch 2365/3000\n",
            "1/1 - 1s - loss: 0.0246 - val_loss: 0.0256 - 1s/epoch - 1s/step\n",
            "Epoch 2366/3000\n",
            "1/1 - 1s - loss: 0.0246 - val_loss: 0.0255 - 1s/epoch - 1s/step\n",
            "Epoch 2367/3000\n",
            "1/1 - 1s - loss: 0.0245 - val_loss: 0.0255 - 1s/epoch - 1s/step\n",
            "Epoch 2368/3000\n",
            "1/1 - 1s - loss: 0.0245 - val_loss: 0.0255 - 1s/epoch - 1s/step\n",
            "Epoch 2369/3000\n",
            "1/1 - 1s - loss: 0.0245 - val_loss: 0.0254 - 1s/epoch - 1s/step\n",
            "Epoch 2370/3000\n",
            "1/1 - 1s - loss: 0.0244 - val_loss: 0.0254 - 1s/epoch - 1s/step\n",
            "Epoch 2371/3000\n",
            "1/1 - 1s - loss: 0.0244 - val_loss: 0.0254 - 1s/epoch - 1s/step\n",
            "Epoch 2372/3000\n",
            "1/1 - 1s - loss: 0.0243 - val_loss: 0.0254 - 1s/epoch - 1s/step\n",
            "Epoch 2373/3000\n",
            "1/1 - 1s - loss: 0.0243 - val_loss: 0.0253 - 1s/epoch - 1s/step\n",
            "Epoch 2374/3000\n",
            "1/1 - 1s - loss: 0.0243 - val_loss: 0.0253 - 1s/epoch - 1s/step\n",
            "Epoch 2375/3000\n",
            "1/1 - 1s - loss: 0.0242 - val_loss: 0.0253 - 1s/epoch - 1s/step\n",
            "Epoch 2376/3000\n",
            "1/1 - 1s - loss: 0.0242 - val_loss: 0.0252 - 1s/epoch - 1s/step\n",
            "Epoch 2377/3000\n",
            "1/1 - 1s - loss: 0.0242 - val_loss: 0.0252 - 1s/epoch - 1s/step\n",
            "Epoch 2378/3000\n",
            "1/1 - 1s - loss: 0.0241 - val_loss: 0.0252 - 1s/epoch - 1s/step\n",
            "Epoch 2379/3000\n",
            "1/1 - 1s - loss: 0.0241 - val_loss: 0.0252 - 1s/epoch - 1s/step\n",
            "Epoch 2380/3000\n",
            "1/1 - 1s - loss: 0.0241 - val_loss: 0.0251 - 1s/epoch - 1s/step\n",
            "Epoch 2381/3000\n",
            "1/1 - 1s - loss: 0.0241 - val_loss: 0.0251 - 1s/epoch - 1s/step\n",
            "Epoch 2382/3000\n",
            "1/1 - 1s - loss: 0.0240 - val_loss: 0.0251 - 1s/epoch - 1s/step\n",
            "Epoch 2383/3000\n",
            "1/1 - 1s - loss: 0.0240 - val_loss: 0.0250 - 1s/epoch - 1s/step\n",
            "Epoch 2384/3000\n",
            "1/1 - 1s - loss: 0.0240 - val_loss: 0.0250 - 1s/epoch - 1s/step\n",
            "Epoch 2385/3000\n",
            "1/1 - 1s - loss: 0.0239 - val_loss: 0.0250 - 1s/epoch - 1s/step\n",
            "Epoch 2386/3000\n",
            "1/1 - 1s - loss: 0.0239 - val_loss: 0.0250 - 1s/epoch - 1s/step\n",
            "Epoch 2387/3000\n",
            "1/1 - 1s - loss: 0.0239 - val_loss: 0.0249 - 1s/epoch - 1s/step\n",
            "Epoch 2388/3000\n",
            "1/1 - 1s - loss: 0.0238 - val_loss: 0.0249 - 1s/epoch - 1s/step\n",
            "Epoch 2389/3000\n",
            "1/1 - 1s - loss: 0.0238 - val_loss: 0.0249 - 1s/epoch - 1s/step\n",
            "Epoch 2390/3000\n",
            "1/1 - 1s - loss: 0.0238 - val_loss: 0.0249 - 1s/epoch - 1s/step\n",
            "Epoch 2391/3000\n",
            "1/1 - 1s - loss: 0.0237 - val_loss: 0.0248 - 1s/epoch - 1s/step\n",
            "Epoch 2392/3000\n",
            "1/1 - 1s - loss: 0.0237 - val_loss: 0.0248 - 1s/epoch - 1s/step\n",
            "Epoch 2393/3000\n",
            "1/1 - 1s - loss: 0.0237 - val_loss: 0.0248 - 1s/epoch - 1s/step\n",
            "Epoch 2394/3000\n",
            "1/1 - 1s - loss: 0.0236 - val_loss: 0.0248 - 1s/epoch - 1s/step\n",
            "Epoch 2395/3000\n",
            "1/1 - 1s - loss: 0.0236 - val_loss: 0.0247 - 1s/epoch - 1s/step\n",
            "Epoch 2396/3000\n",
            "1/1 - 1s - loss: 0.0236 - val_loss: 0.0247 - 1s/epoch - 1s/step\n",
            "Epoch 2397/3000\n",
            "1/1 - 1s - loss: 0.0236 - val_loss: 0.0247 - 1s/epoch - 1s/step\n",
            "Epoch 2398/3000\n",
            "1/1 - 1s - loss: 0.0235 - val_loss: 0.0247 - 1s/epoch - 1s/step\n",
            "Epoch 2399/3000\n",
            "1/1 - 1s - loss: 0.0235 - val_loss: 0.0246 - 1s/epoch - 1s/step\n",
            "Epoch 2400/3000\n",
            "1/1 - 1s - loss: 0.0235 - val_loss: 0.0246 - 1s/epoch - 1s/step\n",
            "Epoch 2401/3000\n",
            "1/1 - 1s - loss: 0.0234 - val_loss: 0.0246 - 1s/epoch - 1s/step\n",
            "Epoch 2402/3000\n",
            "1/1 - 1s - loss: 0.0234 - val_loss: 0.0245 - 1s/epoch - 1s/step\n",
            "Epoch 2403/3000\n",
            "1/1 - 1s - loss: 0.0234 - val_loss: 0.0245 - 1s/epoch - 1s/step\n",
            "Epoch 2404/3000\n",
            "1/1 - 1s - loss: 0.0234 - val_loss: 0.0245 - 1s/epoch - 1s/step\n",
            "Epoch 2405/3000\n",
            "1/1 - 1s - loss: 0.0233 - val_loss: 0.0245 - 1s/epoch - 1s/step\n",
            "Epoch 2406/3000\n",
            "1/1 - 1s - loss: 0.0233 - val_loss: 0.0245 - 1s/epoch - 1s/step\n",
            "Epoch 2407/3000\n",
            "1/1 - 1s - loss: 0.0233 - val_loss: 0.0244 - 1s/epoch - 1s/step\n",
            "Epoch 2408/3000\n",
            "1/1 - 1s - loss: 0.0232 - val_loss: 0.0244 - 1s/epoch - 1s/step\n",
            "Epoch 2409/3000\n",
            "1/1 - 1s - loss: 0.0232 - val_loss: 0.0244 - 1s/epoch - 1s/step\n",
            "Epoch 2410/3000\n",
            "1/1 - 1s - loss: 0.0232 - val_loss: 0.0244 - 1s/epoch - 1s/step\n",
            "Epoch 2411/3000\n",
            "1/1 - 1s - loss: 0.0232 - val_loss: 0.0243 - 1s/epoch - 1s/step\n",
            "Epoch 2412/3000\n",
            "1/1 - 1s - loss: 0.0231 - val_loss: 0.0243 - 1s/epoch - 1s/step\n",
            "Epoch 2413/3000\n",
            "1/1 - 1s - loss: 0.0231 - val_loss: 0.0243 - 1s/epoch - 1s/step\n",
            "Epoch 2414/3000\n",
            "1/1 - 1s - loss: 0.0231 - val_loss: 0.0243 - 1s/epoch - 1s/step\n",
            "Epoch 2415/3000\n",
            "1/1 - 1s - loss: 0.0231 - val_loss: 0.0243 - 1s/epoch - 1s/step\n",
            "Epoch 2416/3000\n",
            "1/1 - 1s - loss: 0.0230 - val_loss: 0.0242 - 1s/epoch - 1s/step\n",
            "Epoch 2417/3000\n",
            "1/1 - 1s - loss: 0.0230 - val_loss: 0.0242 - 1s/epoch - 1s/step\n",
            "Epoch 2418/3000\n",
            "1/1 - 1s - loss: 0.0230 - val_loss: 0.0242 - 1s/epoch - 1s/step\n",
            "Epoch 2419/3000\n",
            "1/1 - 1s - loss: 0.0229 - val_loss: 0.0242 - 1s/epoch - 1s/step\n",
            "Epoch 2420/3000\n",
            "1/1 - 1s - loss: 0.0229 - val_loss: 0.0241 - 1s/epoch - 1s/step\n",
            "Epoch 2421/3000\n",
            "1/1 - 1s - loss: 0.0229 - val_loss: 0.0241 - 1s/epoch - 1s/step\n",
            "Epoch 2422/3000\n",
            "1/1 - 1s - loss: 0.0229 - val_loss: 0.0241 - 1s/epoch - 1s/step\n",
            "Epoch 2423/3000\n",
            "1/1 - 1s - loss: 0.0228 - val_loss: 0.0241 - 1s/epoch - 1s/step\n",
            "Epoch 2424/3000\n",
            "1/1 - 1s - loss: 0.0228 - val_loss: 0.0240 - 1s/epoch - 1s/step\n",
            "Epoch 2425/3000\n",
            "1/1 - 1s - loss: 0.0228 - val_loss: 0.0240 - 1s/epoch - 1s/step\n",
            "Epoch 2426/3000\n",
            "1/1 - 1s - loss: 0.0228 - val_loss: 0.0240 - 1s/epoch - 1s/step\n",
            "Epoch 2427/3000\n",
            "1/1 - 1s - loss: 0.0227 - val_loss: 0.0240 - 1s/epoch - 1s/step\n",
            "Epoch 2428/3000\n",
            "1/1 - 1s - loss: 0.0227 - val_loss: 0.0239 - 1s/epoch - 1s/step\n",
            "Epoch 2429/3000\n",
            "1/1 - 1s - loss: 0.0227 - val_loss: 0.0239 - 1s/epoch - 1s/step\n",
            "Epoch 2430/3000\n",
            "1/1 - 1s - loss: 0.0227 - val_loss: 0.0239 - 1s/epoch - 1s/step\n",
            "Epoch 2431/3000\n",
            "1/1 - 1s - loss: 0.0226 - val_loss: 0.0239 - 1s/epoch - 1s/step\n",
            "Epoch 2432/3000\n",
            "1/1 - 1s - loss: 0.0226 - val_loss: 0.0239 - 1s/epoch - 1s/step\n",
            "Epoch 2433/3000\n",
            "1/1 - 1s - loss: 0.0226 - val_loss: 0.0238 - 1s/epoch - 1s/step\n",
            "Epoch 2434/3000\n",
            "1/1 - 1s - loss: 0.0226 - val_loss: 0.0238 - 1s/epoch - 1s/step\n",
            "Epoch 2435/3000\n",
            "1/1 - 1s - loss: 0.0225 - val_loss: 0.0238 - 1s/epoch - 1s/step\n",
            "Epoch 2436/3000\n",
            "1/1 - 1s - loss: 0.0225 - val_loss: 0.0238 - 1s/epoch - 1s/step\n",
            "Epoch 2437/3000\n",
            "1/1 - 1s - loss: 0.0225 - val_loss: 0.0237 - 1s/epoch - 1s/step\n",
            "Epoch 2438/3000\n",
            "1/1 - 1s - loss: 0.0225 - val_loss: 0.0237 - 1s/epoch - 1s/step\n",
            "Epoch 2439/3000\n",
            "1/1 - 1s - loss: 0.0224 - val_loss: 0.0237 - 1s/epoch - 1s/step\n",
            "Epoch 2440/3000\n",
            "1/1 - 1s - loss: 0.0224 - val_loss: 0.0237 - 1s/epoch - 1s/step\n",
            "Epoch 2441/3000\n",
            "1/1 - 1s - loss: 0.0224 - val_loss: 0.0237 - 1s/epoch - 1s/step\n",
            "Epoch 2442/3000\n",
            "1/1 - 1s - loss: 0.0224 - val_loss: 0.0236 - 1s/epoch - 1s/step\n",
            "Epoch 2443/3000\n",
            "1/1 - 1s - loss: 0.0223 - val_loss: 0.0236 - 1s/epoch - 1s/step\n",
            "Epoch 2444/3000\n",
            "1/1 - 1s - loss: 0.0223 - val_loss: 0.0236 - 1s/epoch - 1s/step\n",
            "Epoch 2445/3000\n",
            "1/1 - 1s - loss: 0.0223 - val_loss: 0.0236 - 1s/epoch - 1s/step\n",
            "Epoch 2446/3000\n",
            "1/1 - 1s - loss: 0.0223 - val_loss: 0.0236 - 1s/epoch - 1s/step\n",
            "Epoch 2447/3000\n",
            "1/1 - 1s - loss: 0.0222 - val_loss: 0.0235 - 1s/epoch - 1s/step\n",
            "Epoch 2448/3000\n",
            "1/1 - 1s - loss: 0.0222 - val_loss: 0.0235 - 1s/epoch - 1s/step\n",
            "Epoch 2449/3000\n",
            "1/1 - 1s - loss: 0.0222 - val_loss: 0.0235 - 1s/epoch - 1s/step\n",
            "Epoch 2450/3000\n",
            "1/1 - 1s - loss: 0.0222 - val_loss: 0.0235 - 1s/epoch - 1s/step\n",
            "Epoch 2451/3000\n",
            "1/1 - 1s - loss: 0.0221 - val_loss: 0.0234 - 1s/epoch - 1s/step\n",
            "Epoch 2452/3000\n",
            "1/1 - 1s - loss: 0.0221 - val_loss: 0.0234 - 1s/epoch - 1s/step\n",
            "Epoch 2453/3000\n",
            "1/1 - 1s - loss: 0.0221 - val_loss: 0.0234 - 1s/epoch - 1s/step\n",
            "Epoch 2454/3000\n",
            "1/1 - 1s - loss: 0.0221 - val_loss: 0.0234 - 1s/epoch - 1s/step\n",
            "Epoch 2455/3000\n",
            "1/1 - 1s - loss: 0.0221 - val_loss: 0.0234 - 1s/epoch - 1s/step\n",
            "Epoch 2456/3000\n",
            "1/1 - 1s - loss: 0.0220 - val_loss: 0.0233 - 1s/epoch - 1s/step\n",
            "Epoch 2457/3000\n",
            "1/1 - 1s - loss: 0.0220 - val_loss: 0.0233 - 1s/epoch - 1s/step\n",
            "Epoch 2458/3000\n",
            "1/1 - 1s - loss: 0.0220 - val_loss: 0.0233 - 1s/epoch - 1s/step\n",
            "Epoch 2459/3000\n",
            "1/1 - 1s - loss: 0.0220 - val_loss: 0.0233 - 1s/epoch - 1s/step\n",
            "Epoch 2460/3000\n",
            "1/1 - 1s - loss: 0.0219 - val_loss: 0.0233 - 1s/epoch - 1s/step\n",
            "Epoch 2461/3000\n",
            "1/1 - 1s - loss: 0.0219 - val_loss: 0.0232 - 1s/epoch - 1s/step\n",
            "Epoch 2462/3000\n",
            "1/1 - 1s - loss: 0.0219 - val_loss: 0.0232 - 1s/epoch - 1s/step\n",
            "Epoch 2463/3000\n",
            "1/1 - 1s - loss: 0.0219 - val_loss: 0.0232 - 1s/epoch - 1s/step\n",
            "Epoch 2464/3000\n",
            "1/1 - 1s - loss: 0.0219 - val_loss: 0.0232 - 1s/epoch - 1s/step\n",
            "Epoch 2465/3000\n",
            "1/1 - 1s - loss: 0.0218 - val_loss: 0.0232 - 1s/epoch - 1s/step\n",
            "Epoch 2466/3000\n",
            "1/1 - 1s - loss: 0.0218 - val_loss: 0.0231 - 1s/epoch - 1s/step\n",
            "Epoch 2467/3000\n",
            "1/1 - 1s - loss: 0.0218 - val_loss: 0.0231 - 1s/epoch - 1s/step\n",
            "Epoch 2468/3000\n",
            "1/1 - 1s - loss: 0.0218 - val_loss: 0.0231 - 1s/epoch - 1s/step\n",
            "Epoch 2469/3000\n",
            "1/1 - 1s - loss: 0.0217 - val_loss: 0.0231 - 1s/epoch - 1s/step\n",
            "Epoch 2470/3000\n",
            "1/1 - 1s - loss: 0.0217 - val_loss: 0.0231 - 1s/epoch - 1s/step\n",
            "Epoch 2471/3000\n",
            "1/1 - 1s - loss: 0.0217 - val_loss: 0.0231 - 1s/epoch - 1s/step\n",
            "Epoch 2472/3000\n",
            "1/1 - 1s - loss: 0.0217 - val_loss: 0.0230 - 1s/epoch - 1s/step\n",
            "Epoch 2473/3000\n",
            "1/1 - 1s - loss: 0.0217 - val_loss: 0.0230 - 1s/epoch - 1s/step\n",
            "Epoch 2474/3000\n",
            "1/1 - 1s - loss: 0.0216 - val_loss: 0.0230 - 1s/epoch - 1s/step\n",
            "Epoch 2475/3000\n",
            "1/1 - 1s - loss: 0.0216 - val_loss: 0.0230 - 1s/epoch - 1s/step\n",
            "Epoch 2476/3000\n",
            "1/1 - 1s - loss: 0.0216 - val_loss: 0.0230 - 1s/epoch - 1s/step\n",
            "Epoch 2477/3000\n",
            "1/1 - 1s - loss: 0.0216 - val_loss: 0.0229 - 1s/epoch - 1s/step\n",
            "Epoch 2478/3000\n",
            "1/1 - 1s - loss: 0.0215 - val_loss: 0.0229 - 1s/epoch - 1s/step\n",
            "Epoch 2479/3000\n",
            "1/1 - 1s - loss: 0.0215 - val_loss: 0.0229 - 1s/epoch - 1s/step\n",
            "Epoch 2480/3000\n",
            "1/1 - 1s - loss: 0.0215 - val_loss: 0.0229 - 1s/epoch - 1s/step\n",
            "Epoch 2481/3000\n",
            "1/1 - 1s - loss: 0.0215 - val_loss: 0.0229 - 1s/epoch - 1s/step\n",
            "Epoch 2482/3000\n",
            "1/1 - 1s - loss: 0.0215 - val_loss: 0.0228 - 1s/epoch - 1s/step\n",
            "Epoch 2483/3000\n",
            "1/1 - 1s - loss: 0.0214 - val_loss: 0.0228 - 1s/epoch - 1s/step\n",
            "Epoch 2484/3000\n",
            "1/1 - 1s - loss: 0.0214 - val_loss: 0.0228 - 1s/epoch - 1s/step\n",
            "Epoch 2485/3000\n",
            "1/1 - 1s - loss: 0.0214 - val_loss: 0.0228 - 1s/epoch - 1s/step\n",
            "Epoch 2486/3000\n",
            "1/1 - 1s - loss: 0.0214 - val_loss: 0.0228 - 1s/epoch - 1s/step\n",
            "Epoch 2487/3000\n",
            "1/1 - 1s - loss: 0.0214 - val_loss: 0.0228 - 1s/epoch - 1s/step\n",
            "Epoch 2488/3000\n",
            "1/1 - 1s - loss: 0.0213 - val_loss: 0.0227 - 1s/epoch - 1s/step\n",
            "Epoch 2489/3000\n",
            "1/1 - 1s - loss: 0.0213 - val_loss: 0.0227 - 1s/epoch - 1s/step\n",
            "Epoch 2490/3000\n",
            "1/1 - 1s - loss: 0.0213 - val_loss: 0.0227 - 1s/epoch - 1s/step\n",
            "Epoch 2491/3000\n",
            "1/1 - 1s - loss: 0.0213 - val_loss: 0.0227 - 1s/epoch - 1s/step\n",
            "Epoch 2492/3000\n",
            "1/1 - 1s - loss: 0.0213 - val_loss: 0.0227 - 1s/epoch - 1s/step\n",
            "Epoch 2493/3000\n",
            "1/1 - 1s - loss: 0.0212 - val_loss: 0.0226 - 1s/epoch - 1s/step\n",
            "Epoch 2494/3000\n",
            "1/1 - 1s - loss: 0.0212 - val_loss: 0.0226 - 1s/epoch - 1s/step\n",
            "Epoch 2495/3000\n",
            "1/1 - 1s - loss: 0.0212 - val_loss: 0.0226 - 1s/epoch - 1s/step\n",
            "Epoch 2496/3000\n",
            "1/1 - 1s - loss: 0.0212 - val_loss: 0.0226 - 1s/epoch - 1s/step\n",
            "Epoch 2497/3000\n",
            "1/1 - 1s - loss: 0.0212 - val_loss: 0.0226 - 1s/epoch - 1s/step\n",
            "Epoch 2498/3000\n",
            "1/1 - 1s - loss: 0.0211 - val_loss: 0.0225 - 1s/epoch - 1s/step\n",
            "Epoch 2499/3000\n",
            "1/1 - 1s - loss: 0.0211 - val_loss: 0.0225 - 1s/epoch - 1s/step\n",
            "Epoch 2500/3000\n",
            "1/1 - 1s - loss: 0.0211 - val_loss: 0.0225 - 1s/epoch - 1s/step\n",
            "Epoch 2501/3000\n",
            "1/1 - 1s - loss: 0.0211 - val_loss: 0.0225 - 1s/epoch - 1s/step\n",
            "Epoch 2502/3000\n",
            "1/1 - 1s - loss: 0.0211 - val_loss: 0.0225 - 1s/epoch - 1s/step\n",
            "Epoch 2503/3000\n",
            "1/1 - 1s - loss: 0.0210 - val_loss: 0.0225 - 1s/epoch - 1s/step\n",
            "Epoch 2504/3000\n",
            "1/1 - 1s - loss: 0.0210 - val_loss: 0.0224 - 1s/epoch - 1s/step\n",
            "Epoch 2505/3000\n",
            "1/1 - 1s - loss: 0.0210 - val_loss: 0.0224 - 1s/epoch - 1s/step\n",
            "Epoch 2506/3000\n",
            "1/1 - 1s - loss: 0.0210 - val_loss: 0.0224 - 1s/epoch - 1s/step\n",
            "Epoch 2507/3000\n",
            "1/1 - 1s - loss: 0.0210 - val_loss: 0.0224 - 1s/epoch - 1s/step\n",
            "Epoch 2508/3000\n",
            "1/1 - 1s - loss: 0.0209 - val_loss: 0.0223 - 1s/epoch - 1s/step\n",
            "Epoch 2509/3000\n",
            "1/1 - 1s - loss: 0.0209 - val_loss: 0.0223 - 1s/epoch - 1s/step\n",
            "Epoch 2510/3000\n",
            "1/1 - 1s - loss: 0.0209 - val_loss: 0.0223 - 1s/epoch - 1s/step\n",
            "Epoch 2511/3000\n",
            "1/1 - 1s - loss: 0.0209 - val_loss: 0.0223 - 1s/epoch - 1s/step\n",
            "Epoch 2512/3000\n",
            "1/1 - 1s - loss: 0.0209 - val_loss: 0.0223 - 1s/epoch - 1s/step\n",
            "Epoch 2513/3000\n",
            "1/1 - 1s - loss: 0.0208 - val_loss: 0.0223 - 1s/epoch - 1s/step\n",
            "Epoch 2514/3000\n",
            "1/1 - 1s - loss: 0.0208 - val_loss: 0.0222 - 1s/epoch - 1s/step\n",
            "Epoch 2515/3000\n",
            "1/1 - 1s - loss: 0.0208 - val_loss: 0.0222 - 1s/epoch - 1s/step\n",
            "Epoch 2516/3000\n",
            "1/1 - 1s - loss: 0.0208 - val_loss: 0.0222 - 1s/epoch - 1s/step\n",
            "Epoch 2517/3000\n",
            "1/1 - 1s - loss: 0.0208 - val_loss: 0.0222 - 1s/epoch - 1s/step\n",
            "Epoch 2518/3000\n",
            "1/1 - 1s - loss: 0.0207 - val_loss: 0.0222 - 1s/epoch - 1s/step\n",
            "Epoch 2519/3000\n",
            "1/1 - 1s - loss: 0.0207 - val_loss: 0.0222 - 1s/epoch - 1s/step\n",
            "Epoch 2520/3000\n",
            "1/1 - 1s - loss: 0.0207 - val_loss: 0.0222 - 1s/epoch - 1s/step\n",
            "Epoch 2521/3000\n",
            "1/1 - 1s - loss: 0.0207 - val_loss: 0.0221 - 1s/epoch - 1s/step\n",
            "Epoch 2522/3000\n",
            "1/1 - 1s - loss: 0.0207 - val_loss: 0.0221 - 1s/epoch - 1s/step\n",
            "Epoch 2523/3000\n",
            "1/1 - 1s - loss: 0.0207 - val_loss: 0.0221 - 1s/epoch - 1s/step\n",
            "Epoch 2524/3000\n",
            "1/1 - 1s - loss: 0.0206 - val_loss: 0.0221 - 1s/epoch - 1s/step\n",
            "Epoch 2525/3000\n",
            "1/1 - 1s - loss: 0.0206 - val_loss: 0.0221 - 1s/epoch - 1s/step\n",
            "Epoch 2526/3000\n",
            "1/1 - 1s - loss: 0.0206 - val_loss: 0.0221 - 1s/epoch - 1s/step\n",
            "Epoch 2527/3000\n",
            "1/1 - 1s - loss: 0.0206 - val_loss: 0.0220 - 1s/epoch - 1s/step\n",
            "Epoch 2528/3000\n",
            "1/1 - 1s - loss: 0.0206 - val_loss: 0.0220 - 1s/epoch - 1s/step\n",
            "Epoch 2529/3000\n",
            "1/1 - 1s - loss: 0.0205 - val_loss: 0.0220 - 1s/epoch - 1s/step\n",
            "Epoch 2530/3000\n",
            "1/1 - 1s - loss: 0.0205 - val_loss: 0.0220 - 1s/epoch - 1s/step\n",
            "Epoch 2531/3000\n",
            "1/1 - 1s - loss: 0.0205 - val_loss: 0.0220 - 1s/epoch - 1s/step\n",
            "Epoch 2532/3000\n",
            "1/1 - 1s - loss: 0.0205 - val_loss: 0.0220 - 1s/epoch - 1s/step\n",
            "Epoch 2533/3000\n",
            "1/1 - 1s - loss: 0.0205 - val_loss: 0.0220 - 1s/epoch - 1s/step\n",
            "Epoch 2534/3000\n",
            "1/1 - 1s - loss: 0.0205 - val_loss: 0.0219 - 1s/epoch - 1s/step\n",
            "Epoch 2535/3000\n",
            "1/1 - 1s - loss: 0.0204 - val_loss: 0.0219 - 1s/epoch - 1s/step\n",
            "Epoch 2536/3000\n",
            "1/1 - 1s - loss: 0.0204 - val_loss: 0.0219 - 1s/epoch - 1s/step\n",
            "Epoch 2537/3000\n",
            "1/1 - 1s - loss: 0.0204 - val_loss: 0.0219 - 1s/epoch - 1s/step\n",
            "Epoch 2538/3000\n",
            "1/1 - 1s - loss: 0.0204 - val_loss: 0.0219 - 1s/epoch - 1s/step\n",
            "Epoch 2539/3000\n",
            "1/1 - 1s - loss: 0.0204 - val_loss: 0.0219 - 1s/epoch - 1s/step\n",
            "Epoch 2540/3000\n",
            "1/1 - 1s - loss: 0.0204 - val_loss: 0.0218 - 1s/epoch - 1s/step\n",
            "Epoch 2541/3000\n",
            "1/1 - 1s - loss: 0.0203 - val_loss: 0.0219 - 1s/epoch - 1s/step\n",
            "Epoch 2542/3000\n",
            "1/1 - 1s - loss: 0.0203 - val_loss: 0.0218 - 1s/epoch - 1s/step\n",
            "Epoch 2543/3000\n",
            "1/1 - 1s - loss: 0.0203 - val_loss: 0.0218 - 1s/epoch - 1s/step\n",
            "Epoch 2544/3000\n",
            "1/1 - 1s - loss: 0.0203 - val_loss: 0.0218 - 1s/epoch - 1s/step\n",
            "Epoch 2545/3000\n",
            "1/1 - 1s - loss: 0.0203 - val_loss: 0.0218 - 1s/epoch - 1s/step\n",
            "Epoch 2546/3000\n",
            "1/1 - 1s - loss: 0.0203 - val_loss: 0.0217 - 1s/epoch - 1s/step\n",
            "Epoch 2547/3000\n",
            "1/1 - 1s - loss: 0.0202 - val_loss: 0.0218 - 1s/epoch - 1s/step\n",
            "Epoch 2548/3000\n",
            "1/1 - 1s - loss: 0.0202 - val_loss: 0.0217 - 1s/epoch - 1s/step\n",
            "Epoch 2549/3000\n",
            "1/1 - 1s - loss: 0.0202 - val_loss: 0.0217 - 1s/epoch - 1s/step\n",
            "Epoch 2550/3000\n",
            "1/1 - 1s - loss: 0.0202 - val_loss: 0.0216 - 1s/epoch - 1s/step\n",
            "Epoch 2551/3000\n",
            "1/1 - 1s - loss: 0.0202 - val_loss: 0.0217 - 1s/epoch - 1s/step\n",
            "Epoch 2552/3000\n",
            "1/1 - 1s - loss: 0.0201 - val_loss: 0.0216 - 1s/epoch - 1s/step\n",
            "Epoch 2553/3000\n",
            "1/1 - 1s - loss: 0.0201 - val_loss: 0.0216 - 1s/epoch - 1s/step\n",
            "Epoch 2554/3000\n",
            "1/1 - 1s - loss: 0.0201 - val_loss: 0.0216 - 1s/epoch - 1s/step\n",
            "Epoch 2555/3000\n",
            "1/1 - 1s - loss: 0.0201 - val_loss: 0.0216 - 1s/epoch - 1s/step\n",
            "Epoch 2556/3000\n",
            "1/1 - 1s - loss: 0.0201 - val_loss: 0.0216 - 1s/epoch - 1s/step\n",
            "Epoch 2557/3000\n",
            "1/1 - 1s - loss: 0.0201 - val_loss: 0.0216 - 1s/epoch - 1s/step\n",
            "Epoch 2558/3000\n",
            "1/1 - 1s - loss: 0.0200 - val_loss: 0.0215 - 1s/epoch - 1s/step\n",
            "Epoch 2559/3000\n",
            "1/1 - 1s - loss: 0.0200 - val_loss: 0.0215 - 1s/epoch - 1s/step\n",
            "Epoch 2560/3000\n",
            "1/1 - 1s - loss: 0.0200 - val_loss: 0.0215 - 1s/epoch - 1s/step\n",
            "Epoch 2561/3000\n",
            "1/1 - 1s - loss: 0.0200 - val_loss: 0.0215 - 1s/epoch - 1s/step\n",
            "Epoch 2562/3000\n",
            "1/1 - 1s - loss: 0.0200 - val_loss: 0.0215 - 1s/epoch - 1s/step\n",
            "Epoch 2563/3000\n",
            "1/1 - 1s - loss: 0.0200 - val_loss: 0.0215 - 1s/epoch - 1s/step\n",
            "Epoch 2564/3000\n",
            "1/1 - 1s - loss: 0.0199 - val_loss: 0.0214 - 1s/epoch - 1s/step\n",
            "Epoch 2565/3000\n",
            "1/1 - 1s - loss: 0.0199 - val_loss: 0.0215 - 1s/epoch - 1s/step\n",
            "Epoch 2566/3000\n",
            "1/1 - 1s - loss: 0.0199 - val_loss: 0.0214 - 1s/epoch - 1s/step\n",
            "Epoch 2567/3000\n",
            "1/1 - 1s - loss: 0.0199 - val_loss: 0.0214 - 1s/epoch - 1s/step\n",
            "Epoch 2568/3000\n",
            "1/1 - 1s - loss: 0.0199 - val_loss: 0.0214 - 1s/epoch - 1s/step\n",
            "Epoch 2569/3000\n",
            "1/1 - 1s - loss: 0.0199 - val_loss: 0.0214 - 1s/epoch - 1s/step\n",
            "Epoch 2570/3000\n",
            "1/1 - 1s - loss: 0.0198 - val_loss: 0.0213 - 1s/epoch - 1s/step\n",
            "Epoch 2571/3000\n",
            "1/1 - 1s - loss: 0.0198 - val_loss: 0.0214 - 1s/epoch - 1s/step\n",
            "Epoch 2572/3000\n",
            "1/1 - 1s - loss: 0.0198 - val_loss: 0.0213 - 1s/epoch - 1s/step\n",
            "Epoch 2573/3000\n",
            "1/1 - 1s - loss: 0.0198 - val_loss: 0.0214 - 1s/epoch - 1s/step\n",
            "Epoch 2574/3000\n",
            "1/1 - 1s - loss: 0.0198 - val_loss: 0.0213 - 1s/epoch - 1s/step\n",
            "Epoch 2575/3000\n",
            "1/1 - 1s - loss: 0.0198 - val_loss: 0.0214 - 1s/epoch - 1s/step\n",
            "Epoch 2576/3000\n",
            "1/1 - 1s - loss: 0.0198 - val_loss: 0.0213 - 1s/epoch - 1s/step\n",
            "Epoch 2577/3000\n",
            "1/1 - 1s - loss: 0.0198 - val_loss: 0.0214 - 1s/epoch - 1s/step\n",
            "Epoch 2578/3000\n",
            "1/1 - 1s - loss: 0.0198 - val_loss: 0.0213 - 1s/epoch - 1s/step\n",
            "Epoch 2579/3000\n",
            "1/1 - 1s - loss: 0.0198 - val_loss: 0.0216 - 1s/epoch - 1s/step\n",
            "Epoch 2580/3000\n",
            "1/1 - 1s - loss: 0.0199 - val_loss: 0.0214 - 1s/epoch - 1s/step\n",
            "Epoch 2581/3000\n",
            "1/1 - 1s - loss: 0.0200 - val_loss: 0.0221 - 1s/epoch - 1s/step\n",
            "Epoch 2582/3000\n",
            "1/1 - 1s - loss: 0.0203 - val_loss: 0.0218 - 1s/epoch - 1s/step\n",
            "Epoch 2583/3000\n",
            "1/1 - 1s - loss: 0.0206 - val_loss: 0.0234 - 1s/epoch - 1s/step\n",
            "Epoch 2584/3000\n",
            "1/1 - 1s - loss: 0.0214 - val_loss: 0.0231 - 1s/epoch - 1s/step\n",
            "Epoch 2585/3000\n",
            "1/1 - 1s - loss: 0.0222 - val_loss: 0.0270 - 1s/epoch - 1s/step\n",
            "Epoch 2586/3000\n",
            "1/1 - 1s - loss: 0.0246 - val_loss: 0.0266 - 1s/epoch - 1s/step\n",
            "Epoch 2587/3000\n",
            "1/1 - 1s - loss: 0.0261 - val_loss: 0.0354 - 1s/epoch - 1s/step\n",
            "Epoch 2588/3000\n",
            "1/1 - 1s - loss: 0.0325 - val_loss: 0.0329 - 1s/epoch - 1s/step\n",
            "Epoch 2589/3000\n",
            "1/1 - 1s - loss: 0.0331 - val_loss: 0.0480 - 1s/epoch - 1s/step\n",
            "Epoch 2590/3000\n",
            "1/1 - 1s - loss: 0.0441 - val_loss: 0.0366 - 1s/epoch - 1s/step\n",
            "Epoch 2591/3000\n",
            "1/1 - 1s - loss: 0.0369 - val_loss: 0.0412 - 1s/epoch - 1s/step\n",
            "Epoch 2592/3000\n",
            "1/1 - 1s - loss: 0.0373 - val_loss: 0.0273 - 1s/epoch - 1s/step\n",
            "Epoch 2593/3000\n",
            "1/1 - 1s - loss: 0.0258 - val_loss: 0.0230 - 1s/epoch - 1s/step\n",
            "Epoch 2594/3000\n",
            "1/1 - 1s - loss: 0.0206 - val_loss: 0.0243 - 1s/epoch - 1s/step\n",
            "Epoch 2595/3000\n",
            "1/1 - 1s - loss: 0.0220 - val_loss: 0.0278 - 1s/epoch - 1s/step\n",
            "Epoch 2596/3000\n",
            "1/1 - 1s - loss: 0.0267 - val_loss: 0.0365 - 1s/epoch - 1s/step\n",
            "Epoch 2597/3000\n",
            "1/1 - 1s - loss: 0.0333 - val_loss: 0.0294 - 1s/epoch - 1s/step\n",
            "Epoch 2598/3000\n",
            "1/1 - 1s - loss: 0.0300 - val_loss: 0.0288 - 1s/epoch - 1s/step\n",
            "Epoch 2599/3000\n",
            "1/1 - 1s - loss: 0.0263 - val_loss: 0.0219 - 1s/epoch - 1s/step\n",
            "Epoch 2600/3000\n",
            "1/1 - 1s - loss: 0.0210 - val_loss: 0.0209 - 1s/epoch - 1s/step\n",
            "Epoch 2601/3000\n",
            "1/1 - 1s - loss: 0.0198 - val_loss: 0.0225 - 1s/epoch - 1s/step\n",
            "Epoch 2602/3000\n",
            "1/1 - 1s - loss: 0.0212 - val_loss: 0.0246 - 1s/epoch - 1s/step\n",
            "Epoch 2603/3000\n",
            "1/1 - 1s - loss: 0.0245 - val_loss: 0.0355 - 1s/epoch - 1s/step\n",
            "Epoch 2604/3000\n",
            "1/1 - 1s - loss: 0.0331 - val_loss: 0.0345 - 1s/epoch - 1s/step\n",
            "Epoch 2605/3000\n",
            "1/1 - 1s - loss: 0.0363 - val_loss: 0.0590 - 1s/epoch - 1s/step\n",
            "Epoch 2606/3000\n",
            "1/1 - 1s - loss: 0.0556 - val_loss: 0.0495 - 1s/epoch - 1s/step\n",
            "Epoch 2607/3000\n",
            "1/1 - 1s - loss: 0.0514 - val_loss: 0.0928 - 1s/epoch - 1s/step\n",
            "Epoch 2608/3000\n",
            "1/1 - 1s - loss: 0.0873 - val_loss: 0.0589 - 1s/epoch - 1s/step\n",
            "Epoch 2609/3000\n",
            "1/1 - 1s - loss: 0.0623 - val_loss: 0.0592 - 1s/epoch - 1s/step\n",
            "Epoch 2610/3000\n",
            "1/1 - 1s - loss: 0.0537 - val_loss: 0.0279 - 1s/epoch - 1s/step\n",
            "Epoch 2611/3000\n",
            "1/1 - 1s - loss: 0.0256 - val_loss: 0.0286 - 1s/epoch - 1s/step\n",
            "Epoch 2612/3000\n",
            "1/1 - 1s - loss: 0.0262 - val_loss: 0.0491 - 1s/epoch - 1s/step\n",
            "Epoch 2613/3000\n",
            "1/1 - 1s - loss: 0.0476 - val_loss: 0.0510 - 1s/epoch - 1s/step\n",
            "Epoch 2614/3000\n",
            "1/1 - 1s - loss: 0.0512 - val_loss: 0.0552 - 1s/epoch - 1s/step\n",
            "Epoch 2615/3000\n",
            "1/1 - 1s - loss: 0.0497 - val_loss: 0.0273 - 1s/epoch - 1s/step\n",
            "Epoch 2616/3000\n",
            "1/1 - 1s - loss: 0.0275 - val_loss: 0.0251 - 1s/epoch - 1s/step\n",
            "Epoch 2617/3000\n",
            "1/1 - 1s - loss: 0.0244 - val_loss: 0.0430 - 1s/epoch - 1s/step\n",
            "Epoch 2618/3000\n",
            "1/1 - 1s - loss: 0.0429 - val_loss: 0.0536 - 1s/epoch - 1s/step\n",
            "Epoch 2619/3000\n",
            "1/1 - 1s - loss: 0.0538 - val_loss: 0.1198 - 1s/epoch - 1s/step\n",
            "Epoch 2620/3000\n",
            "1/1 - 1s - loss: 0.1129 - val_loss: 0.0737 - 1s/epoch - 1s/step\n",
            "Epoch 2621/3000\n",
            "1/1 - 1s - loss: 0.0864 - val_loss: 0.0534 - 1s/epoch - 1s/step\n",
            "Epoch 2622/3000\n",
            "1/1 - 1s - loss: 0.0482 - val_loss: 0.0225 - 1s/epoch - 1s/step\n",
            "Epoch 2623/3000\n",
            "1/1 - 1s - loss: 0.0209 - val_loss: 0.0626 - 1s/epoch - 1s/step\n",
            "Epoch 2624/3000\n",
            "1/1 - 1s - loss: 0.0610 - val_loss: 0.2363 - 1s/epoch - 1s/step\n",
            "Epoch 2625/3000\n",
            "1/1 - 1s - loss: 0.2327 - val_loss: 0.1791 - 1s/epoch - 1s/step\n",
            "Epoch 2626/3000\n",
            "1/1 - 1s - loss: 0.2059 - val_loss: 0.2553 - 1s/epoch - 1s/step\n",
            "Epoch 2627/3000\n",
            "1/1 - 1s - loss: 0.2233 - val_loss: 0.0442 - 1s/epoch - 1s/step\n",
            "Epoch 2628/3000\n",
            "1/1 - 1s - loss: 0.0449 - val_loss: 0.1404 - 1s/epoch - 1s/step\n",
            "Epoch 2629/3000\n",
            "1/1 - 1s - loss: 0.1415 - val_loss: 0.4450 - 1s/epoch - 1s/step\n",
            "Epoch 2630/3000\n",
            "1/1 - 1s - loss: 0.4720 - val_loss: 0.1895 - 1s/epoch - 1s/step\n",
            "Epoch 2631/3000\n",
            "1/1 - 1s - loss: 0.1930 - val_loss: 0.0684 - 1s/epoch - 1s/step\n",
            "Epoch 2632/3000\n",
            "1/1 - 1s - loss: 0.0549 - val_loss: 0.1298 - 1s/epoch - 1s/step\n",
            "Epoch 2633/3000\n",
            "1/1 - 1s - loss: 0.1044 - val_loss: 0.1289 - 1s/epoch - 1s/step\n",
            "Epoch 2634/3000\n",
            "1/1 - 1s - loss: 0.1409 - val_loss: 0.0920 - 1s/epoch - 1s/step\n",
            "Epoch 2635/3000\n",
            "1/1 - 1s - loss: 0.0927 - val_loss: 0.0390 - 1s/epoch - 1s/step\n",
            "Epoch 2636/3000\n",
            "1/1 - 1s - loss: 0.0422 - val_loss: 0.0800 - 1s/epoch - 1s/step\n",
            "Epoch 2637/3000\n",
            "1/1 - 1s - loss: 0.0798 - val_loss: 0.1643 - 1s/epoch - 1s/step\n",
            "Epoch 2638/3000\n",
            "1/1 - 1s - loss: 0.1503 - val_loss: 0.0592 - 1s/epoch - 1s/step\n",
            "Epoch 2639/3000\n",
            "1/1 - 1s - loss: 0.0770 - val_loss: 0.0301 - 1s/epoch - 1s/step\n",
            "Epoch 2640/3000\n",
            "1/1 - 1s - loss: 0.0371 - val_loss: 0.0881 - 1s/epoch - 1s/step\n",
            "Epoch 2641/3000\n",
            "1/1 - 1s - loss: 0.0913 - val_loss: 0.1672 - 1s/epoch - 1s/step\n",
            "Epoch 2642/3000\n",
            "1/1 - 1s - loss: 0.1638 - val_loss: 0.7004 - 1s/epoch - 1s/step\n",
            "Epoch 2643/3000\n",
            "1/1 - 1s - loss: 0.6709 - val_loss: 0.2385 - 1s/epoch - 1s/step\n",
            "Epoch 2644/3000\n",
            "1/1 - 1s - loss: 0.3323 - val_loss: 0.0838 - 1s/epoch - 1s/step\n",
            "Epoch 2645/3000\n",
            "1/1 - 1s - loss: 0.1052 - val_loss: 0.3530 - 1s/epoch - 1s/step\n",
            "Epoch 2646/3000\n",
            "1/1 - 1s - loss: 0.3743 - val_loss: 0.4229 - 1s/epoch - 1s/step\n",
            "Epoch 2647/3000\n",
            "1/1 - 1s - loss: 0.4115 - val_loss: 1.0921 - 1s/epoch - 1s/step\n",
            "Epoch 2648/3000\n",
            "1/1 - 1s - loss: 1.0694 - val_loss: 0.3218 - 1s/epoch - 1s/step\n",
            "Epoch 2649/3000\n",
            "1/1 - 1s - loss: 0.3940 - val_loss: 0.4725 - 1s/epoch - 1s/step\n",
            "Epoch 2650/3000\n",
            "1/1 - 1s - loss: 0.5876 - val_loss: 0.8242 - 1s/epoch - 1s/step\n",
            "Epoch 2651/3000\n",
            "1/1 - 1s - loss: 0.8356 - val_loss: 0.1552 - 1s/epoch - 1s/step\n",
            "Epoch 2652/3000\n",
            "1/1 - 1s - loss: 0.1876 - val_loss: 0.9468 - 1s/epoch - 1s/step\n",
            "Epoch 2653/3000\n",
            "1/1 - 1s - loss: 0.9398 - val_loss: 2.8994 - 1s/epoch - 1s/step\n",
            "Epoch 2654/3000\n",
            "1/1 - 1s - loss: 2.9671 - val_loss: 0.5877 - 1s/epoch - 1s/step\n",
            "Epoch 2655/3000\n",
            "1/1 - 1s - loss: 0.5796 - val_loss: 2.2384 - 1s/epoch - 1s/step\n",
            "Epoch 2656/3000\n",
            "1/1 - 1s - loss: 2.8155 - val_loss: 2.3606 - 1s/epoch - 1s/step\n",
            "Epoch 2657/3000\n",
            "1/1 - 1s - loss: 2.3652 - val_loss: 0.6158 - 1s/epoch - 1s/step\n",
            "Epoch 2658/3000\n",
            "1/1 - 1s - loss: 0.7461 - val_loss: 7.0573 - 1s/epoch - 1s/step\n",
            "Epoch 2659/3000\n",
            "1/1 - 1s - loss: 7.0371 - val_loss: 26.5493 - 1s/epoch - 1s/step\n",
            "Epoch 2660/3000\n",
            "1/1 - 1s - loss: 28.3313 - val_loss: 22.0434 - 1s/epoch - 1s/step\n",
            "Epoch 2661/3000\n",
            "1/1 - 1s - loss: 22.1005 - val_loss: 19.2347 - 1s/epoch - 1s/step\n",
            "Epoch 2662/3000\n",
            "1/1 - 1s - loss: 23.1826 - val_loss: 14.1103 - 1s/epoch - 1s/step\n",
            "Epoch 2663/3000\n",
            "1/1 - 1s - loss: 15.2123 - val_loss: 11.5821 - 1s/epoch - 1s/step\n",
            "Epoch 2664/3000\n",
            "1/1 - 1s - loss: 11.7644 - val_loss: 7.5231 - 1s/epoch - 1s/step\n",
            "Epoch 2665/3000\n",
            "1/1 - 1s - loss: 10.0516 - val_loss: 7.6227 - 1s/epoch - 1s/step\n",
            "Epoch 2666/3000\n",
            "1/1 - 1s - loss: 9.6762 - val_loss: 17.8192 - 1s/epoch - 1s/step\n",
            "Epoch 2667/3000\n",
            "1/1 - 1s - loss: 19.4443 - val_loss: 10.7051 - 1s/epoch - 1s/step\n",
            "Epoch 2668/3000\n",
            "1/1 - 1s - loss: 15.0562 - val_loss: 18.7826 - 1s/epoch - 1s/step\n",
            "Epoch 2669/3000\n",
            "1/1 - 1s - loss: 21.5743 - val_loss: 8.1219 - 1s/epoch - 1s/step\n",
            "Epoch 2670/3000\n",
            "1/1 - 1s - loss: 8.0037 - val_loss: 19.0074 - 1s/epoch - 1s/step\n",
            "Epoch 2671/3000\n",
            "1/1 - 1s - loss: 19.7757 - val_loss: 12.3763 - 1s/epoch - 1s/step\n",
            "Epoch 2672/3000\n",
            "1/1 - 1s - loss: 11.5979 - val_loss: 10.3001 - 1s/epoch - 1s/step\n",
            "Epoch 2673/3000\n",
            "1/1 - 1s - loss: 9.3846 - val_loss: 13.8550 - 1s/epoch - 1s/step\n",
            "Epoch 2674/3000\n",
            "1/1 - 1s - loss: 14.6100 - val_loss: 8.5991 - 1s/epoch - 1s/step\n",
            "Epoch 2675/3000\n",
            "1/1 - 1s - loss: 9.4216 - val_loss: 5.6066 - 1s/epoch - 1s/step\n",
            "Epoch 2676/3000\n",
            "1/1 - 1s - loss: 5.5949 - val_loss: 12.0684 - 1s/epoch - 1s/step\n",
            "Epoch 2677/3000\n",
            "1/1 - 1s - loss: 11.9947 - val_loss: 1.7349 - 1s/epoch - 1s/step\n",
            "Epoch 2678/3000\n",
            "1/1 - 1s - loss: 2.7449 - val_loss: 5.3686 - 1s/epoch - 1s/step\n",
            "Epoch 2679/3000\n",
            "1/1 - 1s - loss: 7.5344 - val_loss: 5.9952 - 1s/epoch - 1s/step\n",
            "Epoch 2680/3000\n",
            "1/1 - 1s - loss: 7.8311 - val_loss: 2.3106 - 1s/epoch - 1s/step\n",
            "Epoch 2681/3000\n",
            "1/1 - 1s - loss: 3.0201 - val_loss: 6.1978 - 1s/epoch - 1s/step\n",
            "Epoch 2682/3000\n",
            "1/1 - 1s - loss: 6.4684 - val_loss: 2.2785 - 1s/epoch - 1s/step\n",
            "Epoch 2683/3000\n",
            "1/1 - 1s - loss: 2.3313 - val_loss: 2.4590 - 1s/epoch - 1s/step\n",
            "Epoch 2684/3000\n",
            "1/1 - 1s - loss: 2.4712 - val_loss: 4.3841 - 1s/epoch - 1s/step\n",
            "Epoch 2685/3000\n",
            "1/1 - 1s - loss: 4.4115 - val_loss: 2.3794 - 1s/epoch - 1s/step\n",
            "Epoch 2686/3000\n",
            "1/1 - 1s - loss: 2.1698 - val_loss: 2.2338 - 1s/epoch - 1s/step\n",
            "Epoch 2687/3000\n",
            "1/1 - 1s - loss: 2.1447 - val_loss: 2.3385 - 1s/epoch - 1s/step\n",
            "Epoch 2688/3000\n",
            "1/1 - 1s - loss: 2.3412 - val_loss: 0.6802 - 1s/epoch - 1s/step\n",
            "Epoch 2689/3000\n",
            "1/1 - 1s - loss: 0.7589 - val_loss: 2.2447 - 1s/epoch - 1s/step\n",
            "Epoch 2690/3000\n",
            "1/1 - 1s - loss: 2.5008 - val_loss: 1.4285 - 1s/epoch - 1s/step\n",
            "Epoch 2691/3000\n",
            "1/1 - 1s - loss: 1.6083 - val_loss: 1.6159 - 1s/epoch - 1s/step\n",
            "Epoch 2692/3000\n",
            "1/1 - 1s - loss: 1.7240 - val_loss: 1.3375 - 1s/epoch - 1s/step\n",
            "Epoch 2693/3000\n",
            "1/1 - 1s - loss: 1.4868 - val_loss: 0.8357 - 1s/epoch - 1s/step\n",
            "Epoch 2694/3000\n",
            "1/1 - 1s - loss: 0.8950 - val_loss: 1.6796 - 1s/epoch - 1s/step\n",
            "Epoch 2695/3000\n",
            "1/1 - 1s - loss: 1.6546 - val_loss: 1.3109 - 1s/epoch - 1s/step\n",
            "Epoch 2696/3000\n",
            "1/1 - 1s - loss: 1.2767 - val_loss: 1.1292 - 1s/epoch - 1s/step\n",
            "Epoch 2697/3000\n",
            "1/1 - 1s - loss: 1.1736 - val_loss: 1.2415 - 1s/epoch - 1s/step\n",
            "Epoch 2698/3000\n",
            "1/1 - 1s - loss: 1.2427 - val_loss: 0.6464 - 1s/epoch - 1s/step\n",
            "Epoch 2699/3000\n",
            "1/1 - 1s - loss: 0.6369 - val_loss: 0.9193 - 1s/epoch - 1s/step\n",
            "Epoch 2700/3000\n",
            "1/1 - 1s - loss: 1.0237 - val_loss: 0.7039 - 1s/epoch - 1s/step\n",
            "Epoch 2701/3000\n",
            "1/1 - 1s - loss: 0.8447 - val_loss: 0.7111 - 1s/epoch - 1s/step\n",
            "Epoch 2702/3000\n",
            "1/1 - 1s - loss: 0.7902 - val_loss: 0.5982 - 1s/epoch - 1s/step\n",
            "Epoch 2703/3000\n",
            "1/1 - 1s - loss: 0.7000 - val_loss: 0.4101 - 1s/epoch - 1s/step\n",
            "Epoch 2704/3000\n",
            "1/1 - 1s - loss: 0.5244 - val_loss: 0.6486 - 1s/epoch - 1s/step\n",
            "Epoch 2705/3000\n",
            "1/1 - 1s - loss: 0.7169 - val_loss: 0.5721 - 1s/epoch - 1s/step\n",
            "Epoch 2706/3000\n",
            "1/1 - 1s - loss: 0.6489 - val_loss: 0.4766 - 1s/epoch - 1s/step\n",
            "Epoch 2707/3000\n",
            "1/1 - 1s - loss: 0.5864 - val_loss: 0.4611 - 1s/epoch - 1s/step\n",
            "Epoch 2708/3000\n",
            "1/1 - 1s - loss: 0.5590 - val_loss: 0.3059 - 1s/epoch - 1s/step\n",
            "Epoch 2709/3000\n",
            "1/1 - 1s - loss: 0.4169 - val_loss: 0.3318 - 1s/epoch - 1s/step\n",
            "Epoch 2710/3000\n",
            "1/1 - 1s - loss: 0.5123 - val_loss: 0.3253 - 1s/epoch - 1s/step\n",
            "Epoch 2711/3000\n",
            "1/1 - 1s - loss: 0.5258 - val_loss: 0.3145 - 1s/epoch - 1s/step\n",
            "Epoch 2712/3000\n",
            "1/1 - 1s - loss: 0.4636 - val_loss: 0.2472 - 1s/epoch - 1s/step\n",
            "Epoch 2713/3000\n",
            "1/1 - 1s - loss: 0.3563 - val_loss: 0.2388 - 1s/epoch - 1s/step\n",
            "Epoch 2714/3000\n",
            "1/1 - 1s - loss: 0.3250 - val_loss: 0.3217 - 1s/epoch - 1s/step\n",
            "Epoch 2715/3000\n",
            "1/1 - 1s - loss: 0.3872 - val_loss: 0.3409 - 1s/epoch - 1s/step\n",
            "Epoch 2716/3000\n",
            "1/1 - 1s - loss: 0.3976 - val_loss: 0.2853 - 1s/epoch - 1s/step\n",
            "Epoch 2717/3000\n",
            "1/1 - 1s - loss: 0.3422 - val_loss: 0.2097 - 1s/epoch - 1s/step\n",
            "Epoch 2718/3000\n",
            "1/1 - 1s - loss: 0.2710 - val_loss: 0.1635 - 1s/epoch - 1s/step\n",
            "Epoch 2719/3000\n",
            "1/1 - 1s - loss: 0.2456 - val_loss: 0.1906 - 1s/epoch - 1s/step\n",
            "Epoch 2720/3000\n",
            "1/1 - 1s - loss: 0.2994 - val_loss: 0.1975 - 1s/epoch - 1s/step\n",
            "Epoch 2721/3000\n",
            "1/1 - 1s - loss: 0.3075 - val_loss: 0.1715 - 1s/epoch - 1s/step\n",
            "Epoch 2722/3000\n",
            "1/1 - 1s - loss: 0.2563 - val_loss: 0.1567 - 1s/epoch - 1s/step\n",
            "Epoch 2723/3000\n",
            "1/1 - 1s - loss: 0.2162 - val_loss: 0.1822 - 1s/epoch - 1s/step\n",
            "Epoch 2724/3000\n",
            "1/1 - 1s - loss: 0.2310 - val_loss: 0.2099 - 1s/epoch - 1s/step\n",
            "Epoch 2725/3000\n",
            "1/1 - 1s - loss: 0.2554 - val_loss: 0.1966 - 1s/epoch - 1s/step\n",
            "Epoch 2726/3000\n",
            "1/1 - 1s - loss: 0.2396 - val_loss: 0.1659 - 1s/epoch - 1s/step\n",
            "Epoch 2727/3000\n",
            "1/1 - 1s - loss: 0.2108 - val_loss: 0.1427 - 1s/epoch - 1s/step\n",
            "Epoch 2728/3000\n",
            "1/1 - 1s - loss: 0.1956 - val_loss: 0.1439 - 1s/epoch - 1s/step\n",
            "Epoch 2729/3000\n",
            "1/1 - 1s - loss: 0.2088 - val_loss: 0.1352 - 1s/epoch - 1s/step\n",
            "Epoch 2730/3000\n",
            "1/1 - 1s - loss: 0.2055 - val_loss: 0.1259 - 1s/epoch - 1s/step\n",
            "Epoch 2731/3000\n",
            "1/1 - 1s - loss: 0.1874 - val_loss: 0.1269 - 1s/epoch - 1s/step\n",
            "Epoch 2732/3000\n",
            "1/1 - 1s - loss: 0.1777 - val_loss: 0.1356 - 1s/epoch - 1s/step\n",
            "Epoch 2733/3000\n",
            "1/1 - 1s - loss: 0.1831 - val_loss: 0.1323 - 1s/epoch - 1s/step\n",
            "Epoch 2734/3000\n",
            "1/1 - 1s - loss: 0.1772 - val_loss: 0.1269 - 1s/epoch - 1s/step\n",
            "Epoch 2735/3000\n",
            "1/1 - 1s - loss: 0.1698 - val_loss: 0.1151 - 1s/epoch - 1s/step\n",
            "Epoch 2736/3000\n",
            "1/1 - 1s - loss: 0.1587 - val_loss: 0.1178 - 1s/epoch - 1s/step\n",
            "Epoch 2737/3000\n",
            "1/1 - 1s - loss: 0.1637 - val_loss: 0.1115 - 1s/epoch - 1s/step\n",
            "Epoch 2738/3000\n",
            "1/1 - 1s - loss: 0.1600 - val_loss: 0.1053 - 1s/epoch - 1s/step\n",
            "Epoch 2739/3000\n",
            "1/1 - 1s - loss: 0.1538 - val_loss: 0.0994 - 1s/epoch - 1s/step\n",
            "Epoch 2740/3000\n",
            "1/1 - 1s - loss: 0.1443 - val_loss: 0.1005 - 1s/epoch - 1s/step\n",
            "Epoch 2741/3000\n",
            "1/1 - 1s - loss: 0.1445 - val_loss: 0.1019 - 1s/epoch - 1s/step\n",
            "Epoch 2742/3000\n",
            "1/1 - 1s - loss: 0.1456 - val_loss: 0.0977 - 1s/epoch - 1s/step\n",
            "Epoch 2743/3000\n",
            "1/1 - 1s - loss: 0.1392 - val_loss: 0.0936 - 1s/epoch - 1s/step\n",
            "Epoch 2744/3000\n",
            "1/1 - 1s - loss: 0.1346 - val_loss: 0.0893 - 1s/epoch - 1s/step\n",
            "Epoch 2745/3000\n",
            "1/1 - 1s - loss: 0.1307 - val_loss: 0.0921 - 1s/epoch - 1s/step\n",
            "Epoch 2746/3000\n",
            "1/1 - 1s - loss: 0.1318 - val_loss: 0.0899 - 1s/epoch - 1s/step\n",
            "Epoch 2747/3000\n",
            "1/1 - 1s - loss: 0.1265 - val_loss: 0.0909 - 1s/epoch - 1s/step\n",
            "Epoch 2748/3000\n",
            "1/1 - 1s - loss: 0.1239 - val_loss: 0.0892 - 1s/epoch - 1s/step\n",
            "Epoch 2749/3000\n",
            "1/1 - 1s - loss: 0.1210 - val_loss: 0.0889 - 1s/epoch - 1s/step\n",
            "Epoch 2750/3000\n",
            "1/1 - 1s - loss: 0.1205 - val_loss: 0.0857 - 1s/epoch - 1s/step\n",
            "Epoch 2751/3000\n",
            "1/1 - 1s - loss: 0.1156 - val_loss: 0.0845 - 1s/epoch - 1s/step\n",
            "Epoch 2752/3000\n",
            "1/1 - 1s - loss: 0.1140 - val_loss: 0.0811 - 1s/epoch - 1s/step\n",
            "Epoch 2753/3000\n",
            "1/1 - 1s - loss: 0.1117 - val_loss: 0.0812 - 1s/epoch - 1s/step\n",
            "Epoch 2754/3000\n",
            "1/1 - 1s - loss: 0.1115 - val_loss: 0.0792 - 1s/epoch - 1s/step\n",
            "Epoch 2755/3000\n",
            "1/1 - 1s - loss: 0.1072 - val_loss: 0.0810 - 1s/epoch - 1s/step\n",
            "Epoch 2756/3000\n",
            "1/1 - 1s - loss: 0.1056 - val_loss: 0.0803 - 1s/epoch - 1s/step\n",
            "Epoch 2757/3000\n",
            "1/1 - 1s - loss: 0.1037 - val_loss: 0.0796 - 1s/epoch - 1s/step\n",
            "Epoch 2758/3000\n",
            "1/1 - 1s - loss: 0.1029 - val_loss: 0.0780 - 1s/epoch - 1s/step\n",
            "Epoch 2759/3000\n",
            "1/1 - 1s - loss: 0.1004 - val_loss: 0.0775 - 1s/epoch - 1s/step\n",
            "Epoch 2760/3000\n",
            "1/1 - 1s - loss: 0.0986 - val_loss: 0.0752 - 1s/epoch - 1s/step\n",
            "Epoch 2761/3000\n",
            "1/1 - 1s - loss: 0.0971 - val_loss: 0.0735 - 1s/epoch - 1s/step\n",
            "Epoch 2762/3000\n",
            "1/1 - 1s - loss: 0.0959 - val_loss: 0.0722 - 1s/epoch - 1s/step\n",
            "Epoch 2763/3000\n",
            "1/1 - 1s - loss: 0.0935 - val_loss: 0.0730 - 1s/epoch - 1s/step\n",
            "Epoch 2764/3000\n",
            "1/1 - 1s - loss: 0.0925 - val_loss: 0.0720 - 1s/epoch - 1s/step\n",
            "Epoch 2765/3000\n",
            "1/1 - 1s - loss: 0.0912 - val_loss: 0.0706 - 1s/epoch - 1s/step\n",
            "Epoch 2766/3000\n",
            "1/1 - 1s - loss: 0.0898 - val_loss: 0.0696 - 1s/epoch - 1s/step\n",
            "Epoch 2767/3000\n",
            "1/1 - 1s - loss: 0.0878 - val_loss: 0.0698 - 1s/epoch - 1s/step\n",
            "Epoch 2768/3000\n",
            "1/1 - 1s - loss: 0.0869 - val_loss: 0.0689 - 1s/epoch - 1s/step\n",
            "Epoch 2769/3000\n",
            "1/1 - 1s - loss: 0.0857 - val_loss: 0.0678 - 1s/epoch - 1s/step\n",
            "Epoch 2770/3000\n",
            "1/1 - 1s - loss: 0.0844 - val_loss: 0.0670 - 1s/epoch - 1s/step\n",
            "Epoch 2771/3000\n",
            "1/1 - 1s - loss: 0.0828 - val_loss: 0.0669 - 1s/epoch - 1s/step\n",
            "Epoch 2772/3000\n",
            "1/1 - 1s - loss: 0.0819 - val_loss: 0.0655 - 1s/epoch - 1s/step\n",
            "Epoch 2773/3000\n",
            "1/1 - 1s - loss: 0.0807 - val_loss: 0.0640 - 1s/epoch - 1s/step\n",
            "Epoch 2774/3000\n",
            "1/1 - 1s - loss: 0.0795 - val_loss: 0.0636 - 1s/epoch - 1s/step\n",
            "Epoch 2775/3000\n",
            "1/1 - 1s - loss: 0.0783 - val_loss: 0.0635 - 1s/epoch - 1s/step\n",
            "Epoch 2776/3000\n",
            "1/1 - 1s - loss: 0.0775 - val_loss: 0.0626 - 1s/epoch - 1s/step\n",
            "Epoch 2777/3000\n",
            "1/1 - 1s - loss: 0.0763 - val_loss: 0.0619 - 1s/epoch - 1s/step\n",
            "Epoch 2778/3000\n",
            "1/1 - 1s - loss: 0.0753 - val_loss: 0.0618 - 1s/epoch - 1s/step\n",
            "Epoch 2779/3000\n",
            "1/1 - 1s - loss: 0.0743 - val_loss: 0.0616 - 1s/epoch - 1s/step\n",
            "Epoch 2780/3000\n",
            "1/1 - 1s - loss: 0.0735 - val_loss: 0.0605 - 1s/epoch - 1s/step\n",
            "Epoch 2781/3000\n",
            "1/1 - 1s - loss: 0.0725 - val_loss: 0.0595 - 1s/epoch - 1s/step\n",
            "Epoch 2782/3000\n",
            "1/1 - 1s - loss: 0.0716 - val_loss: 0.0591 - 1s/epoch - 1s/step\n",
            "Epoch 2783/3000\n",
            "1/1 - 1s - loss: 0.0707 - val_loss: 0.0586 - 1s/epoch - 1s/step\n",
            "Epoch 2784/3000\n",
            "1/1 - 1s - loss: 0.0699 - val_loss: 0.0577 - 1s/epoch - 1s/step\n",
            "Epoch 2785/3000\n",
            "1/1 - 1s - loss: 0.0690 - val_loss: 0.0571 - 1s/epoch - 1s/step\n",
            "Epoch 2786/3000\n",
            "1/1 - 1s - loss: 0.0682 - val_loss: 0.0570 - 1s/epoch - 1s/step\n",
            "Epoch 2787/3000\n",
            "1/1 - 1s - loss: 0.0675 - val_loss: 0.0568 - 1s/epoch - 1s/step\n",
            "Epoch 2788/3000\n",
            "1/1 - 1s - loss: 0.0667 - val_loss: 0.0562 - 1s/epoch - 1s/step\n",
            "Epoch 2789/3000\n",
            "1/1 - 1s - loss: 0.0659 - val_loss: 0.0558 - 1s/epoch - 1s/step\n",
            "Epoch 2790/3000\n",
            "1/1 - 1s - loss: 0.0652 - val_loss: 0.0556 - 1s/epoch - 1s/step\n",
            "Epoch 2791/3000\n",
            "1/1 - 1s - loss: 0.0645 - val_loss: 0.0551 - 1s/epoch - 1s/step\n",
            "Epoch 2792/3000\n",
            "1/1 - 1s - loss: 0.0638 - val_loss: 0.0544 - 1s/epoch - 1s/step\n",
            "Epoch 2793/3000\n",
            "1/1 - 1s - loss: 0.0632 - val_loss: 0.0540 - 1s/epoch - 1s/step\n",
            "Epoch 2794/3000\n",
            "1/1 - 1s - loss: 0.0625 - val_loss: 0.0537 - 1s/epoch - 1s/step\n",
            "Epoch 2795/3000\n",
            "1/1 - 1s - loss: 0.0619 - val_loss: 0.0532 - 1s/epoch - 1s/step\n",
            "Epoch 2796/3000\n",
            "1/1 - 1s - loss: 0.0613 - val_loss: 0.0528 - 1s/epoch - 1s/step\n",
            "Epoch 2797/3000\n",
            "1/1 - 1s - loss: 0.0607 - val_loss: 0.0526 - 1s/epoch - 1s/step\n",
            "Epoch 2798/3000\n",
            "1/1 - 1s - loss: 0.0601 - val_loss: 0.0524 - 1s/epoch - 1s/step\n",
            "Epoch 2799/3000\n",
            "1/1 - 1s - loss: 0.0595 - val_loss: 0.0519 - 1s/epoch - 1s/step\n",
            "Epoch 2800/3000\n",
            "1/1 - 1s - loss: 0.0589 - val_loss: 0.0515 - 1s/epoch - 1s/step\n",
            "Epoch 2801/3000\n",
            "1/1 - 1s - loss: 0.0584 - val_loss: 0.0513 - 1s/epoch - 1s/step\n",
            "Epoch 2802/3000\n",
            "1/1 - 1s - loss: 0.0579 - val_loss: 0.0510 - 1s/epoch - 1s/step\n",
            "Epoch 2803/3000\n",
            "1/1 - 1s - loss: 0.0573 - val_loss: 0.0504 - 1s/epoch - 1s/step\n",
            "Epoch 2804/3000\n",
            "1/1 - 1s - loss: 0.0568 - val_loss: 0.0501 - 1s/epoch - 1s/step\n",
            "Epoch 2805/3000\n",
            "1/1 - 1s - loss: 0.0563 - val_loss: 0.0499 - 1s/epoch - 1s/step\n",
            "Epoch 2806/3000\n",
            "1/1 - 1s - loss: 0.0558 - val_loss: 0.0496 - 1s/epoch - 1s/step\n",
            "Epoch 2807/3000\n",
            "1/1 - 1s - loss: 0.0553 - val_loss: 0.0492 - 1s/epoch - 1s/step\n",
            "Epoch 2808/3000\n",
            "1/1 - 1s - loss: 0.0549 - val_loss: 0.0490 - 1s/epoch - 1s/step\n",
            "Epoch 2809/3000\n",
            "1/1 - 1s - loss: 0.0544 - val_loss: 0.0488 - 1s/epoch - 1s/step\n",
            "Epoch 2810/3000\n",
            "1/1 - 1s - loss: 0.0540 - val_loss: 0.0484 - 1s/epoch - 1s/step\n",
            "Epoch 2811/3000\n",
            "1/1 - 1s - loss: 0.0535 - val_loss: 0.0481 - 1s/epoch - 1s/step\n",
            "Epoch 2812/3000\n",
            "1/1 - 1s - loss: 0.0531 - val_loss: 0.0478 - 1s/epoch - 1s/step\n",
            "Epoch 2813/3000\n",
            "1/1 - 1s - loss: 0.0527 - val_loss: 0.0475 - 1s/epoch - 1s/step\n",
            "Epoch 2814/3000\n",
            "1/1 - 1s - loss: 0.0523 - val_loss: 0.0471 - 1s/epoch - 1s/step\n",
            "Epoch 2815/3000\n",
            "1/1 - 1s - loss: 0.0519 - val_loss: 0.0468 - 1s/epoch - 1s/step\n",
            "Epoch 2816/3000\n",
            "1/1 - 1s - loss: 0.0514 - val_loss: 0.0466 - 1s/epoch - 1s/step\n",
            "Epoch 2817/3000\n",
            "1/1 - 1s - loss: 0.0510 - val_loss: 0.0464 - 1s/epoch - 1s/step\n",
            "Epoch 2818/3000\n",
            "1/1 - 1s - loss: 0.0507 - val_loss: 0.0461 - 1s/epoch - 1s/step\n",
            "Epoch 2819/3000\n",
            "1/1 - 1s - loss: 0.0503 - val_loss: 0.0459 - 1s/epoch - 1s/step\n",
            "Epoch 2820/3000\n",
            "1/1 - 1s - loss: 0.0499 - val_loss: 0.0457 - 1s/epoch - 1s/step\n",
            "Epoch 2821/3000\n",
            "1/1 - 1s - loss: 0.0496 - val_loss: 0.0454 - 1s/epoch - 1s/step\n",
            "Epoch 2822/3000\n",
            "1/1 - 1s - loss: 0.0492 - val_loss: 0.0451 - 1s/epoch - 1s/step\n",
            "Epoch 2823/3000\n",
            "1/1 - 1s - loss: 0.0489 - val_loss: 0.0450 - 1s/epoch - 1s/step\n",
            "Epoch 2824/3000\n",
            "1/1 - 1s - loss: 0.0485 - val_loss: 0.0447 - 1s/epoch - 1s/step\n",
            "Epoch 2825/3000\n",
            "1/1 - 1s - loss: 0.0482 - val_loss: 0.0445 - 1s/epoch - 1s/step\n",
            "Epoch 2826/3000\n",
            "1/1 - 1s - loss: 0.0478 - val_loss: 0.0444 - 1s/epoch - 1s/step\n",
            "Epoch 2827/3000\n",
            "1/1 - 1s - loss: 0.0474 - val_loss: 0.0442 - 1s/epoch - 1s/step\n",
            "Epoch 2828/3000\n",
            "1/1 - 1s - loss: 0.0473 - val_loss: 0.0441 - 1s/epoch - 1s/step\n",
            "Epoch 2829/3000\n",
            "1/1 - 1s - loss: 0.0468 - val_loss: 0.0438 - 1s/epoch - 1s/step\n",
            "Epoch 2830/3000\n",
            "1/1 - 1s - loss: 0.0465 - val_loss: 0.0436 - 1s/epoch - 1s/step\n",
            "Epoch 2831/3000\n",
            "1/1 - 1s - loss: 0.0463 - val_loss: 0.0434 - 1s/epoch - 1s/step\n",
            "Epoch 2832/3000\n",
            "1/1 - 1s - loss: 0.0460 - val_loss: 0.0431 - 1s/epoch - 1s/step\n",
            "Epoch 2833/3000\n",
            "1/1 - 1s - loss: 0.0457 - val_loss: 0.0429 - 1s/epoch - 1s/step\n",
            "Epoch 2834/3000\n",
            "1/1 - 1s - loss: 0.0455 - val_loss: 0.0428 - 1s/epoch - 1s/step\n",
            "Epoch 2835/3000\n",
            "1/1 - 1s - loss: 0.0452 - val_loss: 0.0426 - 1s/epoch - 1s/step\n",
            "Epoch 2836/3000\n",
            "1/1 - 1s - loss: 0.0449 - val_loss: 0.0424 - 1s/epoch - 1s/step\n",
            "Epoch 2837/3000\n",
            "1/1 - 1s - loss: 0.0447 - val_loss: 0.0421 - 1s/epoch - 1s/step\n",
            "Epoch 2838/3000\n",
            "1/1 - 1s - loss: 0.0444 - val_loss: 0.0420 - 1s/epoch - 1s/step\n",
            "Epoch 2839/3000\n",
            "1/1 - 1s - loss: 0.0441 - val_loss: 0.0417 - 1s/epoch - 1s/step\n",
            "Epoch 2840/3000\n",
            "1/1 - 1s - loss: 0.0439 - val_loss: 0.0415 - 1s/epoch - 1s/step\n",
            "Epoch 2841/3000\n",
            "1/1 - 1s - loss: 0.0436 - val_loss: 0.0414 - 1s/epoch - 1s/step\n",
            "Epoch 2842/3000\n",
            "1/1 - 1s - loss: 0.0434 - val_loss: 0.0412 - 1s/epoch - 1s/step\n",
            "Epoch 2843/3000\n",
            "1/1 - 1s - loss: 0.0431 - val_loss: 0.0410 - 1s/epoch - 1s/step\n",
            "Epoch 2844/3000\n",
            "1/1 - 1s - loss: 0.0429 - val_loss: 0.0408 - 1s/epoch - 1s/step\n",
            "Epoch 2845/3000\n",
            "1/1 - 1s - loss: 0.0427 - val_loss: 0.0406 - 1s/epoch - 1s/step\n",
            "Epoch 2846/3000\n",
            "1/1 - 1s - loss: 0.0424 - val_loss: 0.0404 - 1s/epoch - 1s/step\n",
            "Epoch 2847/3000\n",
            "1/1 - 1s - loss: 0.0422 - val_loss: 0.0402 - 1s/epoch - 1s/step\n",
            "Epoch 2848/3000\n",
            "1/1 - 1s - loss: 0.0420 - val_loss: 0.0400 - 1s/epoch - 1s/step\n",
            "Epoch 2849/3000\n",
            "1/1 - 1s - loss: 0.0418 - val_loss: 0.0398 - 1s/epoch - 1s/step\n",
            "Epoch 2850/3000\n",
            "1/1 - 1s - loss: 0.0416 - val_loss: 0.0396 - 1s/epoch - 1s/step\n",
            "Epoch 2851/3000\n",
            "1/1 - 1s - loss: 0.0413 - val_loss: 0.0394 - 1s/epoch - 1s/step\n",
            "Epoch 2852/3000\n",
            "1/1 - 1s - loss: 0.0411 - val_loss: 0.0392 - 1s/epoch - 1s/step\n",
            "Epoch 2853/3000\n",
            "1/1 - 1s - loss: 0.0409 - val_loss: 0.0391 - 1s/epoch - 1s/step\n",
            "Epoch 2854/3000\n",
            "1/1 - 1s - loss: 0.0407 - val_loss: 0.0389 - 1s/epoch - 1s/step\n",
            "Epoch 2855/3000\n",
            "1/1 - 1s - loss: 0.0405 - val_loss: 0.0388 - 1s/epoch - 1s/step\n",
            "Epoch 2856/3000\n",
            "1/1 - 1s - loss: 0.0403 - val_loss: 0.0386 - 1s/epoch - 1s/step\n",
            "Epoch 2857/3000\n",
            "1/1 - 1s - loss: 0.0401 - val_loss: 0.0385 - 1s/epoch - 1s/step\n",
            "Epoch 2858/3000\n",
            "1/1 - 1s - loss: 0.0399 - val_loss: 0.0383 - 1s/epoch - 1s/step\n",
            "Epoch 2859/3000\n",
            "1/1 - 1s - loss: 0.0397 - val_loss: 0.0381 - 1s/epoch - 1s/step\n",
            "Epoch 2860/3000\n",
            "1/1 - 1s - loss: 0.0395 - val_loss: 0.0380 - 1s/epoch - 1s/step\n",
            "Epoch 2861/3000\n",
            "1/1 - 1s - loss: 0.0393 - val_loss: 0.0378 - 1s/epoch - 1s/step\n",
            "Epoch 2862/3000\n",
            "1/1 - 1s - loss: 0.0391 - val_loss: 0.0376 - 1s/epoch - 1s/step\n",
            "Epoch 2863/3000\n",
            "1/1 - 1s - loss: 0.0390 - val_loss: 0.0375 - 1s/epoch - 1s/step\n",
            "Epoch 2864/3000\n",
            "1/1 - 1s - loss: 0.0388 - val_loss: 0.0373 - 1s/epoch - 1s/step\n",
            "Epoch 2865/3000\n",
            "1/1 - 1s - loss: 0.0386 - val_loss: 0.0372 - 1s/epoch - 1s/step\n",
            "Epoch 2866/3000\n",
            "1/1 - 1s - loss: 0.0384 - val_loss: 0.0370 - 1s/epoch - 1s/step\n",
            "Epoch 2867/3000\n",
            "1/1 - 1s - loss: 0.0382 - val_loss: 0.0369 - 1s/epoch - 1s/step\n",
            "Epoch 2868/3000\n",
            "1/1 - 1s - loss: 0.0381 - val_loss: 0.0367 - 1s/epoch - 1s/step\n",
            "Epoch 2869/3000\n",
            "1/1 - 1s - loss: 0.0379 - val_loss: 0.0365 - 1s/epoch - 1s/step\n",
            "Epoch 2870/3000\n",
            "1/1 - 1s - loss: 0.0377 - val_loss: 0.0364 - 1s/epoch - 1s/step\n",
            "Epoch 2871/3000\n",
            "1/1 - 1s - loss: 0.0375 - val_loss: 0.0362 - 1s/epoch - 1s/step\n",
            "Epoch 2872/3000\n",
            "1/1 - 1s - loss: 0.0374 - val_loss: 0.0360 - 1s/epoch - 1s/step\n",
            "Epoch 2873/3000\n",
            "1/1 - 1s - loss: 0.0372 - val_loss: 0.0359 - 1s/epoch - 1s/step\n",
            "Epoch 2874/3000\n",
            "1/1 - 1s - loss: 0.0371 - val_loss: 0.0358 - 1s/epoch - 1s/step\n",
            "Epoch 2875/3000\n",
            "1/1 - 1s - loss: 0.0369 - val_loss: 0.0356 - 1s/epoch - 1s/step\n",
            "Epoch 2876/3000\n",
            "1/1 - 1s - loss: 0.0367 - val_loss: 0.0355 - 1s/epoch - 1s/step\n",
            "Epoch 2877/3000\n",
            "1/1 - 1s - loss: 0.0366 - val_loss: 0.0353 - 1s/epoch - 1s/step\n",
            "Epoch 2878/3000\n",
            "1/1 - 1s - loss: 0.0364 - val_loss: 0.0352 - 1s/epoch - 1s/step\n",
            "Epoch 2879/3000\n",
            "1/1 - 1s - loss: 0.0363 - val_loss: 0.0350 - 1s/epoch - 1s/step\n",
            "Epoch 2880/3000\n",
            "1/1 - 1s - loss: 0.0361 - val_loss: 0.0349 - 1s/epoch - 1s/step\n",
            "Epoch 2881/3000\n",
            "1/1 - 1s - loss: 0.0360 - val_loss: 0.0348 - 1s/epoch - 1s/step\n",
            "Epoch 2882/3000\n",
            "1/1 - 1s - loss: 0.0358 - val_loss: 0.0346 - 1s/epoch - 1s/step\n",
            "Epoch 2883/3000\n",
            "1/1 - 1s - loss: 0.0357 - val_loss: 0.0345 - 1s/epoch - 1s/step\n",
            "Epoch 2884/3000\n",
            "1/1 - 1s - loss: 0.0356 - val_loss: 0.0344 - 1s/epoch - 1s/step\n",
            "Epoch 2885/3000\n",
            "1/1 - 1s - loss: 0.0354 - val_loss: 0.0342 - 1s/epoch - 1s/step\n",
            "Epoch 2886/3000\n",
            "1/1 - 1s - loss: 0.0353 - val_loss: 0.0341 - 1s/epoch - 1s/step\n",
            "Epoch 2887/3000\n",
            "1/1 - 1s - loss: 0.0352 - val_loss: 0.0340 - 1s/epoch - 1s/step\n",
            "Epoch 2888/3000\n",
            "1/1 - 1s - loss: 0.0350 - val_loss: 0.0339 - 1s/epoch - 1s/step\n",
            "Epoch 2889/3000\n",
            "1/1 - 1s - loss: 0.0349 - val_loss: 0.0337 - 1s/epoch - 1s/step\n",
            "Epoch 2890/3000\n",
            "1/1 - 1s - loss: 0.0347 - val_loss: 0.0336 - 1s/epoch - 1s/step\n",
            "Epoch 2891/3000\n",
            "1/1 - 1s - loss: 0.0346 - val_loss: 0.0335 - 1s/epoch - 1s/step\n",
            "Epoch 2892/3000\n",
            "1/1 - 1s - loss: 0.0345 - val_loss: 0.0334 - 1s/epoch - 1s/step\n",
            "Epoch 2893/3000\n",
            "1/1 - 1s - loss: 0.0343 - val_loss: 0.0333 - 1s/epoch - 1s/step\n",
            "Epoch 2894/3000\n",
            "1/1 - 1s - loss: 0.0342 - val_loss: 0.0331 - 1s/epoch - 1s/step\n",
            "Epoch 2895/3000\n",
            "1/1 - 1s - loss: 0.0341 - val_loss: 0.0330 - 1s/epoch - 1s/step\n",
            "Epoch 2896/3000\n",
            "1/1 - 1s - loss: 0.0339 - val_loss: 0.0329 - 1s/epoch - 1s/step\n",
            "Epoch 2897/3000\n",
            "1/1 - 1s - loss: 0.0338 - val_loss: 0.0327 - 1s/epoch - 1s/step\n",
            "Epoch 2898/3000\n",
            "1/1 - 1s - loss: 0.0337 - val_loss: 0.0326 - 1s/epoch - 1s/step\n",
            "Epoch 2899/3000\n",
            "1/1 - 1s - loss: 0.0335 - val_loss: 0.0325 - 1s/epoch - 1s/step\n",
            "Epoch 2900/3000\n",
            "1/1 - 1s - loss: 0.0334 - val_loss: 0.0324 - 1s/epoch - 1s/step\n",
            "Epoch 2901/3000\n",
            "1/1 - 1s - loss: 0.0333 - val_loss: 0.0322 - 1s/epoch - 1s/step\n",
            "Epoch 2902/3000\n",
            "1/1 - 1s - loss: 0.0332 - val_loss: 0.0322 - 1s/epoch - 1s/step\n",
            "Epoch 2903/3000\n",
            "1/1 - 1s - loss: 0.0330 - val_loss: 0.0320 - 1s/epoch - 1s/step\n",
            "Epoch 2904/3000\n",
            "1/1 - 1s - loss: 0.0329 - val_loss: 0.0319 - 1s/epoch - 1s/step\n",
            "Epoch 2905/3000\n",
            "1/1 - 1s - loss: 0.0328 - val_loss: 0.0318 - 1s/epoch - 1s/step\n",
            "Epoch 2906/3000\n",
            "1/1 - 1s - loss: 0.0327 - val_loss: 0.0317 - 1s/epoch - 1s/step\n",
            "Epoch 2907/3000\n",
            "1/1 - 1s - loss: 0.0326 - val_loss: 0.0316 - 1s/epoch - 1s/step\n",
            "Epoch 2908/3000\n",
            "1/1 - 1s - loss: 0.0325 - val_loss: 0.0315 - 1s/epoch - 1s/step\n",
            "Epoch 2909/3000\n",
            "1/1 - 1s - loss: 0.0323 - val_loss: 0.0314 - 1s/epoch - 1s/step\n",
            "Epoch 2910/3000\n",
            "1/1 - 1s - loss: 0.0322 - val_loss: 0.0313 - 1s/epoch - 1s/step\n",
            "Epoch 2911/3000\n",
            "1/1 - 1s - loss: 0.0321 - val_loss: 0.0312 - 1s/epoch - 1s/step\n",
            "Epoch 2912/3000\n",
            "1/1 - 1s - loss: 0.0320 - val_loss: 0.0311 - 1s/epoch - 1s/step\n",
            "Epoch 2913/3000\n",
            "1/1 - 1s - loss: 0.0319 - val_loss: 0.0310 - 1s/epoch - 1s/step\n",
            "Epoch 2914/3000\n",
            "1/1 - 1s - loss: 0.0318 - val_loss: 0.0309 - 1s/epoch - 1s/step\n",
            "Epoch 2915/3000\n",
            "1/1 - 1s - loss: 0.0317 - val_loss: 0.0308 - 1s/epoch - 1s/step\n",
            "Epoch 2916/3000\n",
            "1/1 - 1s - loss: 0.0316 - val_loss: 0.0307 - 1s/epoch - 1s/step\n",
            "Epoch 2917/3000\n",
            "1/1 - 1s - loss: 0.0315 - val_loss: 0.0306 - 1s/epoch - 1s/step\n",
            "Epoch 2918/3000\n",
            "1/1 - 1s - loss: 0.0314 - val_loss: 0.0305 - 1s/epoch - 1s/step\n",
            "Epoch 2919/3000\n",
            "1/1 - 1s - loss: 0.0313 - val_loss: 0.0304 - 1s/epoch - 1s/step\n",
            "Epoch 2920/3000\n",
            "1/1 - 1s - loss: 0.0312 - val_loss: 0.0304 - 1s/epoch - 1s/step\n",
            "Epoch 2921/3000\n",
            "1/1 - 1s - loss: 0.0311 - val_loss: 0.0302 - 1s/epoch - 1s/step\n",
            "Epoch 2922/3000\n",
            "1/1 - 1s - loss: 0.0310 - val_loss: 0.0302 - 1s/epoch - 1s/step\n",
            "Epoch 2923/3000\n",
            "1/1 - 1s - loss: 0.0309 - val_loss: 0.0301 - 1s/epoch - 1s/step\n",
            "Epoch 2924/3000\n",
            "1/1 - 1s - loss: 0.0308 - val_loss: 0.0300 - 1s/epoch - 1s/step\n",
            "Epoch 2925/3000\n",
            "1/1 - 1s - loss: 0.0307 - val_loss: 0.0299 - 1s/epoch - 1s/step\n",
            "Epoch 2926/3000\n",
            "1/1 - 1s - loss: 0.0306 - val_loss: 0.0298 - 1s/epoch - 1s/step\n",
            "Epoch 2927/3000\n",
            "1/1 - 1s - loss: 0.0305 - val_loss: 0.0297 - 1s/epoch - 1s/step\n",
            "Epoch 2928/3000\n",
            "1/1 - 1s - loss: 0.0304 - val_loss: 0.0296 - 1s/epoch - 1s/step\n",
            "Epoch 2929/3000\n",
            "1/1 - 1s - loss: 0.0303 - val_loss: 0.0296 - 1s/epoch - 1s/step\n",
            "Epoch 2930/3000\n",
            "1/1 - 1s - loss: 0.0302 - val_loss: 0.0295 - 1s/epoch - 1s/step\n",
            "Epoch 2931/3000\n",
            "1/1 - 1s - loss: 0.0301 - val_loss: 0.0294 - 1s/epoch - 1s/step\n",
            "Epoch 2932/3000\n",
            "1/1 - 1s - loss: 0.0300 - val_loss: 0.0293 - 1s/epoch - 1s/step\n",
            "Epoch 2933/3000\n",
            "1/1 - 1s - loss: 0.0299 - val_loss: 0.0292 - 1s/epoch - 1s/step\n",
            "Epoch 2934/3000\n",
            "1/1 - 1s - loss: 0.0298 - val_loss: 0.0291 - 1s/epoch - 1s/step\n",
            "Epoch 2935/3000\n",
            "1/1 - 1s - loss: 0.0298 - val_loss: 0.0291 - 1s/epoch - 1s/step\n",
            "Epoch 2936/3000\n",
            "1/1 - 1s - loss: 0.0297 - val_loss: 0.0290 - 1s/epoch - 1s/step\n",
            "Epoch 2937/3000\n",
            "1/1 - 1s - loss: 0.0296 - val_loss: 0.0289 - 1s/epoch - 1s/step\n",
            "Epoch 2938/3000\n",
            "1/1 - 1s - loss: 0.0295 - val_loss: 0.0288 - 1s/epoch - 1s/step\n",
            "Epoch 2939/3000\n",
            "1/1 - 1s - loss: 0.0294 - val_loss: 0.0287 - 1s/epoch - 1s/step\n",
            "Epoch 2940/3000\n",
            "1/1 - 1s - loss: 0.0293 - val_loss: 0.0286 - 1s/epoch - 1s/step\n",
            "Epoch 2941/3000\n",
            "1/1 - 1s - loss: 0.0292 - val_loss: 0.0286 - 1s/epoch - 1s/step\n",
            "Epoch 2942/3000\n",
            "1/1 - 1s - loss: 0.0291 - val_loss: 0.0285 - 1s/epoch - 1s/step\n",
            "Epoch 2943/3000\n",
            "1/1 - 1s - loss: 0.0291 - val_loss: 0.0284 - 1s/epoch - 1s/step\n",
            "Epoch 2944/3000\n",
            "1/1 - 1s - loss: 0.0290 - val_loss: 0.0283 - 1s/epoch - 1s/step\n",
            "Epoch 2945/3000\n",
            "1/1 - 1s - loss: 0.0289 - val_loss: 0.0283 - 1s/epoch - 1s/step\n",
            "Epoch 2946/3000\n",
            "1/1 - 1s - loss: 0.0288 - val_loss: 0.0282 - 1s/epoch - 1s/step\n",
            "Epoch 2947/3000\n",
            "1/1 - 1s - loss: 0.0287 - val_loss: 0.0281 - 1s/epoch - 1s/step\n",
            "Epoch 2948/3000\n",
            "1/1 - 1s - loss: 0.0286 - val_loss: 0.0281 - 1s/epoch - 1s/step\n",
            "Epoch 2949/3000\n",
            "1/1 - 1s - loss: 0.0286 - val_loss: 0.0280 - 1s/epoch - 1s/step\n",
            "Epoch 2950/3000\n",
            "1/1 - 1s - loss: 0.0285 - val_loss: 0.0279 - 1s/epoch - 1s/step\n",
            "Epoch 2951/3000\n",
            "1/1 - 1s - loss: 0.0284 - val_loss: 0.0279 - 1s/epoch - 1s/step\n",
            "Epoch 2952/3000\n",
            "1/1 - 1s - loss: 0.0283 - val_loss: 0.0278 - 1s/epoch - 1s/step\n",
            "Epoch 2953/3000\n",
            "1/1 - 1s - loss: 0.0283 - val_loss: 0.0277 - 1s/epoch - 1s/step\n",
            "Epoch 2954/3000\n",
            "1/1 - 1s - loss: 0.0282 - val_loss: 0.0277 - 1s/epoch - 1s/step\n",
            "Epoch 2955/3000\n",
            "1/1 - 1s - loss: 0.0281 - val_loss: 0.0276 - 1s/epoch - 1s/step\n",
            "Epoch 2956/3000\n",
            "1/1 - 1s - loss: 0.0281 - val_loss: 0.0275 - 1s/epoch - 1s/step\n",
            "Epoch 2957/3000\n",
            "1/1 - 1s - loss: 0.0280 - val_loss: 0.0275 - 1s/epoch - 1s/step\n",
            "Epoch 2958/3000\n",
            "1/1 - 1s - loss: 0.0279 - val_loss: 0.0274 - 1s/epoch - 1s/step\n",
            "Epoch 2959/3000\n",
            "1/1 - 1s - loss: 0.0279 - val_loss: 0.0274 - 1s/epoch - 1s/step\n",
            "Epoch 2960/3000\n",
            "1/1 - 1s - loss: 0.0278 - val_loss: 0.0273 - 1s/epoch - 1s/step\n",
            "Epoch 2961/3000\n",
            "1/1 - 1s - loss: 0.0277 - val_loss: 0.0273 - 1s/epoch - 1s/step\n",
            "Epoch 2962/3000\n",
            "1/1 - 1s - loss: 0.0277 - val_loss: 0.0272 - 1s/epoch - 1s/step\n",
            "Epoch 2963/3000\n",
            "1/1 - 1s - loss: 0.0276 - val_loss: 0.0271 - 1s/epoch - 1s/step\n",
            "Epoch 2964/3000\n",
            "1/1 - 1s - loss: 0.0275 - val_loss: 0.0271 - 1s/epoch - 1s/step\n",
            "Epoch 2965/3000\n",
            "1/1 - 1s - loss: 0.0275 - val_loss: 0.0270 - 1s/epoch - 1s/step\n",
            "Epoch 2966/3000\n",
            "1/1 - 1s - loss: 0.0274 - val_loss: 0.0270 - 1s/epoch - 1s/step\n",
            "Epoch 2967/3000\n",
            "1/1 - 1s - loss: 0.0273 - val_loss: 0.0269 - 1s/epoch - 1s/step\n",
            "Epoch 2968/3000\n",
            "1/1 - 1s - loss: 0.0273 - val_loss: 0.0269 - 1s/epoch - 1s/step\n",
            "Epoch 2969/3000\n",
            "1/1 - 1s - loss: 0.0272 - val_loss: 0.0268 - 1s/epoch - 1s/step\n",
            "Epoch 2970/3000\n",
            "1/1 - 1s - loss: 0.0272 - val_loss: 0.0268 - 1s/epoch - 1s/step\n",
            "Epoch 2971/3000\n",
            "1/1 - 1s - loss: 0.0271 - val_loss: 0.0267 - 1s/epoch - 1s/step\n",
            "Epoch 2972/3000\n",
            "1/1 - 1s - loss: 0.0270 - val_loss: 0.0267 - 1s/epoch - 1s/step\n",
            "Epoch 2973/3000\n",
            "1/1 - 1s - loss: 0.0270 - val_loss: 0.0266 - 1s/epoch - 1s/step\n",
            "Epoch 2974/3000\n",
            "1/1 - 1s - loss: 0.0269 - val_loss: 0.0266 - 1s/epoch - 1s/step\n",
            "Epoch 2975/3000\n",
            "1/1 - 1s - loss: 0.0269 - val_loss: 0.0265 - 1s/epoch - 1s/step\n",
            "Epoch 2976/3000\n",
            "1/1 - 1s - loss: 0.0268 - val_loss: 0.0265 - 1s/epoch - 1s/step\n",
            "Epoch 2977/3000\n",
            "1/1 - 1s - loss: 0.0268 - val_loss: 0.0264 - 1s/epoch - 1s/step\n",
            "Epoch 2978/3000\n",
            "1/1 - 1s - loss: 0.0268 - val_loss: 0.0264 - 1s/epoch - 1s/step\n",
            "Epoch 2979/3000\n",
            "1/1 - 1s - loss: 0.0267 - val_loss: 0.0264 - 1s/epoch - 1s/step\n",
            "Epoch 2980/3000\n",
            "1/1 - 1s - loss: 0.0267 - val_loss: 0.0263 - 1s/epoch - 1s/step\n",
            "Epoch 2981/3000\n",
            "1/1 - 1s - loss: 0.0266 - val_loss: 0.0263 - 1s/epoch - 1s/step\n",
            "Epoch 2982/3000\n",
            "1/1 - 1s - loss: 0.0266 - val_loss: 0.0263 - 1s/epoch - 1s/step\n",
            "Epoch 2983/3000\n",
            "1/1 - 1s - loss: 0.0265 - val_loss: 0.0262 - 1s/epoch - 1s/step\n",
            "Epoch 2984/3000\n",
            "1/1 - 1s - loss: 0.0265 - val_loss: 0.0262 - 1s/epoch - 1s/step\n",
            "Epoch 2985/3000\n",
            "1/1 - 1s - loss: 0.0264 - val_loss: 0.0262 - 1s/epoch - 1s/step\n",
            "Epoch 2986/3000\n",
            "1/1 - 1s - loss: 0.0264 - val_loss: 0.0261 - 1s/epoch - 1s/step\n",
            "Epoch 2987/3000\n",
            "1/1 - 1s - loss: 0.0263 - val_loss: 0.0261 - 1s/epoch - 1s/step\n",
            "Epoch 2988/3000\n",
            "1/1 - 1s - loss: 0.0263 - val_loss: 0.0261 - 1s/epoch - 1s/step\n",
            "Epoch 2989/3000\n",
            "1/1 - 1s - loss: 0.0263 - val_loss: 0.0260 - 1s/epoch - 1s/step\n",
            "Epoch 2990/3000\n",
            "1/1 - 1s - loss: 0.0262 - val_loss: 0.0260 - 1s/epoch - 1s/step\n",
            "Epoch 2991/3000\n",
            "1/1 - 1s - loss: 0.0262 - val_loss: 0.0259 - 1s/epoch - 1s/step\n",
            "Epoch 2992/3000\n",
            "1/1 - 1s - loss: 0.0261 - val_loss: 0.0259 - 1s/epoch - 1s/step\n",
            "Epoch 2993/3000\n",
            "1/1 - 1s - loss: 0.0261 - val_loss: 0.0259 - 1s/epoch - 1s/step\n",
            "Epoch 2994/3000\n",
            "1/1 - 1s - loss: 0.0261 - val_loss: 0.0258 - 1s/epoch - 1s/step\n",
            "Epoch 2995/3000\n",
            "1/1 - 1s - loss: 0.0260 - val_loss: 0.0258 - 1s/epoch - 1s/step\n",
            "Epoch 2996/3000\n",
            "1/1 - 1s - loss: 0.0260 - val_loss: 0.0258 - 1s/epoch - 1s/step\n",
            "Epoch 2997/3000\n",
            "1/1 - 1s - loss: 0.0259 - val_loss: 0.0257 - 1s/epoch - 1s/step\n",
            "Epoch 2998/3000\n",
            "1/1 - 1s - loss: 0.0259 - val_loss: 0.0257 - 1s/epoch - 1s/step\n",
            "Epoch 2999/3000\n",
            "1/1 - 1s - loss: 0.0258 - val_loss: 0.0256 - 1s/epoch - 1s/step\n",
            "Epoch 3000/3000\n",
            "1/1 - 1s - loss: 0.0258 - val_loss: 0.0256 - 1s/epoch - 1s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 평가, 예측 / 날씨\n",
        "loss=model.evaluate(test_x,test_y)\n",
        "pred_y=model.predict(test_x)\n",
        "\n",
        "print('loss: ',loss)\n",
        "print('예상 강수량, 기온 : ', pred_y[-1:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqPThzBMNWkZ",
        "outputId": "f5b28e08-7d25-485d-c292-8461cf2df2b7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 24ms/step - loss: 0.0315\n",
            "loss:  0.03154443949460983\n",
            "예상 강수량, 기온 :  [[ 0.08142194 25.326422  ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss:  0.02682594209909439\n",
        "예상 강수량, 기온 :  [[63.300068 22.007986]] "
      ],
      "metadata": {
        "id": "9Li7zwiKYwa-"
      }
    }
  ]
}